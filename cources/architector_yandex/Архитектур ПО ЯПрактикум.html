<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Архитектур ПО ЯПрактикум</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Архитектур ПО ЯПрактикум</h1>
</header>
<h1 id="яндекс-практикум-архитектура-по">Яндекс Практикум Архитектура
ПО</h1>
<h2 id="спринт-1"><em>Спринт 1</em></h2>
<h2 id="микросервисы-и-документирование-решение">Микросервисы и
документирование решение</h2>
<h3 id="жизненный-цикл-микросервиса">Жизненный цикл микросервиса</h3>
<h2 id="микрофронтенды">Микрофронтенды</h2>
<h3 id="методы-интеграции-микрофронтендов">Методы интеграции
микрофронтендов</h3>
<h3 id="методы-композиции-микрофронтендов">Методы композиции
микрофронтендов</h3>
<h3 id="маршрутизация">Маршрутизация</h3>
<h3 id="взаимодействие-на-основе-api">Взаимодействие на основе API</h3>
<h3 id="паттерн-pubsub">Паттерн Pub/Sub</h3>
<h3 id="библиотека-глобального-состояния">Библиотека глобального
состояния</h3>
<h2 id="domain-driven-design-ddd">Domain-Driven Design (DDD)</h2>
<h3 id="стратегическое-проектирование">Стратегическое
проектирование</h3>
<h3 id="тактическое-проектирование">Тактическое проектирование</h3>
<h3 id="процесс-выделения-доменов-и-контекстов">Процесс выделения
доменов и контекстов</h3>
<h3 id="применение-ddd-в-работе-с-микросервисами">Применение DDD в
работе с микросервисами</h3>
<h2 id="основы-контейнеризации-микросервисов">Основы контейнеризации
микросервисов</h2>
<h3 id="docker">Docker</h3>
<h3 id="dockerfile">Dockerfile</h3>
<h3 id="команды-docker">Команды Docker</h3>
<h3 id="оптимизация-dockerfile">Оптимизация Dockerfile</h3>
<h3 id="расширенная-контейнеризация-и-docker-compose">Расширенная
контейнеризация и Docker Compose</h3>
<h3 id="настройка-сетей-docker-compose">Настройка сетей Docker
Compose</h3>
<h2 id="принципы-12-факторных-приложений">Принципы 12-факторных
приложений</h2>
<h3 id="реализация-12-факторных-приложений">Реализация 12-факторных
приложений</h3>
<h2 id="документирование-решений-с-помощью-диаграмм-c4">Документирование
решений с помощью диаграмм C4</h2>
<h3 id="модель-c4">Модель C4</h3>
<h3 id="context-diagrams-диаграммы-контекста">Context diagrams —
диаграммы контекста</h3>
<h3 id="диаграмма-контейнеров-container-diagram">Диаграмма контейнеров —
Container diagram</h3>
<h3 id="диаграмма-компонентов-component-diagram">Диаграмма компонентов —
Component diagram</h3>
<h3 id="диаграмма-кода-codeclasses-diagram">Диаграмма кода —
Code/classes diagram</h3>
<h3 id="диаграммы-последовательностей-dynamic-diagrams">Диаграммы
последовательностей — Dynamic diagrams</h3>
<h3 id="диаграммы-развёртывания-deployment-diagrams">Диаграммы
развёртывания — Deployment diagrams</h3>
<h3 id="как-создавать-диаграммы-c4">Как создавать диаграммы C4</h3>
<h3 id="анализ-и-интерпретация-диаграмм-c4">Анализ и интерпретация
диаграмм C4</h3>
<h3 id="как-улучшать-диаграммы-c4-на-основе-обратной-связи">Как улучшать
диаграммы C4 на основе обратной связи</h3>
<h2 id="подход-documentation-as-code-с-помощью-plantuml-и-mkdocs">Подход
documentation as code с помощью PlantUML и MKDocs</h2>
<h3 id="работа-с-plantuml">Работа с PlantUML</h3>
<h3 id="создание-диаграмм-в-plantuml">Создание диаграмм в PlantUML</h3>
<h3 id="интеграция-plantuml-с-mkdocs">Интеграция PlantUML с MkDocs</h3>
<h2 id="as-is-и-to-be">As-Is и To-be</h2>
<h3 id="as-is">As-Is</h3>
<h3 id="to-be">To-be</h3>
<hr />
<h1 id="спринт-2">Спринт 2</h1>
<hr />
<h2 id="паттерн-strangler-fig">Паттерн Strangler Fig</h2>
<h3 id="антипаттерн-большой-взрыв">Антипаттерн “Большой взрыв”</h3>
<h2 id="как-реализовать-strangler-fig">Как реализовать Strangler
Fig</h2>
<h3 id="шаг-1.-определение-доменной-области">Шаг 1. Определение доменной
области</h3>
<h3 id="шаг-2.-проектирование-и-разработка-новых-микросервисов">Шаг 2.
Проектирование и разработка новых микросервисов</h3>
<h3 id="шаг-3.-перенаправление-трафика">Шаг 3. Перенаправление
трафика</h3>
<h3 id="фича-тоглы">Фича-тоглы</h3>
<h3 id="шаг-4.-мониторинг-и-верификация-микросервисов">Шаг 4. Мониторинг
и верификация микросервисов</h3>
<h3 id="средства-мониторинга">Средства мониторинга</h3>
<h3 id="методы-верификации">Методы верификации</h3>
<h3 id="шаг-5.-настройка-итерационного-процесса">Шаг 5. Настройка
итерационного процесса</h3>
<h3 id="подводные-камни-реализации-strangler-fig">подводные камни
реализации Strangler Fig</h3>
<h2 id="определение-доменной-области">Определение доменной области</h2>
<h3 id="определение-списка-функций-продукта">Определение списка функций
продукта</h3>
<h3 id="методы-расстановки-приоритетов">Методы расстановки
приоритетов</h3>
<h4 id="moscow">MoSCoW</h4>
<h4 id="матрица-эйзенхауэра">Матрица Эйзенхауэра</h4>
<h4 id="дополнительные-методы-приоритизации">Дополнительные методы
приоритизации</h4>
<h2 id="anti-corruption-layer-и-маршрутизация">Anti-Corruption Layer и
маршрутизация</h2>
<h3 id="задачи-acl-при-миграции-на-микросервисы">Задачи ACL при миграции
на микросервисы</h3>
<h3 id="как-работает-acl">Как работает ACL</h3>
<h3 id="когда-внедрять-и-отключать-acl">Когда внедрять и отключать
ACL</h3>
<h3 id="когда-стоит-отказаться-от-acl">Когда стоит отказаться от
ACL</h3>
<h3 id="как-внедрить-acl">Как внедрить ACL</h3>
<h3 id="технологии-и-инструменты-для-создания-acl">Технологии и
инструменты для создания ACL</h3>
<h3 id="маршрутизация-в-микросервисах">Маршрутизация в
микросервисах</h3>
<h3
id="техники-маршрутизации-между-монолитом-и-новыми-сервисами">Техники
маршрутизации между монолитом и новыми сервисами</h3>
<h2 id="стратегии-проектирования-микрофронтендов">Стратегии
проектирования микрофронтендов</h2>
<h3 id="вертикальная-нарезка">Вертикальная нарезка</h3>
<h3 id="автономность-команд">Автономность команд</h3>
<h3 id="изоляция">Изоляция</h3>
<h2 id="паттерн-backend-for-frontend">Паттерн Backend for Frontend</h2>
<h3 id="проблемы-традиционного-api-в-сложной-архитектуре">Проблемы
традиционного API в сложной архитектуре</h3>
<h3 id="что-такое-backend-for-frontend">Что такое Backend for
Frontend</h3>
<h3 id="когда-использовать-bff">Когда использовать BFF</h3>
<h3 id="bff-для-микрофронтендов">BFF для микрофронтендов</h3>
<h3 id="преимущества-bff">Преимущества BFF</h3>
<h3 id="что-важно-учесть-при-дизайне-bff">Что важно учесть при дизайне
BFF</h3>
<h2 id="паттерны-управления-микросервисами">Паттерны управления
микросервисами</h2>
<h3 id="паттерн-cqrs">Паттерн CQRS</h3>
<h4 id="разделение-чтения-и-записи-данных-с-cqrs">Разделение чтения и
записи данных с CQRS</h4>
<h4 id="документирование-применения-cqrs">Документирование применения
CQRS</h4>
<h3 id="паттерн-saga">Паттерн Saga</h3>
<h4 id="подходы-к-реализации-saga">Подходы к реализации Saga</h4>
<h4 id="оркестрация">Оркестрация</h4>
<h4 id="хореография">Хореография</h4>
<h4 id="обеспечение-согласованности-данных-с-помощью-saga">Обеспечение
согласованности данных с помощью Saga</h4>
<h4 id="документирование-применения-saga">Документирование применения
Saga</h4>
<h3 id="api-gateway">API Gateway</h3>
<h4 id="управление-api-микросервисов-с-помощью-api-gateway">Управление
API микросервисов с помощью API Gateway</h4>
<h4 id="оценка-различных-подходов-к-использованию-api-gateway">Оценка
различных подходов к использованию API Gateway</h4>
<h2
id="взаимодействие-микросервисов-с-использованием-kong">Взаимодействие
микросервисов с использованием Kong</h2>
<h3 id="настройка-и-использование-api-gateway-kong">Настройка и
использование API Gateway — Kong</h3>
<h3 id="безопасность-мониторинг-и-отладка-api-gateway">Безопасность,
мониторинг и отладка API Gateway</h3>
<h4 id="управление-аутентификацией-и-авторизацией">Управление
аутентификацией и авторизацией</h4>
<h4 id="настройка-защиты-от-ddos-атак">Настройка защиты от
DDoS-атак</h4>
<h4 id="мониторинг-метрик-на-api-gateway">Мониторинг метрик на API
Gateway</h4>
<h4 id="пример-использование-api-gateway-в-weathernow">Пример,
Использование API Gateway в WeatherNow</h4>
<h2
id="взаимодействие-микросервисов-с-использованием-kafka">Взаимодействие
микросервисов с использованием Kafka</h2>
<h3 id="взаимодействие-между-микросервисами">Взаимодействие между
микросервисами</h3>
<h3 id="основные-концепции-синхронного-взаимодействия">Основные
концепции синхронного взаимодействия</h3>
<h3 id="основные-концепции-асинхронного-взаимодействия">Основные
концепции асинхронного взаимодействия</h3>
<h4 id="пуш-push-и-пул-pull-подходы">Пуш (Push) и Пул (Pull)
подходы</h4>
<h4 id="паттерны-асинхронного-взаимодействия">Паттерны асинхронного
взаимодействия</h4>
<h3 id="openapi-vs-asyncapi">OpenAPI vs AsyncAPI</h3>
<h3 id="kafka-для-асинхронного-обмена">Kafka для асинхронного
обмена</h3>
<h4 id="альтернативы-kafka">Альтернативы Kafka</h4>
<h3 id="настройка-кластера-kafka">Настройка кластера Kafka</h3>
<h3 id="интеграция-kafka-с-микросервисами-java">Интеграция Kafka с
микросервисами Java</h3>
<h3 id="мониторинг-и-отладка-работы-kafka-в-продакшене">Мониторинг и
отладка работы Kafka в продакшене</h3>
<h4 id="отладка-работы-kafka">Отладка работы Kafka</h4>
<h2 id="создание-и-использование-helm-чартов-в-kubernetes">Создание и
использование Helm-чартов в Kubernetes</h2>
<h3 id="оркестрация-контейнеров">Оркестрация контейнеров</h3>
<h3 id="helm">Helm</h3>
<h4 id="основные-компоненты-helm">Основные компоненты Helm</h4>
<h4 id="создание-helm-чарта-для-quickdelivery">Создание Helm-чарта для
QuickDelivery</h4>
<h4 id="развёртывание-helm-чарта-для-quickdelivery">Развёртывание
Helm-чарта для QuickDelivery</h4>
<h4 id="обновление-helm-чарта">Обновление Helm-чарта</h4>
<h3 id="cloud-native-computing-foundation-cncf">Cloud Native Computing
Foundation (CNCF)</h3>
<h4 id="cncf-landscape">CNCF Landscape</h4>
<h4 id="интеграция-cncf-инструментов-в-проекты">Интеграция
CNCF-инструментов в проекты</h4>
<h2 id="service-mesh">Service Mesh</h2>
<h3 id="основные-концепты-service-mesh">Основные концепты Service
Mesh</h3>
<h3 id="основные-элементы-конфигурации-istio">Основные элементы
конфигурации Istio</h3>
<h3 id="создание-и-настройка-service-mesh-с-istio">Создание и настройка
Service Mesh с Istio</h3>
<h2 id="service-discovery">Service Discovery</h2>
<h3 id="настройка-service-discovery-с-istio">Настройка Service Discovery
с Istio</h3>
<h2 id="feature-toggling">Feature Toggling</h2>
<h3 id="настройка-feature-toggling-с-istio">Настройка Feature Toggling с
Istio</h3>
<h2 id="сicd-процессы">СI/CD-процессы</h2>
<h3 id="continuous-integration-ci">Continuous Integration (CI)</h3>
<h3 id="continuous-delivery-cd">Continuous Delivery (CD)</h3>
<h3 id="continuous-deployment">Continuous Deployment</h3>
<h3 id="pipeline-as-code">Pipeline as Code</h3>
<h3 id="cicd-pac-и-devops">CI/CD, PaC и DevOps</h3>
<h3 id="как-настроить-базовый-cicd-конвейер">Как настроить базовый
CI/CD-конвейер</h3>
<h4 id="что-ещё-можно-автоматизировать">Что ещё можно
автоматизировать?</h4>
<h4 id="как-автоматизировать-cicd-конвейеры-с-помощью-скриптов">Как
автоматизировать CI/CD-конвейеры с помощью скриптов</h4>
<h4 id="как-настроить-мониторинг-cicd-конвейера">Как настроить
мониторинг CI/CD-конвейера</h4>
<h2 id="микросервисы-и-процесс-взаимодействия">Микросервисы и процесс
взаимодействия</h2>
<h3 id="распределённые-транзакции">Распределённые транзакции</h3>
<h3 id="стратегии-развёртывания">Стратегии развёртывания</h3>
<h4 id="cовременные-стратегии-развёртывания">Cовременные стратегии
развёртывания</h4>
<h3 id="helm-1">Helm</h3>
<h3 id="настройка-github-kubernetes">Настройка Github Kubernetes</h3>
<h3 id="circuit-breaker">Circuit Breaker</h3>
<hr />
<h1 id="спринт-3">Спринт 3</h1>
<hr />
<h2 id="цифровая-трансформация">Цифровая трансформация</h2>
<h3 id="формирование-стратегии-цифровой-трансформации">Формирование
стратегии цифровой трансформации</h3>
<h2 id="текущее-и-целевое-состояние-бизнеса">Текущее и целевое состояние
бизнеса</h2>
<h3 id="бизнес-архитектура-компании">Бизнес-архитектура компании</h3>
<h3 id="бизнес-возможности-компании">Бизнес-возможности компании</h3>
<h2 id="текущая-и-целевая-архитектура">Текущая и целевая
архитектура</h2>
<h3 id="обзор-основных-классов-it-систем-компаний">Обзор основных
классов IT-систем компаний</h3>
<h3 id="описание-текущей-и-целевой-архитектуры">Описание текущей и
целевой архитектуры</h3>
<h4 id="карта-it-ландшафта">Карта IT-ландшафта</h4>
<h4 id="целевая-карта-ландшафта">Целевая карта ландшафта</h4>
<h4 id="платформы-в-разработке-и-архитектуре-компаний">Платформы в
разработке и архитектуре компаний</h4>
<h4 id="диаграмма-интеграции-приложений">Диаграмма интеграции
приложений</h4>
<h2 id="планирование-стратегических-изменений">Планирование
стратегических изменений</h2>
<h3 id="дорожная-карта-цифровой-трансформации">Дорожная карта цифровой
трансформации</h3>
<h3 id="различные-подходы">Различные подходы</h3>
<h4 id="проектный-подход">Проектный подход</h4>
<h4 id="продуктовый-подход">Продуктовый подход</h4>
<h4 id="метрики-бизнеса-и-продуктов">Метрики бизнеса и продуктов</h4>
<h4 id="инвестиционные-метрики">Инвестиционные метрики</h4>
<h4 id="метрики-продукта">Метрики продукта</h4>
<h2
id="управление-требованиями-и-определение-бизнес-процессов">Управление
требованиями и определение бизнес-процессов</h2>
<h3 id="как-описывать-требования">Как описывать требования</h3>
<h4 id="архитектурно-значимые-требования">Архитектурно значимые
требования</h4>
<h4 id="пример-описания-требований-по-furps">Пример описания требований
по FURPS+</h4>
<h4 id="пользовательские-сценарии">Пользовательские сценарии</h4>
<h4 id="потоки-вариантов-использования">Потоки вариантов
использования</h4>
<h3 id="описание-бизнес-процессов">Описание бизнес-процессов</h3>
<h2
id="проектирование-архитектуры-и-управление-изменениями">Проектирование
архитектуры и управление изменениями</h2>
<h3
id="architecture-design-record-и-architecture-decision-log">Architecture
Design Record и Architecture Decision Log</h3>
<h4 id="формат-и-шаблоны-adr">Формат и шаблоны ADR</h4>
<h4 id="создание-adr-на-примере">Создание ADR на примере</h4>
<h3 id="дизайн-мышление">Дизайн-мышление</h3>
<h3 id="планирование-реализации">Планирование реализации</h3>
<hr />
<h1 id="спринт-4">Спринт 4</h1>
<hr />
<h2 id="введение-в-масштабирование">Введение в масштабирование</h2>
<h3 id="репликация">Репликация</h3>
<h4 id="репликация-master-slave">Репликация master-slave</h4>
<h4 id="паттерн-read-replica">Паттерн read-replica</h4>
<h4 id="репликация-multi-master">Репликация multi-master</h4>
<h4 id="преимущества-и-недостатки-репликации">Преимущества и недостатки
репликации</h4>
<h4 id="целесообразность-репликации">Целесообразность репликации</h4>
<h3 id="репликация-на-mongodb">Репликация на MongoDb</h3>
<h4 id="настройка-репликации-mongodb-в-docker">Настройка репликации
MongoDB в Docker</h4>
<h3 id="кеширование">Кеширование</h3>
<h3 id="redis-cluster-для-кеширования-данных">Redis Cluster для
кеширования данных</h3>
<h4 id="настройка-redis-cluster">Настройка Redis Cluster</h4>
<h4 id="механизм-работы-redis">Механизм работы Redis</h4>
<h4 id="реализация-репликации-в-различных-бд">Реализация репликации в
различных БД</h4>
<h3 id="шардирование-и-партиционирование">Шардирование и
партиционирование</h3>
<h4 id="методы-шардирования">Методы шардирования</h4>
<h3 id="реализация-шардирования">Реализация шардирования</h3>
<h4 id="шардирование-в-redis">Шардирование в Redis</h4>
<h4 id="шардирование-в-postgresql-практика">Шардирование в PostgreSQL:
практика</h4>
<h4 id="шардирование-в-mongodb">Шардирование в MongoDB</h4>
<h2 id="горизонтальное-масштабирование-приложения">Горизонтальное
масштабирование приложения</h2>
<h3 id="способы-сохранения-состояний-приложения">Способы сохранения
состояний приложения</h3>
<h3 id="балансировщик-нагрузки">Балансировщик нагрузки</h3>
<h4 id="виды-балансировщиков-нагрузки">Виды балансировщиков
нагрузки</h4>
<h4 id="как-настроить-балансировщик-нагрузки-nginx">Как настроить
балансировщик нагрузки Nginx</h4>
<h4 id="apisix-gateway">APISIX Gateway</h4>
<h4 id="практика-настройка-apisix-gateway">Практика: настройка APISIX
Gateway</h4>
<h2 id="архитектура-без-ведущего-узла">Архитектура без ведущего
узла</h2>
<h3 id="архитектура-master-slave-vs-leaderless-архитектура">Архитектура
Master-Slave vs Leaderless-архитектура</h3>
<h4 id="репликация-без-ведущего-узла-в-apache-cassandra">Репликация без
ведущего узла в Apache Cassandra</h4>
<h3 id="условия-согласованности-на-примере-cassandra">Условия
согласованности на примере Cassandra</h3>
<h4 id="механизмы-восстановления-согласованности-в-cassandra">Механизмы
восстановления согласованности в Cassandra</h4>
<h4 id="consistent-hashing-и-виртуальные-ноды">Consistent Hashing и
виртуальные ноды</h4>
<h4 id="принцип-работы-consistent-hashing">Принцип работы consistent
hashing</h4>
<h4 id="особенности-работы-с-cassandra">Особенности работы с
Cassandra</h4>
<h2 id="шарды-и-реплики-в-геораспределённой-среде">Шарды и реплики в
геораспределённой среде</h2>
<h3 id="облако-и-гибридная-архитектура">Облако и гибридная
архитектура</h3>
<h3 id="создание-шардированного-кластера-mongodb">Создание
шардированного кластера MongoDB</h3>
<h2 id="распределённое-кеширование">Распределённое кеширование</h2>
<h3 id="как-настроить-распределённое-кеширование-в-yandex-cloud">Как
настроить распределённое кеширование в Yandex Cloud</h3>
<h2 id="content-delivery-network-cdn">Content Delivery Network
(CDN)</h2>
<h3 id="методы-разделения-данных-на-основе-dns">Методы разделения данных
на основе DNS</h3>
<h3 id="механизм-работы-cdn">Механизм работы CDN</h3>
<h3 id="как-настроить-cdn-в-облаке-yandex-cloud">Как настроить CDN в
облаке Yandex Cloud</h3>
<hr />
<h1 id="спринт-5">Спринт 5</h1>
<hr />
<h2 id="оценка-угроз-системам-компании">Оценка угроз системам
компании</h2>
<h3 id="виды-угроз">Виды угроз</h3>
<h3 id="векторы-угроз">Векторы угроз</h3>
<h3 id="примеры-реализации-угроз-данным">Примеры реализации угроз
данным</h3>
<h3 id="оценка-угроз">Оценка угроз</h3>
<h2 id="как-управлять-рисками">Как управлять рисками</h2>
<h3 id="типы-рисков">Типы рисков</h3>
<h2 id="как-разработать-проект-архитектуры-безопасности">Как разработать
проект архитектуры безопасности</h2>
<h2
id="законодательный-уровень-информационной-безопасности">Законодательный
уровень информационной безопасности</h2>
<h3 id="работа-с-персональными-данными">Работа с персональными
данными</h3>
<h2 id="классификация-данных">Классификация данных</h2>
<h3 id="классификация-данных-при-проектировании-систем">классификация
данных при проектировании систем</h3>
<h3 id="вызовы-и-решения-в-управлении-разными-классами-данных">Вызовы и
решения в управлении разными классами данных</h3>
<h2 id="составление-проверочного-листа">Составление проверочного
листа</h2>
<h3 id="ключевые-разделы-it-инфраструктуры-чек-листа">Ключевые разделы
IT-инфраструктуры чек-листа</h3>
<h2 id="проектирование-слоя-безопасности">Проектирование слоя
безопасности</h2>
<h2
id="идентификация-и-аутентификация-управление-доступом">Идентификация и
аутентификация, управление доступом</h2>
<h3 id="идентификация">Идентификация</h3>
<h3 id="аутентификация">Аутентификация</h3>
<h3 id="авторизация-и-управление-доступом">Авторизация и управление
доступом</h3>
<h4 id="типичные-проблемы-управления-доступом">Типичные проблемы
управления доступом</h4>
<h2 id="протоколирование-аудит">Протоколирование, аудит</h2>
<h3 id="принципы-построения-подсистемы-аудита">Принципы построения
подсистемы аудита</h3>
<h3 id="основные-принципы-аудита">Основные принципы аудита</h3>
<h3 id="определение-состава-процессов-подлежащих-аудиту">Определение
состава процессов, подлежащих аудиту</h3>
<h3 id="проектирование-структуры-данных-для-аудита">Проектирование
структуры данных для аудита</h3>
<h3 id="записи-в-логах">Записи в логах</h3>
<h2 id="как-контролировать-целостность-данных">Как контролировать
целостность данных</h2>
<h3 id="двухфазный-коммит">Двухфазный коммит</h3>
<h3 id="eventual-consistency">Eventual Consistency</h3>
<h3 id="компенсационные-транзакции-в-микросервисах">Компенсационные
транзакции в микросервисах</h3>
<h4
id="приёмы-которые-компенсируют-отсутствие-транзакций-в-распределённых-системах">Приёмы,
которые компенсируют отсутствие транзакций в распределённых
системах</h4>
<h2 id="угрозы-целостности-данных-и-меры-защиты">Угрозы целостности
данных и меры защиты</h2>
<h2 id="средства-защиты-доступа-к-данным">Средства защиты доступа к
данным</h2>
<h3
id="проектирование-защиты-от-несанкционированного-доступа">Проектирование
защиты от несанкционированного доступа</h3>
<h3 id="методы-защиты-данных">Методы защиты данных</h3>
<h2 id="как-настроить-rbac-в-kubernetes">Как настроить RBAC в
Kubernetes</h2>
<h3 id="настройка-rbac-практика">Настройка RBAC: практика</h3>
<hr />
<h1 id="спринт-6">Спринт 6</h1>
<hr />
<h2 id="как-работает-http-кеширование">Как работает
HTTP-кеширование</h2>
<h2 id="паттерны-кеширования-и-способы-инвалидации-кеша">Паттерны
кеширования и способы инвалидации кеша</h2>
<h3 id="способы-инвалидации-кеша">Способы инвалидации кеша</h3>
<h2 id="практика-настройка-кеширования">Практика: настройка
кеширования</h2>
<h3 id="реализация-cache-aside">Реализация Cache-Aside</h3>
<h3 id="паттерн-refresh-ahead">Паттерн Refresh-Ahead</h3>
<h2 id="паттерны-backpressure-и-circuit-breaker">Паттерны Backpressure и
Circuit Breaker</h2>
<h3 id="метрики-нагрузки">Метрики нагрузки</h3>
<h3 id="паттерны-снижения-нагрузки">Паттерны снижения нагрузки</h3>
<h4 id="паттерн-backpressure">Паттерн Backpressure</h4>
<h4 id="паттерн-circuit-breaker">Паттерн Circuit Breaker</h4>
<h2 id="мониторинг-и-логирование">Мониторинг и логирование</h2>
<h3 id="observability">Observability</h3>
<h3 id="мониторинг">Мониторинг</h3>
<h4 id="этапы-мониторинга">Этапы мониторинга</h4>
<h4 id="основные-подходы-к-мониторингу">Основные подходы к
мониторингу</h4>
<h3 id="логирование">Логирование</h3>
<h2 id="сбор-и-визуализация-метрик-с-помощью-prometheus-и-grafana">Сбор
и визуализация метрик с помощью Prometheus и Grafana</h2>
<h3 id="prometheus">Prometheus</h3>
<h4 id="развёртывание-prometheus">Развёртывание Prometheus</h4>
<h3 id="grafana">Grafana</h3>
<h4 id="установка-grafana">Установка Grafana</h4>
<h2 id="elk.-создание-и-настройка-индексов-c-помощью-elasticsearch">ELK.
Создание и настройка индексов c помощью Elasticsearch</h2>
<h3 id="как-работает-elasticsearch">Как работает Elasticsearch</h3>
<h4 id="рекомендации-по-работе-с-индексами">Рекомендации по работе с
индексами</h4>
<h4 id="практика-настройте-elasticsearch-logstash-и-kibana">Практика:
настройте Elasticsearch, Logstash и Kibana</h4>
<h2 id="трейсинг">Трейсинг</h2>
<h3 id="opentelemetry">OpenTelemetry</h3>
<h2 id="применение-мониторинга-логов-кеша">Применение мониторинга,
логов, кеша</h2>
<hr />
<h1 id="спринт-7">Спринт 7</h1>
<hr />
<h2 id="введение-в-искусственный-интеллект-ai">Введение в искусственный
интеллект (AI)</h2>
<h3 id="искусственный-интеллект">Искусственный интеллект</h3>
<h3 id="nlp">NLP</h3>
<h2 id="работа-с-данными-как-основа-машинного-обучения-ml">Работа с
данными как основа машинного обучения (ML)</h2>
<h3 id="crisp-dm">CRISP-DM</h3>
<h2 id="ml-модели-и-их-виды">ML-модели и их виды</h2>
<h2 id="спринт-1c">Спринт 1c</h2>
<h2 id="микросервисы-и-документирование-решение-1">Микросервисы и
документирование решение</h2>
<ul>
<li><p>микросервисы как способ разработки программного обеспечения, при
котором приложения строят из множества небольших, независимых
сервисов</p>
<ul>
<li>Каждый сервис с одной бизнес-функцией.</li>
<li>Микросервисы общаются между собой через легковесные механизмы, такие
как HTTP API и сообщения.</li>
</ul></li>
<li><p>Каждый микросервис ориентирован на конкретную бизнес-функцию и
разрабатывается вокруг неё.</p></li>
<li><p>Проблемы</p>
<ul>
<li>нужно продумывать, как микросервисы будут взаимодействовать друг с
другом.</li>
<li>в распределённой среде, что усложняет отладку и тестирование</li>
<li>Сетевые задержки и надёжность</li>
<li>Более сложное управление конфигурацией</li>
</ul></li>
<li><blockquote>
<p>Любая организация, которая проектирует систему, неизбежно создаёт
дизайн, который копирует структуру коммуникаций этой организации.</p>
</blockquote></li>
<li><p>Разделение ответственности.</p>
<ul>
<li>В микросервисной архитектуре каждая команда отвечает за свой
сервис</li>
</ul></li>
<li><p>Минимизация зависимостей.</p>
<ul>
<li>Команды могут работать независимо друг от друга, что минимизирует
количество зависимостей между сервисами</li>
</ul></li>
<li><p>Оптимизация коммуникаций.</p>
<ul>
<li>Микросервисная архитектура отражает коммуникационные пути внутри
организации.</li>
</ul></li>
<li><p>Преимущества от разделения по закону Конвея</p>
<ul>
<li>Повышенная автономность команд.</li>
<li>Улучшенная гибкость и адаптивность.
<ul>
<li>Каждая команда может быстро реагировать на изменения требований и
вносить необходимые улучшения в свой микросервис без необходимости
координироваться с другими командами.</li>
</ul></li>
<li>Оптимизированная архитектур
<ul>
<li>Архитектура системы становится отражением эффективных
коммуникационных путей внутри организации.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="жизненный-цикл-микросервиса-1">Жизненный цикл микросервиса</h3>
<ul>
<li>Этап 1. Проектирование
<ul>
<li>определение его цели и функциональности</li>
<li>команда анализирует бизнес-требования и принимает решения о границах
микросервиса.</li>
<li>Выбрать технологии и инструменты для реализации микросервиса</li>
</ul></li>
<li>Этап 2. Разработка
<ul>
<li>команда разработчиков пишет, тестирует и документирует код, следуя
принципам разработки микросервисов.</li>
</ul></li>
<li>Этап 3. Тестирование
<ul>
<li>включает в себя проверку его функциональности, производительности и
безопасности</li>
<li>модульные тесты, интеграционные тесты, нагрузочное тестирование,
чтобы оценить производительность микросервиса.</li>
</ul></li>
<li>Этап 4. Развёртывание
<ul>
<li>установка и настройка в производственной среде</li>
<li>среда для развёртывания — настроить серверы и контейнеры.</li>
<li>Автоматизировать процесс развёртывания с помощью
CI/CD-инструментов.</li>
<li>Развернуть микросервис в производственной среде.</li>
</ul></li>
<li>Этап 5. Мониторинг и поддержка
<ul>
<li>Настроить мониторинг, чтобы отслеживать состояние и
производительность микросервиса</li>
<li>Реагировать на инциденты и устранять неполадки.</li>
<li>Обновлять микросервис и внедрять улучшения на основе собранных
данных.</li>
</ul></li>
<li>Этап 6. Масштабирование
<ul>
<li>Проанализировать метрики и логи, чтобы выявить потребность в
масштабировании.</li>
<li>Увеличить ресурсы (CPU, память) или количество экземпляров
микросервиса.</li>
<li>Обеспечить балансировку нагрузки между экземплярами.</li>
</ul></li>
<li>Этап 7. Обновление и улучшение
<ul>
<li>Собрать обратную связь от пользователей и проанализировать метрики,
чтобы выявить области для улучшения.</li>
<li>Разработать и протестировать новые функции.</li>
<li>Обновить микросервис в производственной среде.</li>
</ul></li>
<li>Этап 8. Вывод из эксплуатации
<ul>
<li>Оповестить пользователей и другие команды о том, что вы планируете
вывести микросервис из эксплуатации.</li>
<li>Если нужно, перенести данные и функции на другие сервисы.</li>
<li>Отключить микросервис и удалить его из производственной среды.</li>
</ul></li>
<li><blockquote>
<p>Если приложение уже не маленькое, но пока и не огромное, не стоит
сразу внедрять микросервисы. Лучше сначала перейти к модульному
монолиту.</p>
</blockquote></li>
</ul>
<h2 id="микрофронтенды-1">Микрофронтенды</h2>
<ul>
<li><blockquote>
<p>онбординг - процесс, направленный на адаптацию персонала в
компании</p>
</blockquote></li>
<li><p>Микрофронтенд — это концепция, которая распространяет принципы
архитектуры микросервисов на мир фронтенда.</p></li>
<li><p>Модули микрофронтенда</p>
<ul>
<li>Каждый модуль — это определённая бизнес-область или
функциональность.</li>
<li>Модули разрабатывают, тестируют и развёртывают независимо друг от
друга.</li>
</ul></li>
<li><p>Слой композиции.</p>
<ul>
<li>Он отвечает за сборку различных модулей микрофронтенда в целостное
приложение,
<ul>
<li>а также управляет потоком данных и взаимодействием между клиентом и
сервером</li>
<li>Компоновка модулей может происходить
<ul>
<li>на стороне сервера, на стороне клиента или с помощью гибридного
подхода</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Маршрутизация</p>
<ul>
<li>При работе с микрофронтендами важно выбрать эффективные механизмы
маршрутизации.
<ul>
<li>Надо гарантировать, что запросы будут направляться к нужному
микрофронтенду</li>
</ul></li>
</ul></li>
<li><p>Коммуникационный слой</p>
<ul>
<li>управляет взаимодействием между микрофронтендами и остальной
инфраструктурой приложения.</li>
<li>можно через API, шины сообщений или собственные системы
событий.</li>
</ul></li>
</ul>
<h3 id="методы-интеграции-микрофронтендов-1">Методы интеграции
микрофронтендов</h3>
<ul>
<li>Build time — объединять во время сборки
<ul>
<li>Вы помещаете все компоненты в контейнер так же, как библиотеки,
которые вы устанавливаете из npm.</li>
<li>Нужно синхронизировать разные версии библиотек</li>
<li>Между контейнером и микрофронтендами будет тесная связь.</li>
<li>Если появятся изменения в зависимостях, вам придётся развёртывать
пакет заново.</li>
</ul></li>
<li>Run time — объединять во время выполнения
<ul>
<li>Развёртывать модули независимо</li>
<li>Вы объединяете микрофронтенды в единый интерфейс во время исполнения
кода на стороне пользователя.</li>
<li>нужно продумать управление маршрутизацией, разделением состояний и
интеграцией компонентов.</li>
<li>Динамически обновлять отдельные модули.</li>
<li>обновлять отдельные микрофронтенды без переразвёртывания всего
приложения.</li>
</ul></li>
<li>Build time лучше подходит простым проектам и проектам, где функции
тесно связаны между собой.</li>
<li>И наоборот, интеграция run time подходит приложениям, которые
требуют высокой гибкости, независимого развёртывания и частых
обновлений.</li>
</ul>
<h3 id="методы-композиции-микрофронтендов-1">Методы композиции
микрофронтендов</h3>
<ul>
<li><p>Композиция микрофронтендов — это процесс сборки нескольких
микрофронтендов в единое целое.</p></li>
<li><p>Серверная</p>
<ul>
<li>все микрофронтенды собирают на сервере</li>
<li>Вся функциональность находится в бекхенде</li>
<li>сервер решает какой микрофонен собрать и загрузить.</li>
<li>обратный прокси-сервер Nginx</li>
<li>либо Backend for Frontend</li>
<li>выбирать если важен SEO, отклик</li>
</ul></li>
<li><p>Клиентская</p>
<ul>
<li>браузер отвечает за динамическую загрузку каждого микрофронтенда во
время выполнения.</li>
<li>выбирать если много интерактивного контента</li>
</ul></li>
<li><p>Гибридная</p>
<ul>
<li>возможно благодаря паттерну Backend for Frontend (BFF)</li>
<li>каждый микрофронтенд имеет свой выделенный бэкенд</li>
<li>BFF обрабатывает все данные, взаимодействует с API и при
необходимости предоставляет клиенту предварительно отрендеренный
HTML</li>
<li>После первоначальной загрузки за дело берётся клиентская часть
<ul>
<li>берёт на себя динамические взаимодействия, которые необязательно
требуют обращения к серверу.</li>
<li>!! лучший выбор, но самый сложный</li>
</ul></li>
<li><figure>
<img src="images/img.png" alt="img.png" />
<figcaption aria-hidden="true">img.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="маршрутизация-1">Маршрутизация</h3>
<ul>
<li>Гибридный подход к маршрутизации.
<ul>
<li>Он сочетает механизмы маршрутизации и на стороне сервера, и на
стороне клиента:
<ul>
<li>Маршрутизацию на стороне сервера используют для начальной загрузки
страниц, для SEO и ускорить время рендеринга.</li>
<li>Клиентскую маршрутизацию используют во время взаимодействия с
пользователем.
<ul>
<li>Это обеспечивает плавные переходы и динамическое обновление контента
без полной перезагрузки страницы.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Динамическая обработка маршрутов:
<ul>
<li>У каждого микрофронтенда свой маршрутизатор.</li>
<li>Команды могут управлять логикой маршрутизации для своих
разделов.</li>
<li>Центральный оркестратор динамически загружает нужный микрофронтенд в
зависимости от навигации пользователя.
<ul>
<li>Оркестратор использует маршрутизатор на основе JavaScript для
интерпретации URL-адреса и получения нужного микрофронтенда.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="взаимодействие-на-основе-api-1">Взаимодействие на основе
API</h3>
<ul>
<li>Микрофронтенды должны взаимодействовать с бэкендом, а не напрямую
друг с другом
<ul>
<li>!!! между ними нет прямой коммуникации.</li>
<li>но эта стратегия не подойдёт, если вам нужно реактивно обновлять
компоненты одного микрофронтенда в ответ на изменение данных в
другом.</li>
</ul></li>
<li>Простой обмен данными.
<ul>
<li>если у приложения простые коммуникационные потребности, лучше
реализовать API</li>
</ul></li>
</ul>
<h3 id="паттерн-pubsub-1">Паттерн Pub/Sub</h3>
<ul>
<li><p>это паттерн проектирования, при котором компоненты системы
выступают в роли издателей (publisher) или подписчиков
(subscriber).</p></li>
<li><p>Event Bus (шина событий) — это система обмена сообщениями,
которая основана на паттерне Pub/Sub.</p>
<ul>
<li>События публикуют в шине событий.</li>
<li>Компоненты-подписчики регистрируются в шине и указывают список
событий, которые они хотят получать</li>
</ul></li>
<li><p>подойдет если:</p>
<ul>
<li>Предпочтительно несвязанное соединение, несвязанное взаимодействие
между микрофронтендами.</li>
<li>Архитектура, управляемая событиями (event-driven architecture, EDA).
<ul>
<li>действия или обновления в одной части приложения вызывают реакции в
других частях</li>
</ul></li>
<li>Независимое развёртывание.
<ul>
<li>микрофронтенды должны разворачиваться независимо друг от друга.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="библиотека-глобального-состояния-1">Библиотека глобального
состояния</h3>
<ul>
<li>Redux, MobX и Context API в React.</li>
<li>все части приложения синхронизируются и последовательно
взаимодействуют с пользователем.
<ul>
<li>Например, с помощью Redux можно реализовать паттерн Observable state
(наблюдаемое состояние)</li>
</ul></li>
<li>Когда использовать библиотеку глобального состояния
<ul>
<li>Тесная связь между разными частями приложения
<ul>
<li>несколько микрофронтендов читают из одного состояния и записывают в
него обновления.</li>
</ul></li>
<li>Важно поддерживать последовательный пользовательский опыт
<ul>
<li>несколько компонентов вашего интерфейса отражают состояние
аутентификации пользователя</li>
</ul></li>
<li>Сложные требования к управлению состояниями
<ul>
<li>пример, Онлайн-магазин.
<ul>
<li>Состояние корзины разделено между тремя микрофронтендами:
<ul>
<li>собственно, корзиной, списком товаров и оформлением заказа.</li>
</ul></li>
<li>Любое обновление должно немедленно отобразиться в нужной части
приложения.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Каждый микрофронтенд может подключаться к этому хранилищу —
обновлять общее состояние или реагировать на изменения.
<ul>
<li>независимо от React, Vue, Angular</li>
</ul></li>
</ul>
<p><img src="images/img_1.png" alt="img_1.png" /> - &gt; когда
приложение простое, используют коммуникацию через API. Каждый компонент
ходит в бэкенд за данными, которые нужны ему для работы. &gt; Если
достаточно обновлять в компонентах только одно конкретное значение,
команды подключают общую шину событий. Она реализует паттерн Pub/Sub.
&gt; нужны состояния более сложные, подключают библиотеку глобального
состояния типа Redux, MobX или NGRX. - микрофронтенды — не лучшее
решение - Приложение маленькое или простое - Ресурсы разработки
ограничены - Компоненты тесно связаны - краткосрочный проект или
прототип - жёсткие требования к производительности - Инфраструктура и
инструментарий ограничены</p>
<h3 id="domain-driven-design">Domain-Driven Design</h3>
<ul>
<li><p>предметно-ориентированное проектирование</p>
<ul>
<li>это подход к проектированию, который предполагает, что приложение
делят на домены (domain).</li>
<li>Они, в свою очередь, описывают разные цели бизнеса.</li>
</ul></li>
<li><p>по факту разделение по бизнес-функциям</p>
<ul>
<li>каждый домен есть модуль со своей функцией</li>
</ul></li>
<li><p>так же делим команды по бизнес-функциям</p></li>
<li><p>разработка программного обеспечения фокусируется на глубоком
понимании бизнес-домена и его модели</p></li>
<li><p>Цель микросервисной архитектуры — разбить приложение на множество
автономных сервисов, каждый из которых выполняет свою функцию</p></li>
<li><p>DDD предлагает методологию, чтобы определить, какие именно
микросервисы нужны и как они должны взаимодействовать.</p></li>
<li><p>Домен — это область знаний или деятельности, которая представляет
собой основную часть работы компании.</p>
<ul>
<li>В контексте DDD домен охватывает все понятия, связанные с данной
областью, и описывает её поведение и правила.</li>
<li>содержит несколько поддоменов</li>
</ul></li>
<li><p>Поддомен — это логически выделенная часть домена, которая
выполняет определённую функцию или решает конкретную задачу.</p></li>
<li><p>Контекст — это область, внутри которой определённые термины и
правила имеют чёткое значение.</p>
<ul>
<li>В DDD контексты помогают избежать путаницы, определяя границы
использования понятий.</li>
</ul></li>
</ul>
<h3 id="стратегическое-проектирование-1">Стратегическое
проектирование</h3>
<ul>
<li><p>На этом уровне определяется общая структура системы и
взаимодействие между различными частями домена.</p>
<ul>
<li>Основная задача — разделить систему на поддомены и очертить границы
контекстов.</li>
</ul></li>
<li><p>Bounded Context: определяет границы, в пределах которых
терминология и правила имеют чёткое значение.</p></li>
<li><p>Context Map: диаграмма, показывающая взаимодействие между
различными контекстами.</p></li>
<li><p>пример</p></li>
</ul>
<pre><code>
Домен: управление транспортом
  поддомен управления расписанием
    контекст: планирование расписания
    контекст: публикация расписания
  поддомен управления платежами
    контекст: обработка транзакций
    контекст: ведение журнала транзакций
Домен: продажа билетов
  поддомен обработки платежей
  поддомен управления пользователями
Домен: мониторинг транспорта
  поддомен отслеживания транспорта
  поддомен отчётности и аналитики

</code></pre>
<figure>
<img src="images/img_3.png" alt="img_3.png" />
<figcaption aria-hidden="true">img_3.png</figcaption>
</figure>
<h3 id="тактическое-проектирование-1">Тактическое проектирование</h3>
<ul>
<li>На этом уровне определяются детали реализации внутри каждого
контекста.
<ul>
<li>Основная задача — создать модель, которая точно отражает
бизнес-логику и поведение домена.</li>
</ul></li>
<li>Основные элементы:
<ul>
<li>Entities: объекты, которые имеют уникальный идентификатор и
состояние, изменяющееся со временем.</li>
<li>Value Objects: объекты, которые не имеют уникального идентификатора
и полностью определяются своими атрибутами.</li>
<li>Aggregates: группы связанных сущностей и объектов-значений, которые
обрабатываются как единое целое.</li>
<li>Repositories: интерфейсы для доступа к агрегатам из хранилища
данных.</li>
<li>Services: операции, которые не относятся к какой-либо сущности, но
важны для домена.</li>
</ul></li>
<li>пример</li>
</ul>
<pre><code>
Микросервис управления расписанием
  Контекст планирования расписания:
      сущности: расписание, маршрут;
      объекты-значения: время отправления, время прибытия;
      агрегаты: расписание;
      репозитории: репозиторий расписания;
      сервисы: сервис планирования расписания.
Микросервис обработки платежей
  Контекст обработки транзакций:
      сущности: транзакция, платёж;
      объекты-значения: сумма, валюта;
      агрегаты: транзакция;
      репозитории: репозиторий транзакций;
      сервисы: сервис обработки транзакций.

</code></pre>
<p><img src="images/img_4.png" alt="img_4.png" /> - &gt; Стратегическое
проектирование позволяет определить высокоуровневую структуру системы,
&gt; а тактическое проектирование — детализировать каждый контекст,
обеспечивая реализацию бизнес-логики.</p>
<h3 id="процесс-выделения-доменов-и-контекстов-1">Процесс выделения
доменов и контекстов</h3>
<p><img src="images/img_5.png" alt="img_5.png" /> - Шаг 1. Анализ
бизнеса и требований - информация о том, как работает компания, какие
задачи решает и какие проблемы у неё возникаю - Сбор и анализ
бизнес-требований и сценариев использования. - Определение основных
бизнес-целей и приоритетов.</p>
<ul>
<li>Шаг 2. Выделение доменов
<ul>
<li>Определение границ домена.</li>
<li>Идентификация основных функций и процессов внутри домена.</li>
<li>Документирование ключевых понятий и терминов, используемых в
домене.</li>
</ul></li>
<li>Шаг 3. Разделение на поддомены
<ul>
<li>Каждый домен может быть разбит на более мелкие логические части,
называемые поддоменами.</li>
<li>Поддомены фокусируются на конкретных функциях или задачах внутри
основного домена.</li>
<li>Идентификация поддоменов на основе функциональных требований.</li>
<li>Определение взаимодействий между поддоменами.</li>
<li>Документирование поддоменов и их границ.</li>
</ul></li>
<li>Шаг 4. Определение контекстов
<ul>
<li>Каждый поддомен может содержать один или несколько контекстов.</li>
<li>Определение границ контекстов внутри поддоменов.</li>
<li>Создание контекстных карт (Context Maps) для визуализации
взаимодействий.</li>
<li>Документирование терминов и правил внутри каждого контекста.</li>
</ul></li>
</ul>
<pre><code>
Пример
В поддомене управления расписанием в CityTransit контекстами могут быть контекст планирования расписания (с терминами «время отправления», «время прибытия»). 
Контекст публикации расписания (с терминами «публикация», «обновление расписания»).

</code></pre>
<ul>
<li>Шаг 5. Создание контекстных карт (Context Maps)
<ul>
<li>Контекстные карты визуализируют взаимодействие между различными
контекстами</li>
<li>Создание диаграмм, отображающих контексты и их взаимодействия.</li>
<li>Определение типов взаимодействий (например, интеграция,
антипаттерны).</li>
<li>Документирование зависимостей и договорённостей между контекстами.
<img src="images/img_6.png" alt="img_6.png" /></li>
</ul></li>
<li>Шаг 6. Итеративное уточнение
<ul>
<li>Регулярный пересмотр и обновление доменов и контекстов.</li>
<li>Внедрение изменений на основе обратной связи от пользователей и
команды.</li>
<li>Обеспечение согласованности между всеми частями системы.</li>
</ul></li>
</ul>
<h3 id="применение-ddd-в-работе-с-микросервисами-1">Применение DDD в
работе с микросервисами</h3>
<ul>
<li>ПРИМЕР</li>
</ul>
<pre><code>
На основе выделенных доменов, поддоменов и контекстов мы можем спроектировать соответствующие микросервисы. 
Рассмотрим, как это выглядит на примере CityTransit.

Управление транспортом: всё, что связано с планированием и управлением движением транспорта.
  Микросервис управления расписанием:
    Планирование расписания: микросервис, который отвечает за создание и изменение расписания.
    Публикация расписания: микросервис, который отвечает за распространение и обновление расписания для пользователей.
  Микросервис управления маршрутами:
    Управление маршрутами: микросервис, который управляет маршрутами транспортных средств и их оптимизацией.
Продажа билетов: всё, что связано с продажей и обработкой билетов.
  Микросервис обработки платежей:
    Обработка транзакций: микросервис, который отвечает за обработку платежей и интеграцию с платёжными системами.
    Ведение журнала транзакций: микросервис, который ведёт учёт всех транзакций и их состояния.
  Микросервис управления пользователями:
    Управление аккаунтами пользователей: микросервис, который отвечает за регистрацию, аутентификацию и управление данными пользователей.
Мониторинг транспорта: отслеживание местоположения и состояния транспортных средств.
  Микросервис отслеживания транспорта:
    Отслеживание местоположения: микросервис, который собирает и обрабатывает данные о местоположении транспортных средств.
    Аналитика состояния транспорта: микросервис, который анализирует данные о состоянии транспорта и генерирует отчёты.

</code></pre>
<p><img src="images/img_7.png" alt="img_7.png" /> - пример
микросервиса</p>
<pre><code>
Микросервис обработки платежей

Определение бизнес-требований:
  Обработка платежей за билеты.
  Поддержание различных способов оплаты (кредитные карты, электронные кошельки и так далее).
  Ведение журнала транзакций для отслеживания состояния платежей.
Проектирование микросервиса:
  Контекст обработки транзакций:
  API для приёма платёжных данных.
  Логика интеграции с платёжными шлюзами.
  Обработка статусов платежей (успех, отказ, возврат).
  Контекст ведения журнала транзакций:
  Хранение информации обо всех транзакциях.
  API для получения данных о транзакциях для отчётности и аналитики.
Реализация микросервиса:
  Разработка API для обработки транзакций.
  Интеграция с платёжными шлюзами.
  Реализация ведения журнала транзакций и предоставление данных для других сервисов (например, для микросервиса отчётности).

</code></pre>
<p><img src="images/img_8.png" alt="img_8.png" /> - Подход DDD
подразумевает, что для проектирования микросервисной архитектуры
совместно с бизнес-экспертами определяются области: - домены, которые
представляют собой основную часть работы компании. - поддомены —
выделенные части домена с определённой функцией или конкретной задачей.
- контексты — границы, очерчивающие правила и значения использования
терминов.</p>
<h2 id="основы-контейнеризации-микросервисов-1">Основы контейнеризации
микросервисов</h2>
<ul>
<li><p>Виртуальные машины (ВМ) — это виртуальные компьютеры, которые
используют ресурсы реального компьютера.</p>
<ul>
<li>Высокое потребление ресурсов.</li>
<li>Длительное время загрузки.</li>
<li>Трудоёмкое обновление. <img src="images/img_9.png"
alt="img_9.png" /></li>
</ul></li>
<li><p>Контейнеризация — это технология, которая позволяет упаковать
приложение и все его зависимости в единый изолированный контейнер.</p>
<ul>
<li>В отличие от виртуальных машин, контейнеры разделяют ядро
операционной системы и используют общие ресурсы — память и процессорное
время.</li>
<li>Благодаря этому они запускаются быстрее и потребляют меньше
ресурсов, чем виртуальные машины. <img src="images/img_10.png"
alt="img_10.png" /></li>
</ul></li>
<li><p>преимущества контейнеров:</p>
<ul>
<li>Эффективное использование ресурсов.
<ul>
<li>ВМ ест много ресурсов, потому что содержит полную операционную
систему. Контейнеры гораздо компактнее.</li>
</ul></li>
<li>Портативность
<ul>
<li>можно запускать на любой системе, где установлена контейнерная
платформа — например, Docker.</li>
</ul></li>
<li>консистентность. Каждый контейнер включает в себя всё, что нужно для
выполнения приложения:
<ul>
<li>код приложения, библиотеки и зависимости, системные инструменты,
которые нужны для выполнения задач внутри контейнера.</li>
</ul></li>
</ul></li>
<li><p>минусы.</p>
<ul>
<li>Степень изоляции в контейнерах ниже, чем в виртуальных машинах,
потому что они делят между собой часть ресурсов.</li>
</ul></li>
<li><p>ВМ стоит использовать, если</p></li>
<li><p>Вы запускаете корпоративные приложения, у которых высокие
требования к изоляции и безопасности.</p></li>
<li><p>Вы разрабатываете и тестируете приложения на разных операционных
системах и в разных конфигурациях.</p></li>
<li><p>Контейнеры стоит использовать, если</p>
<ul>
<li>Вы работаете с микросервисной архитектурой. Контейнеры обеспечат
достаточный уровень изоляции и портативность каждого микросервиса.</li>
<li>Вы строите конвейеры непрерывной интеграции и доставки (CI/CD),
чтобы обеспечить консистентность и высокую скорость развёртывания
приложений.</li>
<li>Вы развёртываете масштабируемые приложения и управляете ими. Если у
вас много микросервисов в продукте, контейнеры позволят легко
масштабировать их, обеспечивая гибкое и эффективное управление
нагрузкой.</li>
</ul></li>
</ul>
<h3 id="docker-1">Docker</h3>
<p><img src="images/img_11.png" alt="img_11.png" /> - Dockerfile — это
текстовый файл, который содержит набор инструкций для создания
Docker-образа. - Он определяет, какие базовые образы использовать, какие
установить зависимости и какие файлы скопировать. - А ещё — какие
команды нужно выполнить при запуске контейнера.</p>
<ul>
<li><p>Docker Image (образ) — это неизменяемый файл, который содержит
всё,</p>
<ul>
<li>что нужно для запуска приложения: код, зависимости, библиотеки,
окружение и настройки.</li>
<li>Образ создаётся на основе инструкций из Dockerfile.</li>
</ul></li>
<li><p>Docker Registry (реестр) — это централизованное хранилище
образов.</p>
<ul>
<li>Сам Docker предоставляет публичный реестр Docker Hub.</li>
</ul></li>
<li><p>Docker Container (контейнер) — это запущенный экземпляр
Docker-образа</p></li>
<li><p>Docker Volume (том) — это механизм для хранения данных. Тома
используют,</p>
<ul>
<li>чтобы хранить данные между перезапусками контейнеров и обеспечить
совместный доступ к данным для нескольких контейнеров.</li>
<li>Docker Network (сеть) — это виртуальная сеть, которая позволяет
контейнерам взаимодействовать друг с другом</li>
</ul></li>
</ul>
<h3 id="dockerfile-1">Dockerfile</h3>
<ul>
<li>FROM всегда идёт первой в файле, какой образ мы берём за основу.
<ul>
<li>FROM python:3.8-slim - официальный образ Python</li>
</ul></li>
<li>WORKDIR /app - рабочая директория</li>
<li>COPY . /app - копируем файлы</li>
<li>Установите зависимости - RUN pip install –no-cache-dir -r
requirements.txt</li>
<li>Определите команды для запуска приложения
<ul>
<li>CMD [“uvicorn”, “app:app”, “–host”, “0.0.0.0”, “–port”, “8000”]</li>
</ul></li>
</ul>
<h3 id="команды-docker-1">Команды Docker</h3>
<p><img src="images/img_12.png" alt="img_12.png" /> - docker build -
Команда создаёт Docker-образ из Dockerfile - docker build -t
quickdelivery/order-service .</p>
<ul>
<li><p>docker images - показывает все образы, которые вы загрузили на
свою машину или создали сами</p></li>
<li><p>docker run - команда запускает контейнер из Docker-образа</p>
<ul>
<li>docker run -d –name order-service -p 8000:8000
quickdelivery/order-service
<ul>
<li>d — запускает контейнер в фоновом режиме.</li>
<li>p 8000:8000 — перенаправляет порт 8000 на хосте на порт 8000 в
контейнере.</li>
<li>-name order-service — задаёт имя контейнеру.</li>
<li>quickdelivery/order-service — указывает образ, который нужно
использовать для создания контейнера.</li>
</ul></li>
</ul></li>
<li><p>docker ps - все активные контейнеры</p>
<ul>
<li>docker ps -a - активные и остановленные</li>
</ul></li>
<li><p>docker stop - останавливает работающий контейнер</p>
<ul>
<li>docker stop order-service</li>
</ul></li>
<li><p>docker rm - удалить контейнер после его остановки</p>
<ul>
<li>docker rm order-service</li>
</ul></li>
<li><p>docker rmi - удаляет Docker-образ</p>
<ul>
<li>docker rm order-service</li>
</ul></li>
<li><p>docker logs - отображает логи контейнера</p>
<ul>
<li>docker logs order-service</li>
</ul></li>
<li><p>docker exec - открыть интерактивную оболочку bash внутри
контейнера</p>
<ul>
<li>docker exec -it order-service /bin/bash</li>
</ul></li>
</ul>
<h3 id="оптимизация-dockerfile-1">Оптимизация Dockerfile</h3>
<ul>
<li>Используйте лёгкие базовые образы
<ul>
<li>например, Python:3.8-slim — это уже облегчённый вариант,
<ul>
<li>но можно использовать ещё более лёгкий образ Alpine.</li>
</ul></li>
</ul></li>
<li>Удаляйте временные файлы и кеш
<ul>
<li>Удаление временных файлов и кеша после установки пакетов помогает
уменьшить размер образа
<ul>
<li>RUN pip install –no-cache-dir -r requirements.txt &amp;&amp; apk del
gcc musl-dev linux-headers</li>
</ul></li>
</ul></li>
<li>Минимизируйте количество слоёв
<ul>
<li>Слой — это команда в Dockerfile, которая меняет содержимое образа.
<ul>
<li>Ввели три команды, получили — три слоя.</li>
</ul></li>
<li>Объедините команды RUN в один слой</li>
<li>RUN pip install -r requirements.txt &amp;&amp;<br />
</li>
<li>apt-get clean &amp;&amp;<br />
</li>
<li>rm -rf /var/lib/apt/lists/*</li>
</ul></li>
<li>Используйте многоступенчатую сборку
<ul>
<li>Многоступенчатая сборка позволяет использовать несколько базовых
образов
<ul>
<li>для создания оптимизированного конечного образа</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
FROM python:3.8-alpine as builder

WORKDIR /app

COPY . /app

RUN apk add --no-cache gcc musl-dev linux-headers &amp;&amp; \
    pip install --no-cache-dir -r requirements.txt

FROM python:3.8-alpine

WORKDIR /app

COPY --from=builder /app /app

CMD [&quot;python&quot;, &quot;app.py&quot;] 


</code></pre>
<h3 id="расширенная-контейнеризация-и-docker-compose-1">Расширенная
контейнеризация и Docker Compose</h3>
<ul>
<li><p>Docker Compose — это инструмент для определения и запуска
многоконтейнерных Docker-приложений</p></li>
<li><p>Основные сущности Docker Compose</p>
<ul>
<li>Services (Сервисы) -
<ul>
<li>отдельные контейнеры, которые нужно запускать.</li>
<li>Сервисы могут зависеть друг от друга и взаимодействовать между
собой</li>
</ul></li>
<li>Networks (Сети)
<ul>
<li>По умолчанию, Docker Compose создаёт отдельную сеть для каждого
проекта,
<ul>
<li>но вы можете определить собственные сети и подключать контейнеры к
ним.</li>
</ul></li>
</ul></li>
<li>Volumes (Тома)
<ul>
<li>используются для хранения данных, которые должны сохраняться между
перезапусками контейнеров</li>
<li>могут быть определены в файле docker-compose.yml и подключены к
контейнерам для обеспечения долговременного хранения данных</li>
</ul></li>
</ul></li>
<li><p>Переменные окружения в Docker Compose</p>
<ul>
<li>позволяют настраивать контейнеры без изменения их конфигурации</li>
<li>задавать в самом файле docker-compose.yml или в отдельном файле
.env.</li>
</ul></li>
<li><p>пример</p>
<ul>
<li>services - Описывает сервисы.</li>
<li>order-service - Сервис обработки заказов.
<ul>
<li>build Указывает на текущую директорию для сборки Docker-образа.</li>
<li>ports - Перенаправление порта 5000 на хосте на порт 5000 в
контейнере.</li>
<li>environment - Переменные окружения, используемые сервисом. В данном
случае, мы задаём URL для подключения к базе данных.</li>
<li>depends_on - Указывает на зависимость от сервиса базы данных.</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
version: &#39;3.8&#39;

services:
  order-service:
    build: ./order-service
    container_name: order-service
    ports:
      - &quot;5000:5000&quot;
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/orders
    depends_on:
      - db

  logistics-service:
    build: ./logistics-service
    container_name: logistics-service
    ports:
      - &quot;5001:5001&quot;
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/logistics
    depends_on:
      - db

  db:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: orders
    ports:
      - &quot;5432:5432&quot;
      

</code></pre>
<ul>
<li>Запуск сервисов с помощью Docker Compose
<ul>
<li>docker-compose up –build</li>
<li>docker-compose down</li>
</ul></li>
<li>используем:
<ul>
<li>env для переменных .env POSTGRES_PASSWORD=mysecretpassword</li>
<li>volumes директория для сохранения состояния</li>
</ul></li>
</ul>
<pre><code>
logistics-service:
    build: ./logistics-service
    container_name: logistics-service
    ports:
      - &quot;5001:5001&quot;
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@db:5432/logistics
    depends_on:
      - db
    networks:
      - quickdelivery-network

  db:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: orders
    ports:
      - &quot;5432:5432&quot;
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - quickdelivery-network

networks:
  quickdelivery-network:
    driver: bridge

volumes:
  postgres-data: 
  

</code></pre>
<ul>
<li>по умолчанию, Docker Compose создаёт отдельную сеть для каждого
проекта</li>
<li>Проверка логов контейнеров
<ul>
<li>все контейнеры docker-compose logs</li>
<li>определенный контейнер - docker-compose logs order-service</li>
</ul></li>
<li>подключение к БД
<ul>
<li>psql -h localhost -U postgres -d orders</li>
</ul></li>
</ul>
<h2 id="принципы-12-факторных-приложений-1">Принципы 12-факторных
приложений</h2>
<p><img src="images/img_13.png" alt="img_13.png" /> - разница между
платформ-ориентированными, контейнеризацией и оркестрации <img
src="images/img_14.png" alt="img_14.png" /> - когда и что применять <img
src="images/img_15.png" alt="img_15.png" /></p>
<h3 id="реализация-12-факторных-приложений-1">Реализация 12-факторных
приложений</h3>
<ul>
<li>Кодовая база (Codebase)
<ul>
<li>Проблема:
<ul>
<li>Кодовая база разбита на несколько репозиториев для различных
компонентов системы,
<ul>
<li>что усложняет развёртывание и управление версиями.</li>
</ul></li>
</ul></li>
<li>Решение:
<ul>
<li>Объединить кодовую базу в едином репозитории и обеспечить
использование одной и той же кодовой базы
<ul>
<li>для всех окружений (разработка, тестирование, продакшн).</li>
</ul></li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Каждое приложение должно иметь одну кодовую базу, отслеживаемую в
системе контроля версий, и множество развёртываний.</p>
</blockquote></li>
<li>Зависимости (Dependencies)
<ul>
<li>Проблема:
<ul>
<li>Зависимости неявно указаны в конфигурационных файлах, что затрудняет
установку и обновление.</li>
</ul></li>
<li>Решение:
<ul>
<li>Явно указать все зависимости в манифестах, таких как
requirements.txt или pom.xml,
<ul>
<li>и автоматизировать их установку при развёртывании.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Конфигурация (Config)
<ul>
<li>Проблема:
<ul>
<li>Конфигурация хранится в коде и требует изменений в коде для
настройки, что усложняет процесс развёртывания.</li>
</ul></li>
<li>Решение:
<ul>
<li>Перенести конфигурационные параметры в переменные окружения, чтобы
настройки можно было изменять без изменения кода.</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Конфигурация приложения должна храниться в переменных окружения, а не
в коде.</p>
</blockquote></li>
<li>Сторонние службы (Backing Services)
<ul>
<li>Проблема:
<ul>
<li>Приложение жёстко связано с конкретными реализациями бэкенд-сервисов
(например, база данных, кэш), что затрудняет замену или обновление
сервисов.</li>
</ul></li>
<li>Решение:
<ul>
<li>Рассматривать все бэкенд-сервисы как прикреплённые ресурсы, которые
можно легко заменить или обновить без изменения кода приложения.</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Все сторонние службы должны рассматриваться как внешние сервисы,
которые могут быть легко заменены.</p>
</blockquote></li>
<li><blockquote>
<p>Все бэкенд-сервисы (базы данных, кэши, очереди сообщений) могут быть
легко заменены.</p>
</blockquote></li>
<li><blockquote>
<p>Приложение не зависит жёстко от конкретных реализаций сервисов</p>
</blockquote></li>
<li>Сборка, выпуск, запуск (Build, Release, Run)
<ul>
<li>Проблема:
<ul>
<li>Процессы сборки, выпуска и запуска не разделены, что приводит к
путанице и ошибкам при развёртывании.</li>
</ul></li>
<li>Решение:
<ul>
<li>Ясно разделить процессы сборки, выпуска и запуска, гарантируя, что
каждый выпуск неизменяем и содержит все необходимые зависимости и
конфигурации.</li>
</ul></li>
</ul></li>
<li>Процессы (Processes)
<ul>
<li>Проблема:
<ul>
<li>Процессы состояния приложения сохраняют данные внутри процесса, что
затрудняет масштабирование и перезапуск.</li>
</ul></li>
<li>Решение:
<ul>
<li>Сделать процессы stateless и хранить данные вне процессов в
постоянных хранилищах.</li>
</ul></li>
<li>Например:
<ul>
<li>В QuickDelivery все данные сохраняются в базах данных и других
постоянных хранилищах.</li>
<li>Сами процессы приложения не зависят от локального состояния и могут
быть перезапущены в любое время без потери данных.</li>
</ul></li>
</ul></li>
<li>Порт привязки (Port Binding)
<ul>
<li>Проблема:
<ul>
<li>Приложение требует внешнего веб-сервера для обработки запросов, что
усложняет развёртывание и управление.</li>
</ul></li>
<li>Решение:
<ul>
<li>Экспортировать HTTP-сервис через привязку к порту, чтобы приложение
было самодостаточным.</li>
<li>Приложение должно быть самодостаточным и не зависеть от внешнего
веб-сервера.</li>
</ul></li>
</ul></li>
<li>Конкурентные процессы (Concurrency)
<ul>
<li>Проблема:
<ul>
<li>Приложение не поддерживает масштабирование путём запуска нескольких
процессов или потоков, что ограничивает его производительность.</li>
</ul></li>
<li>Решение:
<ul>
<li>Поддерживать запуск множества процессов или потоков для
масштабирования и эффективного использования ресурсов.</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Приложение должно уметь масштабироваться путём запуска множества
процессов или потоков.</p>
</blockquote></li>
<li>Утилизируемость (Disposability)
<ul>
<li>Проблема:
<ul>
<li>Процессы не могут быть быстро перезапущены или остановлены, что
затрудняет масштабирование и обновление.</li>
</ul></li>
<li>Решение:
<ul>
<li>Обеспечить возможность быстрого запуска и остановки процессов, а
также лёгкость масштабирования в зависимости от нагрузки.</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Процессы должны быть лёгкими для запуска и остановки.</p>
</blockquote></li>
<li>Среды разработки и эксплуатации (Dev/Prod Parity)
<ul>
<li>Проблема:
<ul>
<li>Среда разработки существенно отличается от среды эксплуатации, что
приводит к неожиданным проблемам при развёртывании.</li>
</ul></li>
<li>Решение:
<ul>
<li>Сделать среду разработки максимально приближенной к среде
эксплуатации, используя одинаковые инструменты и процессы.</li>
</ul></li>
<li>Среда разработки должна максимально приближаться к среде
эксплуатации.</li>
</ul></li>
<li>Логи (Logs)
<ul>
<li>Проблема:
<ul>
<li>Логи приложения хранятся в файлах, что затрудняет их сбор и
анализ.</li>
</ul></li>
<li>Решение:
<ul>
<li>Писать логи в стандартный вывод (stdout) и использовать инструменты
для их сбора и анализа.</li>
<li>Приложение должно писать свои логи в stdout.</li>
</ul></li>
</ul></li>
<li>Административные процессы (Admin Processes)
<ul>
<li>Проблема:
<ul>
<li>Административные задачи выполняются вручную и не являются
одноразовыми процессами.</li>
</ul></li>
<li>Решение:
<ul>
<li>Выполнять административные задачи как одноразовые процессы,
запускаемые в той же среде, что и основное приложение.</li>
</ul></li>
<li>Например:
<ul>
<li>Миграции баз данных и другие административные задачи в QuickDelivery
<ul>
<li>запускаются как одноразовые процессы в той же среде, что и основное
приложение.</li>
</ul></li>
<li>Это обеспечивает консистентность и упрощает управление
системой.</li>
</ul></li>
</ul></li>
</ul>
<h2
id="документирование-решений-с-помощью-диаграмм-c4-1">Документирование
решений с помощью диаграмм C4</h2>
<ul>
<li>нотации и подходы <img src="images/img_16.png"
alt="img_16.png" /></li>
</ul>
<h3 id="модель-c4-1">Модель C4</h3>
<ul>
<li>4 уровня абстракции
<ul>
<li>контекст, контейнер, компонент, код</li>
</ul></li>
<li>не всегда нужно использовать эту модель
<ul>
<li>можно только часть <img src="images/img_17.png"
alt="img_17.png" /></li>
</ul></li>
</ul>
<h3 id="context-diagrams-диаграммы-контекста-1">Context diagrams —
диаграммы контекста</h3>
<ul>
<li>как система выглядит целиком</li>
<li>Диаграмма предоставляет общий обзор системы и её границ.
<ul>
<li>показывает систему в окружении, выделяя основные внешние системы и
пользователей, которые взаимодействуют с ней.</li>
</ul></li>
<li>применяют
<ul>
<li>бизнес-аналитики</li>
<li>проект-менеджеры</li>
<li>архитекторы <img src="images/img_18.png" alt="img_18.png" /></li>
</ul></li>
<li>диаграмма контекста <img src="images/img_20.png"
alt="img_20.png" /></li>
</ul>
<h3 id="диаграмма-контейнеров-container-diagram-1">Диаграмма контейнеров
— Container diagram</h3>
<ul>
<li><p>Так в C4 называют приложения и хранилища данных.</p></li>
<li><p>Диаграммы контейнеров показывают высокоуровневые технические
строительные блоки и взаимодействия между ними <img
src="images/img_19.png" alt="img_19.png" /></p></li>
<li><p>применяют</p>
<ul>
<li>разработчики</li>
<li>devops</li>
<li>архитекторы</li>
</ul></li>
<li><p>диаграмма контейнера <img src="images/img_21.png"
alt="img_21.png" /></p></li>
</ul>
<h3 id="диаграмма-компонентов-component-diagram-1">Диаграмма компонентов
— Component diagram</h3>
<ul>
<li>уровень отдельного контейнера и показывают компоненты внутри него.
<ul>
<li>как эти компоненты взаимодействуют друг с другом.</li>
</ul></li>
<li>применяют
<ul>
<li>разработчики</li>
<li>тестировщики</li>
<li>архитекторы <img src="images/img_22.png" alt="img_22.png" /></li>
</ul></li>
<li>легенда диаграммы контейнера <img src="images/img_23.png"
alt="img_23.png" /></li>
</ul>
<h3 id="диаграмма-кода-codeclasses-diagram-1">Диаграмма кода —
Code/classes diagram</h3>
<ul>
<li>как реализован отдельный компонент.
<ul>
<li>отображает структуру кода в рамках одного из компонентов</li>
</ul></li>
<li>применяют
<ul>
<li>разработчики</li>
<li>тестировщики</li>
<li>архитекторы <img src="images/img_24.png" alt="img_24.png" /></li>
</ul></li>
</ul>
<h3 id="диаграммы-последовательностей-dynamic-diagrams-1">Диаграммы
последовательностей — Dynamic diagrams</h3>
<ul>
<li>дополнительная
<ul>
<li>у меня так используется</li>
<li>показывает взаимодействие объектов в определённом временном порядке,
<ul>
<li>акцентируя внимание на порядке сообщений между объектами.</li>
</ul></li>
</ul></li>
<li>применяют - архитекторам НЕ НУЖНО
<ul>
<li>разработчики</li>
<li>тестировщики</li>
<li>Бизнес-аналитики <img src="images/img_25.png"
alt="img_25.png" /></li>
</ul></li>
<li>легенда диаграммы последоватльеностей <img src="images/img_26.png"
alt="img_26.png" /></li>
</ul>
<h3 id="диаграммы-развёртывания-deployment-diagrams-1">Диаграммы
развёртывания — Deployment diagrams</h3>
<ul>
<li>физическое размещение программных артефактов на узлах развёртывания.
<img src="images/img_27.png" alt="img_27.png" /></li>
<li>применяют - архитекторам НЕ НУЖНО
<ul>
<li>архитекторы</li>
<li>devops</li>
<li>Системные администраторы</li>
</ul></li>
</ul>
<h3 id="как-создавать-диаграммы-c4-1">Как создавать диаграммы C4</h3>
<ul>
<li>Диаграммы C4 создают в пять шагов <img src="images/img_28.png"
alt="img_28.png" /></li>
<li>Соберите требования и определите границы системы
<ul>
<li>Определите основные функции и компоненты системы.</li>
<li>Определите внешние системы и пользователей, которые будут
взаимодействовать с вашей системой.</li>
</ul></li>
</ul>
<pre><code>
Например, FitLife — это система управления фитнес-клубом. 
Она автоматизирует процессы управления членством, расписанием занятий, обработки платежей и интеграции с внешними системами.
Система включает в себя веб-приложение и мобильное приложение для пользователей, 
административный интерфейс для управления, а также разные службы для обработки данных и взаимодействия с внешними API и банковскими системами.

</code></pre>
<ul>
<li>Создайте диаграмму контекста
<ul>
<li>Опишите вашу систему и её окружение.</li>
<li>Укажите внешние системы и пользователей, которые взаимодействуют с
вашей системой.</li>
</ul></li>
</ul>
<pre><code>
На диаграмме контекста нужно показать такие элементы:
User — пользователь системы фитнес-клуба, который управляет своим членством и расписанием занятий с помощью функционала системы.
Administrator — администратор, управляющий системой и осуществляющий поддержку пользователей.
FitLife System — основная система, которая управляет членством, расписанием занятий и обработкой платежей.
Third-Party API — внешний API для интеграции данных о фитнесе.
Bank System — внешняя банковская система для обработки платежей.

</code></pre>
<ul>
<li><blockquote>
<p>Все диаграммы сделаны с помощью PlantUML.</p>
</blockquote></li>
<li><blockquote>
<p>Вы создаёте текстовое описание системы, а инструмент отрисовывает по
нему диаграмму. <img src="images/img_29.png" alt="img_29.png" /></p>
</blockquote></li>
<li>Создайте диаграмму контейнеров
<ul>
<li>Определите основные контейнеры внутри вашей системы. В C4 контейнеры
— это приложения и хранилища данных.</li>
<li>Покажите взаимодействие между контейнерами и внешними
системами.</li>
</ul></li>
</ul>
<pre><code>
На диаграмме контейнера нужно показать:
Web Application — веб-приложение, реализованное на Java с использованием Spring. Оно обрабатывает взаимодействие с пользователем.
Mobile Application — мобильное приложение, реализованное на Kotlin и Swift. Оно позволяет пользователям управлять своим членством.
Payment Service — сервис для обработки платежей, реализованный на Node.js.
Database — база данных на PostgreSQL, хранящая информацию о пользователях и расписании занятий.
Third-Party API — внешний API для интеграции данных о фитнесе.
Bank System — внешняя банковская система для обработки платежей.

</code></pre>
<p><img src="images/img_30.png" alt="img_30.png" /> - Создайте диаграмму
компонентов - Выберите один из контейнеров и детализируйте его
внутреннюю структуру. - Определите основные компоненты внутри контейнера
и их взаимодействие.</p>
<pre><code>
На диаграмме компонентов нужно показать:
AuthController — компонент, который обрабатывает аутентификацию и авторизацию пользователей.
UserController — компонент, который управляет профилями пользователей.
ScheduleController — компонент, который управляет расписаниями занятий.
PaymentController — компонент, который обрабатывает платежи.
Service Layer — слой бизнес-логики.
Repository Layer — слой доступа к данным.

</code></pre>
<p><img src="images/img_31.png" alt="img_31.png" /> - Создайте диаграмму
кода - Детализируйте код одного из компонентов. - Покажите основные
классы или файлы и их взаимодействие.</p>
<pre><code>
На диаграмме нужно показать:
User — класс, который представляет пользователя системы. У него есть атрибуты name и email. А ещё методы — register() и login().
Membership — класс, который представляет членство пользователя. Его атрибуты — type, startDate и endDate. Его методы — activate() и cancel().
Schedule — класс, который представляет расписание занятий. Его атрибуты — date и activity. Его методы — addActivity() и removeActivity().

</code></pre>
<figure>
<img src="images/img_32.png" alt="img_32.png" />
<figcaption aria-hidden="true">img_32.png</figcaption>
</figure>
<h3 id="анализ-и-интерпретация-диаграмм-c4-1">Анализ и интерпретация
диаграмм C4</h3>
<ul>
<li>Метод 1. Проверьте полноту и ясность
<ul>
<li>Убедитесь, что все основные элементы системы и их взаимодействия
отражены на диаграммах.</li>
<li>Проверьте, что диаграммы понятны всем стейкхолдерам, включая тех,
кто не имеет технического образования.</li>
<li>Нужно убедиться, что все основные контейнеры (WebApp, MobileApp,
PaymentService и Database) отображены на диаграмме и что взаимодействия
между ними тоже показаны.</li>
</ul></li>
<li>Метод 2. Выявите узкие места и потенциальные проблемы
<ul>
<li>Определите компоненты, которые могут стать узкими местами. Например,
контейнеры с высокой нагрузкой.</li>
<li>Оцените взаимодействия между компонентами на предмет потенциальных
проблем — например, задержек или сбоев в коммуникации.</li>
</ul></li>
</ul>
<pre><code>
Диаграмма контекста FitLife.
 Нужно понять, насколько система зависит от внешних API и банковских сервисов могут ли сбои в API или банковской системе негативно повлиять на работу всей системы.
Диаграмма контейнеров FitLife. 
 Нужно оценить нагрузку на PaymentService и Database. 
 Высокая частота запросов к базе данных или к сервису обработки платежей может создать узкое место.
Диаграмма компонентов FitLife.
  Нужно проверить, что компоненты AuthController и PaymentController содержат необходимые меры безопасности для защиты данных пользователей и обработки платежей.
Диаграмма кода FitLife. 
 Нужно оценить, насколько сложное взаимодействие между классами, 
 - и определить методы, которые могут стать узкими местами при высоких нагрузках.


</code></pre>
<ul>
<li>Метод 3. Проанализируйте безопасность
<ul>
<li>Проверьте диаграммы на предмет потенциальных уязвимостей, связанных
с доступом к данным и авторизацией пользователей.</li>
<li>Убедитесь, что критически важные компоненты защищены
соответствующими механизмами безопасности.</li>
</ul></li>
</ul>
<pre><code>
Диаграмма контекста FitLife.
 Нужно проверить, что взаимодействие с банковской системой и API защищено и данные передаются по защищённым каналам.
Диаграмма контейнеров FitLife. 
 Нужно проверить, что взаимодействия между WebApp, MobileApp и PaymentService защищены.
 Убедитесь, что данные пользователей в базе данных шифруются.
Диаграмма компонентов FitLife. 
 Нужно убедиться, что компоненты AuthController и PaymentController содержат необходимые меры безопасности для защиты данных пользователей и обработки платежей.
Диаграмма кода FitLife. 
 Нужно проверить, что классы, связанные с обработкой данных пользователей и платежей, содержат необходимые меры безопасности.

</code></pre>
<ul>
<li>Метод 4. Оцените масштабируемость
<ul>
<li>Определите, какие компоненты системы могут требовать масштабирования
при увеличении нагрузки.</li>
<li>Оцените возможности горизонтального и вертикального масштабирования
компонентов.</li>
</ul></li>
</ul>
<h3 id="как-улучшать-диаграммы-c4-на-основе-обратной-связи-1">Как
улучшать диаграммы C4 на основе обратной связи</h3>
<ul>
<li><p>Метод 1. Ревью команды</p></li>
<li><p>Метод 2. Вовлекайте стейкхолдеров</p>
<ul>
<li>Проводите презентации диаграмм для бизнес-экспертов и
стейкхолдеров.</li>
<li>Собирайте их мнения о том, насколько диаграммы понятны и какие
аспекты можно улучшить.</li>
</ul></li>
<li><p>Метод 3. Используйте инструменты для комментариев</p>
<ul>
<li>Поощряйте команду оставлять свои замечания и предложения прямо на
диаграммах</li>
</ul></li>
<li><p>Метод 4. Анализируйте инциденты и проблемы</p>
<ul>
<li>Обновляйте диаграммы, чтобы учитывать полученные уроки и
улучшения.</li>
<li>Нужно анализировать возникшие инциденты и проблемы в системе для
выявления недостатков в архитектуре</li>
</ul></li>
</ul>
<h2
id="подход-documentation-as-code-с-помощью-plantuml-и-mkdocs-1">Подход
documentation as code с помощью PlantUML и MKDocs</h2>
<ul>
<li>инструменты PlantUML и MkDocs для создания и поддержания
документации,
<ul>
<li>которая всегда будет актуальной и синхронизированной с вашим
проектом</li>
<li>хранить и поддерживать документацию в тех же системах контроля
версий, что и исходный код</li>
</ul></li>
<li><blockquote>
<p>Документация как код (Documentation as Code) — это подход, при
котором документация создаётся, обновляется и управляется так же, как и
исходный код</p>
</blockquote></li>
</ul>
<h3 id="работа-с-plantuml-1">Работа с PlantUML</h3>
<ul>
<li>позволяет создавать с помощью простого текстового формата различные
диаграммы
<ul>
<li>для документирования архитектуры и дизайна программного
обеспечения.</li>
</ul></li>
<li>можно автоматизировать создание диаграмм, интегрируя его в процесс
сборки и развёртывания.
<ul>
<li>Это позволяет поддерживать документацию в актуальном состоянии</li>
</ul></li>
<li>поддерживает создание различных типов диаграмм, включая диаграммы
классов, последовательностей, состояний, развёртывания
<ul>
<li>и, конечно же, C4-модель</li>
</ul></li>
<li>C4-модель и PlantUML
<ul>
<li>это два различных подхода к визуализации архитектуры программного
обеспечения,</li>
<li>которые могут быть использованы вместе или независимо друг от
друга</li>
</ul></li>
<li>C4-модель
<ul>
<li>Это подход к описанию архитектуры системы, которая включает четыре
уровня абстракции: диаграммы контекста, контейнера, компонента и
кода.</li>
<li>C4-модель определяет, что должно быть отображено на каждом уровне
диаграммы и как эти уровни взаимодействуют между собой.</li>
<li>Чёткая и понятная структура для различных уровней абстракции,
построенная по C4-модели, помогает эффективно общаться как с
техническими специалистами, так и с бизнес-экспертами.</li>
</ul></li>
<li>PlantUML
<ul>
<li>Это инструмент для создания диаграмм на основе текстового
описания.</li>
<li>Он поддерживает множество типов диаграмм, включая те, которые
используются в C4-модели.</li>
<li>PlantUML позволяет автоматически генерировать диаграммы, что
упрощает их создание и обновление.</li>
<li>PlantUML можно использовать для реализации диаграмм C4, импортируя
соответствующие шаблоны.</li>
</ul></li>
<li>процесс установки и настройки PlantUML в среде разработки JetBrains
IDE</li>
<li>Инструкция по установке и настройке PlantUML в JetBrains IDE</li>
</ul>
<pre><code>
Откройте вашу JetBrains IDE. Запустите IntelliJ IDEA, PyCharm, WebStorm или любую другую IDE от JetBrains.

Откройте настройки IDE. Перейдите в меню File и выберите Settings (или используйте сочетание клавиш Ctrl+Alt+S).

Установите плагин PlantUML.
 В настройках перейдите в раздел Plugins. В строке поиска введите «PlantUML» и найдите соответствующий плагин. 
 Нажмите Install для установки плагина. После установки плагина перезапустите IDE, чтобы изменения вступили в силу.
PlantUML требует установки Java для работы.
 Убедитесь, что у вас установлена последняя версия JDK (Java Development Kit).

</code></pre>
<ul>
<li>PlantUML использует Graphviz для генерации диаграмм.
<ul>
<li>Убедитесь, что Graphviz установлен на вашем компьютере.</li>
<li>Скачайте Graphviz с официального сайта и установите его, следуя
инструкциям.</li>
</ul></li>
<li>Создайте новый файл для PlantUML. В вашей IDE создайте новый файл с
расширением .puml или .plantuml.</li>
</ul>
<pre><code>
@startuml
Alice -&gt; Bob: Hello
@enduml

</code></pre>
<h3 id="создание-диаграмм-в-plantuml-1">Создание диаграмм в
PlantUML</h3>
<ul>
<li>Диаграммы классов используются для отображения структуры классов в
системе, их атрибутов, методов и взаимосвязей</li>
</ul>
<pre><code>
Пример набора классов:
  User — класс, представляющий пользователя, с атрибутами name, email и списком членств.
  Membership — класс, представляющий членство, с атрибутами type, startDate, endDate и методами activate(), cancel().
  Schedule — класс, представляющий расписание, с атрибутами date, activity и методами addActivity(), removeActivity().
  Payment — класс, представляющий платежи, с атрибутами double amount, date и методом processPayment().

</code></pre>
<ul>
<li>пример проекта</li>
</ul>
<pre><code>
FitLife/
├── .gitignore
├── README.md
├── diagrams/
│   ├── context/
│   │   └── FitLife_Context.puml
│   ├── container/
│   │   └── FitLife_Container.puml
│   ├── component/
│   │   └── FitLife_Component_WebApp.puml
│   └── code/
│       └── FitLife_Code_Membership.puml
└── src/
    ├── main/
    │   └── ...
    └── test/
        └── ...
        
.gitignore: файл для указания файлов и директорий, которые должны быть проигнорированы Git.
README.md: файл с описанием проекта, содержащий основную информацию и инструкции.
diagrams/: директория для хранения всех диаграмм C4.
context/: поддиректория для диаграмм контекста.
FitLife_Context.puml: диаграмма контекста для системы FitLife.
container/: поддиректория для диаграмм контейнеров.
FitLife_Container.puml: диаграмма контейнера для системы FitLife.
component/: поддиректория для диаграмм компонентов.
FitLife_Component_WebApp.puml: диаграмма компонентов для веб-приложения FitLife.
code/: поддиректория для диаграмм кода.
FitLife_Code_Membership.puml: диаграмма кода для компонента управления членством FitLife.
src/: директория для хранения исходного кода проекта.
main/: поддиректория для основного кода приложения.
test/: поддиректория для тестов.

</code></pre>
<ul>
<li>Автоматизация создания диаграмм с помощью PlantUML
<ul>
<li>Пример файла workflow для GitHub Actions
<ul>
<li>.github/workflows/plantuml.yml</li>
</ul></li>
<li>Этот файл настроит GitHub Actions для автоматической генерации
диаграмм PlantUML
<ul>
<li>и коммита их обратно в репозиторий при каждом изменении в ветке
main</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
name: PlantUML Diagrams

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  generate-diagrams:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Java
      uses: actions/setup-java@v2
      with:
        java-version: &#39;11&#39;

    - name: Install PlantUML
      run: sudo apt-get install plantuml

    - name: Generate Diagrams
      run: |
        plantuml diagrams/context/*.puml
        plantuml diagrams/container/*.puml
        plantuml diagrams/component/*.puml
        plantuml diagrams/code/*.puml

    - name: Commit Diagrams
      run: |
        git config --local user.email &quot;github-actions[bot]@users.noreply.github.com&quot;
        git config --local user.name &quot;github-actions[bot]&quot;
        git add diagrams/**/*.png
        git commit -m &quot;Automated diagram generation&quot;
        git push origin main
      if: success()

</code></pre>
<h3 id="интеграция-plantuml-с-mkdocs-1">Интеграция PlantUML с
MkDocs</h3>
<ul>
<li><p>MkDocs — это статический генератор сайтов, предназначенный для
создания документации из файлов Markdown.</p></li>
<li><p>Он прост в использовании, имеет множество тем оформления и легко
интегрируется с системами контроля версий, такими как Git.</p></li>
<li><p>MkDocs можно установить с помощью менеджера пакетов pip</p>
<ul>
<li>pip install mkdocs</li>
<li>mkdocs –version</li>
</ul></li>
<li><p>Перейдите в директорию вашего проекта и выполните команду для
создания нового проекта MkDocs:</p>
<ul>
<li>mkdocs new docs</li>
<li>Эта команда создаст новую директорию docs с базовой структурой
проекта.</li>
</ul></li>
</ul>
<pre><code>
site_name: FitLife Documentation
theme: readthedocs
markdown_extensions:
  - md_in_html
  - plantuml_markdown
plugins:
  - search

</code></pre>
<ul>
<li>Организуйте структуру документации.</li>
</ul>
<pre><code>
docs/
├── index.md
├── architecture/
│   ├── context.md
│   ├── container.md
│   ├── component.md
│   └── code.md
└── mkdocs.yml

</code></pre>
<ul>
<li>Установите плагин mkdocs-plantuml для интеграции PlantUML с MkDocs.
<ul>
<li>pip install mkdocs-plantuml</li>
<li>pip install mkdocs_puml</li>
<li>pip install plantuml-markdown</li>
</ul></li>
<li>Добавьте плагин plantuml в файл mkdocs.yml:</li>
</ul>
<pre><code>
plugins:
    - plantuml:
        puml_url: https://www.plantuml.com/plantuml/ 

</code></pre>
<ul>
<li>Создайте диаграмму PlantUML в Markdown. Для этого вставьте код
PlantUML в файлы Markdown с использованием блока кода plantuml:</li>
</ul>
<pre><code>
  здесь три ковычки верхние puml
  @startuml
  title FitLife Context Diagram
  
  top to bottom direction
  
  !includeurl https://raw.githubusercontent.com/RicardoNiepel/C4-PlantUML/master/C4_Component.puml
  
  Person(user, &quot;User&quot;, &quot;A user of the fitness club system&quot;)
  Person(admin, &quot;Administrator&quot;, &quot;An administrator managing the system&quot;)
  System(FitLifeSystem, &quot;FitLife System&quot;, &quot;System managing memberships, schedules, and payments&quot;)
  
  System_Ext(api, &quot;Third-Party API&quot;, &quot;External API for fitness data integration&quot;, &quot;Uses REST API, JSON data format&quot;)
  System_Ext(bank, &quot;Bank System&quot;, &quot;External bank for processing payments&quot;, &quot;Uses SOAP, XML data format&quot;)
  Rel(user, FitLifeSystem, &quot;Uses the system&quot;)
  Rel(admin,FitLifeSystem,&quot;Manages the system&quot;)
  Rel(FitLifeSystem,api,&quot;Fetches fitness data&quot;)
  Rel(FitLifeSystem,bank,&quot;Processes payments&quot;)
  
  @enduml
  
  здесь три ковычки верхние

</code></pre>
<ul>
<li>Для предварительного просмотра документации запустите локальный
сервер MkDocs:
<ul>
<li>mkdocs serve</li>
</ul></li>
<li>Откройте браузер и перейдите по адресу http://127.0.0.1:8000</li>
<li>Для генерации статического сайта выполните команду:
<ul>
<li>mkdocs build</li>
</ul></li>
</ul>
<h2 id="as-is-и-to-be-1">As-Is и To-be</h2>
<ul>
<li>As is («Как есть») и To be («Как должно быть»)
<ul>
<li>это модели для описания бизнес-процессов, которые помогают понять
текущие процессы и определить, как их улучшить.</li>
</ul></li>
<li>Сравнение моделей As is и To be позволяет выявить разницу между
текущим и будущим состоянием компании.
<ul>
<li>Это помогает определить, какие изменения необходимо провести, чтобы
достичь желаемого результата.</li>
</ul></li>
</ul>
<h3 id="as-is-1">As-Is</h3>
<ul>
<li>As is представляет собой текущее состояние процессов.
<ul>
<li>Главная задача анализа этой модели — выявить все существующие
операции, их последовательности, участников и результаты.</li>
<li>Некоторые компоненты модели As is:</li>
</ul></li>
<li>Процесс
<ul>
<li>порядок действий, которые выполняются для достижения определённой
цели или результата.</li>
</ul></li>
<li>Ресурсы
<ul>
<li>материальные и нематериальные активы, которые включены в процесс,
технологии и оборудование, а также труд людей, связанных с этой
моделью.</li>
</ul></li>
<li>Участники
<ul>
<li>это все лица и группы, вовлечённые в выполнение процессов (например,
сотрудники, менеджеры, поставщики).</li>
</ul></li>
<li>Документация
<ul>
<li>все существующие документы и записи, связанные с процессом, включая
инструкции, отчёты и регламенты.</li>
</ul></li>
</ul>
<h3 id="to-be-1">To be</h3>
<ul>
<li>описывает целевое состояние процессов после их оптимизации.</li>
<li>Эта модель показывает, как процессы должны выглядеть и работать с
учётом всех улучшений.</li>
<li>Основная задача создания модели To be
<ul>
<li>определить, какие изменения нужно внести, чтобы повысить
эффективность.</li>
</ul></li>
<li>Оптимизированные процессы
<ul>
<li>эффективные и продуктивные последовательности действий, направленные
на достижение желаемого результата.</li>
</ul></li>
<li>Новые ресурсы
<ul>
<li>могут включать в себя дополнительные или более современные
технологии, обучение персонала и переосмысление ролей.</li>
</ul></li>
<li>Изменения в работе участников
<ul>
<li>возможно, потребуется перераспределение обязанностей или изменение
состава команды.</li>
</ul></li>
<li>Новая документация
<ul>
<li>создание новых регламентов, инструкций и процессов, которые
поддерживают новую модель.</li>
</ul></li>
</ul>
<hr />
<h2 id="спринт-2-1">Спринт 2</h2>
<hr />
<h2 id="паттерн-strangler-fig-1">Паттерн Strangler Fig</h2>
<ul>
<li>Фикус-душитель - деревья фикусы, которые опуская корни к земле,
постепенно “душат” дерево-хозяина</li>
<li>паттерны - подходы, которые помогают снизить риски.</li>
<li>антипаттерны - те, что риски увеличивают</li>
</ul>
<h3 id="антипаттерн-большой-взрыв-1">Антипаттерн “Большой взрыв”</h3>
<ul>
<li>Миграцию монолита на микросервисы можно провести за один раз.
<ul>
<li>Такой подход называют «Большим взрывом»</li>
</ul></li>
<li>После перехода можно обнаружить такие проблемы:
<ul>
<li>ошибки в новой архитектуре привели к длительному простою после
релиза,</li>
<li>новые системы не всегда работают корректно,</li>
<li>часть информации из монолитной базы данных утеряна,</li>
<li>микросервисы писали в спешке, поэтому технический долг вырос.</li>
</ul></li>
</ul>
<h2 id="паттерн-strangler-fig-2">Паттерн Strangler Fig</h2>
<ul>
<li><p>Монолитный бэкенд онлайн-магазина — это дерево-хозяин, а
микросервисы — фикус-душитель.</p></li>
<li><p>Новую систему постепенно создают по краям старой: компоненты по
очереди извлекают из монолита и заменяют на микросервисы.</p></li>
<li><p>Новую архитектуру развивают в течение нескольких лет, пока она не
«задушит» монолит.</p></li>
<li><p>Последовательность разработки микросервисов зависит от
потребностей бизнеса.</p>
<ul>
<li>можно начать миграцию с написания сервиса, которого в приложении ещё
не было.</li>
<li>Или выбрать ту часть приложения, где больше всего legacy-кода. <img
src="images/img_33.png" alt="img_33.png" /></li>
</ul></li>
<li><p>Преимущества паттерна Strangler Fig</p>
<ul>
<li>Постепенная замена монолита.
<ul>
<li>Уменьшить количество сбоев</li>
<li>Повысить адаптивность новой системы.</li>
<li>Обучить и адаптировать команду.</li>
</ul></li>
<li>Снижение рисков и управление ими.
<ul>
<li>Инкрементные изменения. Небольшие изменения легче тестировать,
отслеживать и откатывать</li>
<li>параллельные операции. Микросервисы запускают параллельно с
существующими монолитными компонентами.
<ul>
<li>Если появятся проблемы, их можно будет устранить, не затрагивая всю
систему.</li>
</ul></li>
<li>Контролируемое развёртывание. Новые функции внедряют только после
тщательного тестирования и проверок на каждом этапе</li>
</ul></li>
<li>Инкрементная доставка новых функций в процессе миграции.
<ul>
<li>Приложение продолжает развиваться. Новые функции и улучшения можно
релизить по готовности.
<ul>
<li>Для этого не нужно ждать окончания миграции</li>
</ul></li>
<li>Пользовательский опыт улучшается.</li>
<li>По мере модернизации и оптимизации компонентов пользователи увидят,
что приложение работает лучше: повышается производительность и
надёжность знакомых функций.</li>
<li>Система адаптируется к ожиданиям пользователей.</li>
</ul></li>
<li>Эффективное решение проблемы технического долга.
<ul>
<li>помогает управлять техническим долгом</li>
<li>Систематический рефакторинг. Постепенная миграция — это фактически
последовательный и глубокий рефакторинг</li>
<li>Замена устаревших компонентов в первую очередь.</li>
<li>Разработка документации и поддержание стандартов</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Новую систему постепенно создают по краям старой: компоненты по
очереди извлекают из монолита и заменяют на микросервисы.</p>
</blockquote></li>
</ul>
<h2 id="как-реализовать-strangler-fig-1">Как реализовать Strangler
Fig</h2>
<ul>
<li>в общих чертах паттерн выглядит так <img src="images/img_34.png"
alt="img_34.png" /></li>
</ul>
<h3 id="шаг-1.-определение-доменной-области-1">Шаг 1. Определение
доменной области</h3>
<ul>
<li>сначала нужно определить и приоритизировать компоненты монолитного
приложения, которые должны быть извлечены
<ul>
<li>технический анализ</li>
<li>анализ производительности KPI, SLO, SLI</li>
<li>DDD</li>
</ul></li>
</ul>
<h3 id="шаг-2.-проектирование-и-разработка-новых-микросервисов-1">Шаг 2.
Проектирование и разработка новых микросервисов</h3>
<ul>
<li>после определения компонентов, необходимо спроектировать и
разработать новые микросервисы
<ul>
<li>применяем лучшие современные практики</li>
</ul></li>
<li>Принципы проектирования сервисов
<ul>
<li>у каждого микросервиса есть единственная, чётко определённая зона
ответственности.</li>
<li>микросервисы с минимальной зависимостью от других сервисов.</li>
<li>Группируйте связанную функциональность в рамках одного сервиса
(согласованность)</li>
</ul></li>
<li>Технологический стек
<ul>
<li>Определяйте чёткие контракты API для каждого микросервиса</li>
</ul></li>
<li>Практики разработки
<ul>
<li>Используйте технику TDD, чтобы обеспечить тщательное тестирование
каждого микросервиса
<ul>
<li>разработка через тестирование</li>
</ul></li>
<li>Внедряйте конвейеры CI/CD для автоматизации процессов тестирования и
развёртывания.</li>
</ul></li>
</ul>
<h3 id="шаг-3.-перенаправление-трафика-1">Шаг 3. Перенаправление
трафика</h3>
<ul>
<li>Маршрутизация на основе прокси
<ul>
<li>Обратный прокси-сервер можно использовать для маршрутизации запросов
либо к монолиту,
<ul>
<li>либо к новым микросервисам на основе определённых правил.</li>
</ul></li>
<li>API-шлюз реализуется для управления и маршрутизации трафика,
обеспечивая единую точку входа для всех клиентских запросов.</li>
<li>Фича-тоглы</li>
<li>Канареечные релизы, или инкрементальное смещение трафика</li>
</ul></li>
</ul>
<h3 id="фича-тоглы-1">Фича-тоглы</h3>
<ul>
<li>Переключатели функций нужны для управления развёртыванием новых
функций, чтобы постепенно перенаправлять трафик на новые сервисы.</li>
<li>Фича-тоглы — это механизм включения/выключения функциональности без
изменения кода и без нового релиза.</li>
</ul>
<pre><code>
if (featureFlags.newPaymentsFlow) {
  enableNewPayments();
} else {
  enableOldPayments();
}

</code></pre>
<ul>
<li>Постепенное развёртывание (progressive delivery)</li>
<li>Новую функцию можно включать только для небольшой группы
пользователей (например, 1% трафика).</li>
<li>Если всё работает нормально — постепенно увеличивать процент.</li>
<li>Если что-то сломалось — быстро откатить без деплоя.</li>
<li>A/B-тесты</li>
<li>Можно показывать разные версии интерфейса разным пользователям и
сравнивать конверсии.</li>
<li>Канареечные релизы</li>
<li>Сначала получают доступ сотрудники или тестовые аккаунты.</li>
<li>Потом часть клиентов.</li>
<li>Потом весь рынок.</li>
<li>Гибкость в бизнесе</li>
<li>Включение/выключение функционала по времени (например, “чёрная
пятница”).</li>
<li>Разделение фич по регионам, клиентам или тарифам.</li>
<li>Упрощение DevOps</li>
<li>Можно доставлять код заранее, а активировать в нужный момент.</li>
<li>Нет необходимости ждать деплой-окна</li>
</ul>
<h3 id="шаг-4.-мониторинг-и-верификация-микросервисов-1">Шаг 4.
Мониторинг и верификация микросервисов</h3>
<ul>
<li>устанавливаются метрики производительности и настраивается
мониторинг и верификация микросервисов.</li>
<li>используются количественные показатели — метрики производительности
<ul>
<li>Ключевые показатели эффективности (Key Performance Indicators, или
KPI).
<ul>
<li>время отклика, частота ошибок, пропускная способность, количество
запросов в секунду</li>
<li>KPI определяют для каждого микросервиса и устанавливают пороговое
значение уровня производительности</li>
</ul></li>
<li>Цели уровня сервиса (Service-Level Objectives, или SLO)
<ul>
<li>SLO ставятся на основе бизнес-требований, таких, как время
безотказной работы или время отклика.</li>
</ul></li>
<li>Индикаторы уровня обслуживания (Service Level Indicator, или SLI)
<ul>
<li>количественная оценка работы сервиса, которая показывает,
выполняются ли SLO.</li>
<li>латентность — время, необходимое для обработки запроса, доступность
— доля времени, в течение которого сервис работает, и частота
ошибок.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="средства-мониторинга-1">Средства мониторинга</h3>
<ul>
<li><p>В идеале нужно пройти через все шаги</p></li>
<li><p>Мониторинг производительности приложений (Application Performance
Monitoring, или APM).</p>
<ul>
<li>производительность приложений и отдельных микросервисов в режиме
реального времени и предоставляют информацию
<ul>
<li>о времени отклика, количестве ошибок и взаимодействии с
пользователями.</li>
<li>New Relic, Datadog, Dynatrace.</li>
</ul></li>
</ul></li>
<li><p>Централизованное логирование</p>
<ul>
<li>ELK Stack (Elasticsearch, Logstash, Kibana), Splunk и Fluentd.</li>
</ul></li>
<li><p>Мониторинг инфраструктуры</p>
<ul>
<li>следят за состоянием и производительностью базовой инфраструктуры,
такой как серверы, контейнеры и сетевые компоненты</li>
<li>Prometheus, Grafana, Nagios</li>
</ul></li>
<li><p>пример использования</p></li>
</ul>
<pre><code>
В «Шайбе» на этапе развёртывания мониторинга поступили так. 
Команда Алекса внедрила Datadog для мониторинга производительности новых микросервисов, отслеживая время отклика, количество ошибок и взаимодействие с пользователями. 
Затем она настроила все микросервисы на отправку логов в ELK Stack, что позволило эффективно агрегировать и анализировать логи. 
И третье — Prometheus и Grafana использовались для мониторинга состояния базовой инфраструктуры и обеспечения оптимальной работы серверов и контейнеров, поддерживающих микросервисы.

</code></pre>
<h3 id="методы-верификации-1">Методы верификации</h3>
<ul>
<li>Методы верификации включают в себя процессы и инструменты, которые
обеспечивают правильное
<ul>
<li>функционирование новых микросервисов в соответствии с ожидаемыми
стандартами производительности и надёжности</li>
</ul></li>
<li>Автоматизированное тестирование (юнит-тесты, интеграционные тесты,
e2e-тесты)
<ul>
<li>проверяет функциональность, производительность и интеграцию
микросервисов на их соответствие заданным критериям</li>
<li>настраиваются конвейеры CI/CD для запуска автоматизированных тестов
при каждом коммите кода в системе контроля версий</li>
</ul></li>
<li>А/B-тестирование
<ul>
<li>сравнивать производительность и влияние на пользователей двух версий
сайта,
<ul>
<li>приложения или сервиса, чтобы определить, какая из них работает
лучше.</li>
</ul></li>
<li>То есть часть трафика направляют на новую версию сервиса, а
остальную часть — на старую.</li>
<li>Затем анализируют показатели производительности</li>
</ul></li>
<li>Jenkins для автоматизации тестирования</li>
</ul>
<h3 id="шаг-5.-настройка-итерационного-процесса-1">Шаг 5. Настройка
итерационного процесса</h3>
<ul>
<li>подразумевает итерационное возвращение к первому пункту и реализацию
цикла до тех пор, пока весь монолит не будет заменён.</li>
<li>состоит из процессов
<ul>
<li>инкрементальное извлечение компонента из монолита</li>
<li>постепенного улучшения системы</li>
<li>координации усилий различных команд.</li>
</ul></li>
<li>Инкрементальное извлечение предполагает разбиение монолитного
приложения на более мелкие,
<ul>
<li>управляемые компоненты и постепенную замену их микросервисами.</li>
</ul></li>
<li><blockquote>
<p>Извлекайте по одному компоненту за раз</p>
</blockquote></li>
<li>Непрерывное улучшение направлено на регулярное усовершенствование
новых микросервисов и всей системы в целом
<ul>
<li>на основе данных о производительности, отзывов пользователей и
меняющихся потребностей бизнеса</li>
<li>инструменты APM для постоянного мониторинга</li>
<li>Собирайте и анализируйте обратную связь от пользователей,</li>
<li>Проводите рефакторинг и оптимизацию микросервисов по мере
необходимости на основе данных о производительности</li>
</ul></li>
<li>Координация работы команды важна для управления всеми сложностями
итерационного процесса миграции
<ul>
<li>Обеспечьте кросс-функциональное взаимодействие между командами
разработки, эксплуатации и бизнеса для согласования целей и
прогресса</li>
<li>Проводите регулярные встречи</li>
<li>Ведите документацию на протяжении всего процесса для обеспечения
последовательности и обмена знаниями</li>
</ul></li>
</ul>
<h3 id="подводные-камни-реализации-strangler-fig-1">подводные камни
реализации Strangler Fig</h3>
<ul>
<li>Недостаточное планирование
<ul>
<li>проблема
<ul>
<li>слишком поспешная реализация миграции без чёткого плана</li>
</ul></li>
<li>решение
<ul>
<li>разработать подробный план миграции с описанием каждого этапа,
определить ключевые компоненты для извлечения</li>
<li>поставить четкие сроки</li>
</ul></li>
</ul></li>
<li>Отсутствие поддержки заинтересованных сторон
<ul>
<li>проблема
<ul>
<li>сопротивление заинтересованных сторон из-за отсутствия понимания или
предполагаемых рисков.</li>
</ul></li>
<li>решение все заинтересованные стороны должны чётко представлять
преимущества модели фикус-душитель</li>
</ul></li>
<li>Недостаточный мониторинг и тестирование
<ul>
<li>проблема
<ul>
<li>неспособность адекватно контролировать новые сервисы</li>
</ul></li>
<li>решение
<ul>
<li>с самого начала организовать надёжный мониторинг и автоматическое
тестирование и настроить механизмы оповещения для раннего выявления
проблем.</li>
</ul></li>
</ul></li>
<li>Игнорирование зависимостей
<ul>
<li>проблема
<ul>
<li>игнорирование взаимозависимостей между компонентами приводит к
сбоям</li>
</ul></li>
<li>решение
<ul>
<li>провести тщательный анализ зависимостей внутри монолитного
приложения</li>
</ul></li>
</ul></li>
<li>Неполная документация
<ul>
<li>вести полную и актуальную документацию на протяжении всего процесса
миграции</li>
<li>документировать дизайн, API и рабочие процедуры каждого
микросервиса.</li>
</ul></li>
<li>Игнорирование проблем управления данными
<ul>
<li>обмен ими между монолитом и микросервисами, приводит к
несогласованности и проблемам целостности данных.</li>
</ul></li>
</ul>
<h3 id="реализация-паттерна-strangler-fig">Реализация паттерна Strangler
Fig</h3>
<pre><code>
1. Определение доменной области — того компонента, который необходимо извлечь из монолита.
2. Разработка микросервисов.
3. Настройка маршрутизации и извлечение старого функционала с помощью прокси, переключателей функций или канареечных релизов.
4. Мониторинг и верификация новых микросервисов — для надёжной работы микросервисов и своевременного реагирования используют инструменты APM, централизованное логирование и настраивают тестирование.
5. Итерационное повторение процесса — необходимый шаг миграции монолитной структуры до момента полного замещения её микросервисами.

</code></pre>
<h2 id="определение-доменной-области-1">Определение доменной
области</h2>
<ul>
<li><blockquote>
<p>Команда сначала определяет список потенциальных функций продукта, а
затем приоритет и возможность их извлечения.</p>
</blockquote></li>
</ul>
<h3 id="определение-списка-функций-продукта-1">Определение списка
функций продукта</h3>
<ul>
<li>Техника 1. Анализ домена бизнеса, Domain-Driven Design
<ul>
<li>разделение приложения на домены, которые представляют собой
ограниченный контекст бизнес-проблем и целей.</li>
<li>ограниченный контекст — бизнес-домен — может рассматриваться для
выделения в качестве независимого микросервиса</li>
</ul></li>
<li>Техника 2. Технический анализ
<ul>
<li>этот подход «смотрит» внутрь приложения.</li>
<li>оценивается монолитная кодовая база на предмет тесно связанных
компонентов, зависимостей и взаимодействия модулей</li>
<li>Лучше всего этот подход использовать в унаследованных системах, где
кодовая база сложна и плохо документирована.</li>
<li>Технический анализ помогает выявить скрытые зависимости и
взаимодействия, которые не видны только при бизнес-анализе.</li>
</ul></li>
<li>Техника 3. Анализ производительности
<ul>
<li>здесь важно сосредоточиться на компонентах, вызывающих проблемы с
производительностью или требующих больших ресурсов.</li>
<li>выявить компоненты, которые требуют оптимизации и модернизации в
первую очередь</li>
<li>применяется прежде всего в приложениях, которым необходимо
эффективное масштабирование.</li>
</ul></li>
<li>где какую использовать
<ul>
<li>анализ бизнес-домена - Если согласование переноса с бизнес-целями и
максимизация непосредственной ценности для бизнеса имеют решающее
значение</li>
<li>технический анализ - Для унаследованных систем с большим техническим
долгом и сложной, запутанной кодовой базой</li>
<li>показатели производительности - основные проблемы связаны с
масштабируемостью и производительностью и они влияют на пользовательский
опыт</li>
</ul></li>
</ul>
<h3 id="приоритизация-функций">Приоритизация функций</h3>
<ul>
<li><p>если после анализов у нас несколько функций для извлечения из
монолита</p></li>
<li><blockquote>
<p>Отдавайте предпочтение тем функциям, которые обеспечивают высокую
ценность при относительно небольших технических затратах.</p>
</blockquote></li>
<li><p>для ранжирования учитываем соотношение трех факторов</p>
<ul>
<li>Бизнес-влияние - согласуйте приоритетность функций с общими
бизнес-целями и стратегией.</li>
<li>Техническое влияние - Оцените масштабируемость и производительность
новой архитектуры
<ul>
<li>без значительных изменений других частей системы.</li>
</ul></li>
<li>Клиентское влияние - отзывы, предпочтения и болевые точки
клиентов</li>
</ul></li>
</ul>
<h3 id="методы-расстановки-приоритетов-1">Методы расстановки
приоритетов</h3>
<h4 id="moscow-1">MoSCoW</h4>
<ul>
<li><p>разделяет требования на четыре категории</p>
<ul>
<li>Must have (обязательно)</li>
<li>Should have (нужно)</li>
<li>Could have (желательно)</li>
<li>Won’t have (можно перенести)</li>
</ul></li>
<li><p>Однако он может быть менее эффективным, если команда с трудом
различает функции «обязательно» и «нужно».</p></li>
<li><p>Когда использовать метод MoSCoW:</p>
<ul>
<li>есть чётко определённые бизнес-цели, и необходимо тесно увязать
технические задачи с приоритетами бизнеса
<ul>
<li>наиболее важные бизнес-функции будут рассмотрены в первую
очередь.</li>
</ul></li>
<li>в процесс вовлечено множество заинтересованных сторон и их согласие
крайне важно</li>
<li>При управлении ограниченными ресурсами (время, бюджет,
персонал)</li>
</ul></li>
</ul>
<h4 id="матрица-эйзенхауэра-1">Матрица Эйзенхауэра</h4>
<ul>
<li>инструмент управления временем, который помогает расставить
приоритеты задач, разделяя их на четыре категории
<ul>
<li>срочные и важные,</li>
<li>важные, но несрочные,</li>
<li>срочные, но неважные,</li>
<li>несрочные и неважные</li>
</ul></li>
<li>Когда использовать матрицу Эйзенхауэра:
<ul>
<li>Если при расстановке приоритетов необходимо учитывать срочность
зада</li>
<li>В сценариях, где быстрое принятие решений имеет решающее значение
<ul>
<li>при устранении узких мест в производительности или перебоев</li>
<li>При определении приоритетов повседневных задач, которые требуют
чёткого разграничения между срочными задачами, требующими немедленных
действий</li>
</ul></li>
</ul></li>
</ul>
<h4 id="дополнительные-методы-приоритизации-1">Дополнительные методы
приоритизации</h4>
<ul>
<li>Модель Кано
<ul>
<li>метод приоритизации, ориентированный на клиента.</li>
<li>Модель Кано разделяет функции на пять типов в зависимости от их
влияния на удовлетворённость клиентов:
<ul>
<li>Must-Have, Performance, Excitement, Indifferent и Reverse.</li>
</ul></li>
<li>помогает командам определить функции, которые могут создать
конкурентное преимущество.</li>
<li>Однако она может потребовать больше времени и усилий для сбора
отзывов клиентов по каждой функции и может быть субъективной по своей
природе.</li>
</ul></li>
<li>Модель взвешенного оценивания (Weighted Scoring Model)
<ul>
<li>метод присваивает вес каждой функции на основе таких факторов:
<ul>
<li>потребительская ценность, влияние на бизнес и техническая
осуществимость.</li>
</ul></li>
<li>Затем функции ранжируются по их общему взвешенному баллу.</li>
<li>метод обеспечивает структурированный подход к расстановке
приоритетов, но может занять много времени и быть предвзятым,
<ul>
<li>если весовые коэффициенты не будут тщательно продуманы.</li>
</ul></li>
</ul></li>
<li>ICE Scoring
<ul>
<li>это простая и эффективная система расстановки приоритетов,</li>
<li>помогает командам оценивать и определять приоритеты задач, проектов
или функций на основе трёх ключевых критериев:
<ul>
<li>Воздействие, Уверенность и Усилия (Impact, Confidence, and Effort,
ICE).</li>
</ul></li>
<li>Каждый критерий оценивается по заранее определённой шкале, а
полученные баллы объединяются для получения чёткого рейтинга
приоритетов.</li>
</ul></li>
<li>Value vs. Effort
<ul>
<li>метод предполагает нанесение характеристик на график, где оси это:
<ul>
<li>ценность для клиентов, а другая — усилия, необходимые для реализации
характеристики.</li>
</ul></li>
<li>Такой подход помогает командам сосредоточиться на функциях, имеющих
высокую ценность и не требующих больших затрат.</li>
<li>Однако точная количественная оценка ценности и усилий может быть
затруднена.</li>
</ul></li>
<li>Cost of Delay (CoD)
<ul>
<li>это система расстановки приоритетов,</li>
<li>помогает бизнесу количественно оценить экономическую ценность более
раннего достижения конкретной цели по сравнению с более поздним.</li>
<li>Однако этот метод может не подходить для проектов, в которых
финансовое воздействие не является первостепенной задачей,</li>
<li>требует точной оценки затрат и выгод.</li>
</ul></li>
</ul>
<h2 id="anti-corruption-layer-и-маршрутизация-1">Anti-Corruption Layer и
маршрутизация</h2>
<ul>
<li><p>Проблемы монолита могут помешать разработке микросервисов и
повлиять на их производительность:</p>
<ul>
<li>можно повредить данные, которые новая и унаследованная системы
передают друг другу,</li>
<li>затраты на обслуживание вырастут,</li>
<li>циклы разработки замедлятся.</li>
</ul></li>
<li><p>В итоге команда вложит много сил в миграцию, а новая архитектура
только усугубит проблемы приложения.</p></li>
<li><p>Anti-Corruption Layer (ACL)</p></li>
<li><p>это паттерн проектирования, который помогает создать границу
между новой системой и унаследованной.</p></li>
<li><p>Через этот уровень проходят все данные, которые системы передают
друг другу.</p></li>
<li><p>ACL знает их форматы и модели данных.</p></li>
<li><p>Он адаптирует информацию под требования получателя.</p></li>
<li><p>Обычно используют паттерн Фасад и Адаптер</p></li>
</ul>
<h3 id="задачи-acl-при-миграции-на-микросервисы-1">Задачи ACL при
миграции на микросервисы</h3>
<ul>
<li><p>Изолирует микросервисы от сложностей и проблем унаследованной
системы</p></li>
<li><p>Управляет маршрутизацией запросов между монолитом и
микросервисами.</p></li>
<li><p>Адаптирует данные под требования разных систем.</p></li>
<li><p>Инкапсулирует монолитную систему.</p></li>
<li><p>его размещают внутри монолита, заменяет связи между
компонентами</p>
<ul>
<li>класс не будет знать куда он обращается к ACL или к какому-то
классу</li>
<li>и он же будет либо внутри перенапрявлять, либо наружу через
маршрутизацию</li>
</ul></li>
</ul>
<h3 id="как-работает-acl-1">Как работает ACL</h3>
<ul>
<li>алгоритм обмена данными выглядит так:
<ul>
<li>Микросервису нужна информация от монолитной системы. Он посылает
запрос на ACL.</li>
<li>ACL передаёт запрос адаптеру, чтобы он перевёл запрос микросервиса в
формат и семантику монолитной системы.</li>
<li>Адаптер переводит запрос и отправляет его монолитной системе.</li>
<li>Монолитная система обрабатывает запрос и отправляет ответ
адаптеру.</li>
<li>Адаптер переводит ответ в формат и семантику микросервиса, а затем
передаёт запрос ACL.</li>
<li>ACL отправляет переведённые данные микросервису. <img
src="images/img_35.png" alt="img_35.png" /></li>
<li><h3 id="когда-внедрять-и-отключать-acl-1">Когда внедрять и отключать
ACL</h3></li>
</ul></li>
<li><blockquote>
<p>ACL внедряют, как только команда начинает разработку микросервиса,
которому нужно взаимодействовать с монолитом.</p>
</blockquote></li>
<li>пример</li>
</ul>
<pre><code>
примера миграцию онлайн-магазина «Шайба». В монолитной системе пять функциональных областей, между которыми следующие зависимости:
- Корзина запрашивает данные у каталога товаров и системы обработки платежей.
- Профиль пользователя обращается к корзине, системе обработки платежей и управлению заказами.
- Обработка платежей обращается к управлению заказами.
- Управление заказами обращается к каталогу товаров.
- Каталог товаров не запрашивает данные у остальных систем, но отвечает на запросы.

Допустим, команда собирается выделить каталог товаров в отдельный сервис. После отключения монолитного каталога корзине
 и управлению заказами придётся взаимодействовать с микросервисом. Значит, нужен ACL.

Команда начинает писать сервис каталога и параллельно внедряет ACL. Когда сервис выкатят в продакшен, трафик переключат.

</code></pre>
<p><img src="images/img_36.png" alt="img_36.png" /> - ACL выводят из
эксплуатации, когда все зависимые сервисы перенесли в архитектуру
микросервисов. - если останется кусок, но он автономен, ACL можно
отключить раньше</p>
<h3 id="когда-стоит-отказаться-от-acl-1">Когда стоит отказаться от
ACL</h3>
<ul>
<li>старевшая система работает настолько плохо, что вам нужно заменить
её сразу целиком</li>
<li>в монолит нужно вносить изменения во время миграции. Такое возможно,
в частности, в банковском приложении.
<ul>
<li>Экономическая обстановка нестабильна, регулятор часто вносит
изменения на законодательном уровне,</li>
<li>а вам нужно адаптировать к ним приложение.</li>
<li>При таком миграция станет уже старой</li>
</ul></li>
</ul>
<h3 id="использование-strangler-fig-без-acl">Использование Strangler Fig
без ACL</h3>
<ul>
<li><p>Прямую интеграцию просто осуществить</p>
<ul>
<li>наследованная система относительно проста и понятна, а ещё у неё
чёткие и последовательные модели данных и протоколы</li>
</ul></li>
<li><p>Вы разрабатываете краткосрочный проект или временное
решение</p></li>
<li><p>Вам критически важна производительность приложения</p>
<ul>
<li>ACL разрабатывают так, чтобы он оказывал минимальное влияния на
производительность,
<ul>
<li>но дополнительный уровень абстракции — это всё ещё дополнительный
уровень абстракции.</li>
<li>Он может создавать задержки</li>
</ul></li>
</ul></li>
<li><p>У команды ограниченные ресурсы или нет опыта в создании
ACL</p></li>
<li><p>С ACL система станет слишком сложной</p></li>
</ul>
<h3 id="как-внедрить-acl-1">Как внедрить ACL</h3>
<ul>
<li>Определите границы и зависимости
<ul>
<li>Сначала изучите унаследованную систему</li>
<li>определите границы между унаследованной системой и
микросервисами</li>
<li>определите зависимости между унаследованной системой и
микросервисам</li>
</ul></li>
<li>Разработайте интерфейс ACL
<ul>
<li>создайте интерфейс для ACL, который абстрагирует сложности
унаследованной системы
<ul>
<li>сделать чистым и чётко определённым,</li>
<li>согласовать с требованиями микросервисов, которые вы
разрабатываете.</li>
</ul></li>
</ul></li>
<li>Внедрите ACL-компоненты
<ul>
<li>Адаптеры данных — они преобразуют форматы данных и обеспечивают
совместимость унаследованной системы и новой.</li>
<li>Шлюзы сервисов — они нужны для управления взаимодействием между
старой системой и новыми сервисами.
<ul>
<li>Шлюзы занимаются преобразованием протоколов, маршрутизацией запросов
и преобразованием ответов.</li>
</ul></li>
</ul></li>
<li>Протестируйте ACL
<ul>
<li>проведите тестирование производительности, чтобы убедиться</li>
<li>тщательное интеграционное тестирование</li>
<li>Протестируйте различные сценарии для проверки функциональности
ACL</li>
</ul></li>
<li>Разверните ACL и внедрите мониторинг
<ul>
<li>Расширяйте развёртывание постепенно — по мере роста доверия к
ACL</li>
<li>мониторинг для отслеживания производительности и надёжности
ACL.</li>
<li>Настройте оповещения о любых возникающих проблемах — например, об
ошибках трансляции данных или сбоях связи. <img src="images/img_37.png"
alt="img_37.png" /></li>
</ul></li>
</ul>
<h3 id="технологии-и-инструменты-для-создания-acl-1">Технологии и
инструменты для создания ACL</h3>
<ul>
<li>API-шлюзы.
<ul>
<li>Kong, NGINX и AWS API Gateway можно использовать для управления и
маршрутизации запросов между старой системой и микросервисами.</li>
</ul></li>
<li>Инструменты для преобразования данных
<ul>
<li>Apache Camel и MuleSoft, упростят трансформацию данных и
преобразование протоколов.</li>
</ul></li>
<li>Брокеры сообщений.
<ul>
<li>Брокеры сообщений обеспечивают связь и обмен данными между старой
системой и новыми сервисами.</li>
</ul></li>
<li>Service Mesh.
<ul>
<li>Решения Service Mesh, такие как Istio и Linkerd, могут предоставить
дополнительные возможности для управления взаимодействиями микросервисов
<ul>
<li>В том числе — управление трафиком, безопасность и
наблюдаемость.</li>
</ul></li>
</ul></li>
<li>Настраиваемое промежуточное ПО
<ul>
<li>использовать Java с Spring Boot и Node.js</li>
</ul></li>
<li><blockquote>
<p>Anti-Corruption Layer — это паттерн, который помогает обезопасить
взаимодействие между новой системой и устаревшей.</p>
</blockquote></li>
<li><blockquote>
<p>В задачи паттерна входит маршрутизация запросов от старой системы к
новой.</p>
</blockquote></li>
<li><blockquote>
<p>Чтобы реализовать ACL, нужно использовать инструменты
маршрутизации.</p>
</blockquote></li>
</ul>
<h3 id="маршрутизация-в-микросервисах-1">Маршрутизация в
микросервисах</h3>
<ul>
<li><blockquote>
<p>Маршрутизация — это способы управления и направления потока трафика
между различными частями системы.</p>
</blockquote></li>
<li>Польза маршрутизации в период миграции
<ul>
<li>Безболезненное взаимодействие с пользователями.</li>
<li>Непрерывность работы.</li>
<li>Инкрементное развёртывание.
<ul>
<li>Поддерживает поэтапное развёртывание новых функций и услуг.</li>
</ul></li>
<li>Управление рисками.
<ul>
<li>Снижает риск полного отказа системы за счёт возможности отката или
перенаправления трафика.</li>
</ul></li>
</ul></li>
<li>Проблемы маршрутизации в период миграции
<ul>
<li>Сложность управления трафиком:
<ul>
<li>Множество путей</li>
<li>Согласованность</li>
</ul></li>
<li>Задержка и производительность
<ul>
<li>Увеличение задержки
<ul>
<li>обратные прокси или API-шлюзы, может приводить к увеличению
задержек.</li>
</ul></li>
<li>Масштабируемость</li>
</ul></li>
<li>Обработка сбоев
<ul>
<li>Отказы сервисов</li>
<li>Механизмы аварийного восстановления</li>
</ul></li>
<li>Безопасность
<ul>
<li>Безопасность данных</li>
<li>Управление доступом</li>
</ul></li>
<li>Мониторинг и отладка
<ul>
<li>Наглядность</li>
<li>Устранение неполадок</li>
</ul></li>
</ul></li>
</ul>
<h3
id="техники-маршрутизации-между-монолитом-и-новыми-сервисами-1">Техники
маршрутизации между монолитом и новыми сервисами</h3>
<ul>
<li>обратный прокси-сервер (reverse proxy)
<ul>
<li>это промежуточный сервер, который ретранслирует запросы клиентов из
внешней сети на один или несколько серверов внутренней сети.</li>
<li>го настраивают так, чтобы он занимался маршрутизацией всех входящих
запросов к нужному внутреннему сервису.</li>
<li>Nginx, HAProxy или Apache HTTP Server.</li>
<li>преимущества
<ul>
<li>Упрощённая маршрутизация</li>
<li>Балансировка нагрузки</li>
<li>Безопасность</li>
<li>Кеширование</li>
</ul></li>
</ul></li>
<li>API-шлюз (Gateway API)
<ul>
<li>это продвинутая и многофункциональная альтернатива обратному
прокси-серверу.</li>
<li>Когда шлюз развёртывают, он начинает обрабатывать все входящие
запросы и перенаправлять их на основе заранее определённых правил</li>
<li>Kong, Apigee, AWS API Gateway и Zuul.</li>
<li>преимущества
<ul>
<li>Унифицированная точка входа</li>
<li>Безопасность и аутентификация</li>
<li>Ограничение скорости и дробление.</li>
<li>Аналитика и мониторинг.</li>
</ul></li>
</ul></li>
<li>Service Mesh
<ul>
<li>представляет собой объединение двух техник в среде Kubernetes</li>
</ul></li>
</ul>
<h2 id="стратегии-проектирования-микрофронтендов-1">Стратегии
проектирования микрофронтендов</h2>
<ul>
<li>всего 3 вида стратегий
<ul>
<li>вертикальная нарезка</li>
<li>автономность команд</li>
<li>изоляция</li>
</ul></li>
</ul>
<h3 id="вертикальная-нарезка-1">Вертикальная нарезка</h3>
<ul>
<li><blockquote>
<p>Организуйте микрофронтенды вокруг бизнес-возможностей или
пользовательских маршрутов.</p>
</blockquote></li>
<li><p>DDD подход - приложение делят на домены (на разные цели
бизнеса)</p></li>
<li><p>каждый микрофронтенд - есть самодостаточная система, которая есть
отдельная бизнес-функция</p>
<ul>
<li>со своей внешней логикой и от пользовательского интерфейса до уровня
получения данных <img src="images/img_38.png" alt="img_38.png" /></li>
</ul></li>
<li><p>Пример</p>
<ul>
<li>Вы разрабатываете систему управления медицинским центром.
Пообщавшись с клиентом, вы выделили четыре домена:
<ul>
<li>регистрация пациентов,</li>
<li>назначение встреч,</li>
<li>медицинские записи,</li>
<li>выставление счёта.</li>
</ul></li>
<li>Каждый домен будет обрабатывать всё, что касается его
бизнес-функции:
<ul>
<li>от компонентов пользовательского интерфейса до взаимодействия с API
и управления состоянием.</li>
</ul></li>
</ul></li>
<li><p>плюсы</p>
<ul>
<li>каждый микрофронтенд полный набор функций - независимый во всем
(разработка, тесты, разворачивание)</li>
</ul></li>
<li><p>минусы</p>
<ul>
<li>для определения границ домена, нужно хорошо понимать бизнес</li>
</ul></li>
<li><p>когда применять</p>
<ul>
<li>сложные пользовательские интерфейсы</li>
<li>кросс-функциональные команды</li>
</ul></li>
</ul>
<h3 id="автономность-команд-1">Автономность команд</h3>
<ul>
<li><blockquote>
<p>Дайте каждой команде возможность выбрать технологический стек,
который подходит под её задачи.</p>
</blockquote></li>
</ul>
<figure>
<img src="images/img_39.png" alt="img_39.png" />
<figcaption aria-hidden="true">img_39.png</figcaption>
</figure>
<ul>
<li>пример
<ul>
<li>для динамики React</li>
<li>для форм - Angular</li>
</ul></li>
<li>плюсы
<ul>
<li>более адаптивные решения</li>
</ul></li>
<li>минусы
<ul>
<li>проблемы общей стилизации и сквозного управления</li>
</ul></li>
</ul>
<h3 id="изоляция-1">Изоляция</h3>
<ul>
<li><blockquote>
<p>Убедитесь, что у микрофронтендов нет общих зависимостей во время
выполнения.</p>
</blockquote></li>
<li><p>Каждый микрофронтенд должен включать все свои
зависимости</p></li>
<li><p>Их инкапсулируют в его пакет развёртывания.</p></li>
<li><p>Общие библиотеки в микрофронтендах будут дублироваться, но их
можно совместить с помощью стратегического управления версиями на более
широком уровне.</p></li>
<li><p>Изоляция необходима, чтобы избежать конфликтов версий и облегчить
обновление или замену отдельных микрофронтендов.</p></li>
</ul>
<figure>
<img src="images/img_40.png" alt="img_40.png" />
<figcaption aria-hidden="true">img_40.png</figcaption>
</figure>
<ul>
<li>пример
<ul>
<li>В приложении есть финансовая панель. Торговые данные в реальном
времени требуют быстрого обновления.</li>
<li>Они не должны зависеть от более статичных разделов — например, от
управления профилем пользователя или новостной ленты.</li>
<li>Изолирование этих микрофронтендов гарантирует, что высокочастотные
обновления торгового интерфейса
<ul>
<li>не повлияют на производительность других частей приложения.</li>
</ul></li>
</ul></li>
<li>плюсы
<ul>
<li>Изоляция снижает риск того, что изменения в одном микрофронтенде
повлияют на другие.</li>
</ul></li>
<li>минусы
<ul>
<li>Если общие библиотеки включены в несколько микрофронтендов, размер
приложения увеличится.</li>
</ul></li>
<li>когда использовать
<ul>
<li>Частые обновления и развёртывания</li>
<li>Задачи масштабирования</li>
</ul></li>
</ul>
<h2 id="паттерн-backend-for-frontend-1">Паттерн Backend for
Frontend</h2>
<h3 id="проблемы-традиционного-api-в-сложной-архитектуре-1">Проблемы
традиционного API в сложной архитектуре</h3>
<ul>
<li>проблема в классическом API при микросервисах не только
фронт-монолит обращается к разным,
<ul>
<li>но и мимкрофронты зависят от разных API <img src="images/img_41.png"
alt="img_41.png" /></li>
</ul></li>
<li>пример, микрофронт Корзина делает запросы к сервисам: авторизации,
корзины, каталога
<ul>
<li>это будет не удобно агрегировать во фронте все запросы от
микросервисов</li>
<li>Процесс разработки усложняется. Фронтенд-разработчики вынуждены
следить за всеми изменениями в микросервисах</li>
<li>Безопасность снижается</li>
</ul></li>
</ul>
<h3 id="что-такое-backend-for-frontend-1">Что такое Backend for
Frontend</h3>
<ul>
<li><blockquote>
<p>Backend for Frontend (бэкенд для фронтенда, BFF) — это подход к
проектированию, при котором каждый фронтенд обслуживает специальный
бэкенд.</p>
</blockquote></li>
<li><p>промежуточный слой между фронтендом и внутренними
сервисами.</p></li>
<li><p>BFF отвечает за сбор информации от разных микросервисов, её
обработку и доставку на фронтенд в удобном формате.</p></li>
<li><p>также BFF используется если есть Мобильное и веб приложения</p>
<ul>
<li>один использует REST API, второй GraphQl</li>
<li>для каждого делается свой BFF, чтобы в микросервисах не
реализовывать оба API
<ul>
<li>вообще может быть другой, BFF делает внутри себя под нужный формат
фронта</li>
</ul></li>
</ul></li>
<li><p>BFF тесно связан с клиентом и развёртывается вместе с
ним</p></li>
<li><p>Вместо того чтобы напрямую вызвать метод API на сервере, клиент
будет вызывать метод API на уровне BFF.</p></li>
<li><p>BFF - есть промежуточный слой, принимающий запросы от клиента и
работающий с беком <img src="images/img_42.png"
alt="img_42.png" /></p></li>
</ul>
<h3 id="когда-использовать-bff-1">Когда использовать BFF</h3>
<ul>
<li>Монолитный фронтенд и микросервисы.</li>
<li>Несколько клиентов, которые используют разные технологии</li>
<li>Микросервисы и микрофронтенды.</li>
</ul>
<h3 id="bff-для-микрофронтендов-1">BFF для микрофронтендов</h3>
<ul>
<li>У каждого микрофронтенда — свой BFF.
<ul>
<li>Его настраивают в соответствии с требованиями конкретного
фронтенда</li>
</ul></li>
<li>BFF агрегирует данные из нескольких бэкенд-сервисов, преобразовывает
их в нужный формат и отправляет на фронтенд.
<ul>
<li>Ещё можно настроить кеширование. <img src="images/img_43.png"
alt="img_43.png" /></li>
</ul></li>
</ul>
<h3 id="преимущества-bff-1">Преимущества BFF</h3>
<ul>
<li>Подготовить данные для конкретного фронтенда
<ul>
<li>снижаете необходимость дополнительной обработки данных на стороне
клиента</li>
</ul></li>
<li>Упростить логику на стороне клиента
<ul>
<li>BFF обрабатывает сложные логические операции на стороне сервера. Это
относится к агрегации, композиции и преобразованию данных.</li>
</ul></li>
<li>Увеличить производительность.
<ul>
<li>С BFF вы передаёте меньше данных по сети, а фронтенд выполняет
меньше запросов</li>
</ul></li>
<li>Усилить безопасность</li>
</ul>
<h3 id="что-важно-учесть-при-дизайне-bff-1">Что важно учесть при дизайне
BFF</h3>
<ul>
<li>подберите оптимальный технологический стек</li>
<li>внедрить стратегии кеширования</li>
<li>разработать систему обработки ошибок</li>
<li>внедрить мониторинг и ведение логов</li>
</ul>
<h2 id="паттерны-управления-микросервисами-1">Паттерны управления
микросервисами</h2>
<ul>
<li>CQRS
<ul>
<li>для разделения чтения и записи данных</li>
</ul></li>
<li>Saga
<ul>
<li>для обеспечения согласованности данных на примере реальных
проектов</li>
</ul></li>
<li>API Gateway</li>
</ul>
<h3 id="паттерн-cqrs-1">Паттерн CQRS</h3>
<ul>
<li>Command Query Responsibility Segregation (CQRS)
<ul>
<li>это паттерн проектирования, который разделяет операцию чтения и
записи данных в системе на два отдельных интерфейса.</li>
</ul></li>
<li>плюсы
<ul>
<li>масштабируемость</li>
<li>оптимизация запросов
<ul>
<li>Запросы на чтение могут быть оптимизированы для быстрого получения
данных</li>
<li>команды записи — для эффективного обновления данных.</li>
</ul></li>
<li>улучшенная согласованность</li>
</ul></li>
<li>минусы
<ul>
<li>сложности реализации
<ul>
<li>два отдельных интерфейса</li>
</ul></li>
<li>увеличение объема кода</li>
</ul></li>
</ul>
<h4 id="разделение-чтения-и-записи-данных-с-cqrs-1">Разделение чтения и
записи данных с CQRS</h4>
<ul>
<li>операция чтения - запросы (queries)
<ul>
<li>не изменяют состояние системы</li>
</ul></li>
<li>операция изменения - команды (commands)
<ul>
<li>изменяют состояние системы</li>
</ul></li>
</ul>
<h4 id="документирование-применения-cqrs-1">Документирование применения
CQRS</h4>
<ul>
<li>Документирование применения CQRS включает
<ul>
<li>описание всех команд и запросов, используемых в системе,</li>
<li>модели данных, связанные с каждой операцией</li>
</ul></li>
<li>пример задачи</li>
</ul>
<pre><code>
Команды (Commands):
  CreateOrderCommand: Команда для создания нового заказа.
    Модель данных: Order (id, courierId, status, deliveryTime)
    Метод: execute()
  UpdateCourierStatusCommand: Команда для обновления статуса курьера.
    Модель данных: Courier (id, name, status)
    Метод: execute()
  CompleteDeliveryCommand: Команда для завершения доставки.
    Модель данных: Order (id, courierId, status, deliveryTime)
    Метод: execute()
Запросы (Queries):
  GetCourierLocationQuery: Запрос для получения текущего местоположения курьера.
    Модель данных: Location (courierId, latitude, longitude, timestamp)
    Метод: execute()
  GetActiveOrdersQuery: Запрос для получения списка активных заказов.
    Модель данных: Order (id, courierId, status, deliveryTime)
    Метод: execute()
  GetDeliveryHistoryQuery: Запрос для получения истории доставки.
    Модель данных: Order (id, courierId, status, deliveryTime)
    Метод: execute()

</code></pre>
<ul>
<li>пример описания на YAML <img src="images/img_44.png"
alt="img_44.png" /></li>
</ul>
<pre><code>
@startuml
package &quot;Commands&quot; {
  class CreateOrderCommand {
    +execute()
  }
  class UpdateCourierStatusCommand {
    +execute()
  }
  class CompleteDeliveryCommand {
    +execute()
  }
}

package &quot;Queries&quot; {
  class GetCourierLocationQuery {
    +execute()
  }
  class GetActiveOrdersQuery {
    +execute()
  }
  class GetDeliveryHistoryQuery {
    +execute()
  }
}

class OrderService {
  +handleCommand()
  +handleQuery()
}

OrderService --&gt; CreateOrderCommand : handles
OrderService --&gt; UpdateCourierStatusCommand : handles
OrderService --&gt; CompleteDeliveryCommand : handles
OrderService --&gt; GetCourierLocationQuery : handles
OrderService --&gt; GetActiveOrdersQuery : handles
OrderService --&gt; GetDeliveryHistoryQuery : handles
@enduml


</code></pre>
<h3 id="паттерн-saga-1">Паттерн Saga</h3>
<ul>
<li>Паттерн Saga позволяет согласованно управлять состоянием системы,
разделяя большую транзакцию на серию меньших шагов,
<ul>
<li>каждый из которых может быть выполнен автономно.</li>
<li>Каждый шаг транзакции имеет соответствующую компенсирующую операцию,
которая выполняется в случае неудачи.</li>
</ul></li>
<li>требованиям ACID:
<ul>
<li>Atomicity — атомарность,</li>
<li>Consistency — целостность,</li>
<li>Isolation — изолированность,</li>
<li>Durability — надёжность.</li>
</ul></li>
<li>В микросервисных архитектурах тоже нужно поддерживать ACID,
<ul>
<li>но использовать механизмы СУБД не получится:
<ul>
<li>процесс включает несколько баз данных.</li>
</ul></li>
<li>Saga решает эту проблему с помощью набора локальных транзакций и
компенсирующих действий.</li>
</ul></li>
<li>паттерн дробит транзакцию на шаги, которыми занимаются разные
микросервисы.
<ul>
<li>В случае ошибки система активирует отмену действия, которая
распространяется на все вовлечённые микросервисы.b</li>
</ul></li>
<li>плюсы
<ul>
<li>согласованность данных</li>
<li>устойчивость ка сбоям</li>
<li>гибкость</li>
</ul></li>
<li>минусы
<ul>
<li>сложность реализации</li>
<li>временная несогласованность</li>
</ul></li>
</ul>
<h4 id="подходы-к-реализации-saga-1">Подходы к реализации Saga</h4>
<h4 id="оркестрация-1">Оркестрация</h4>
<ul>
<li>Orchestration-based Saga
<ul>
<li>центральный координатор (оркестратор), который управляет выполнением
всех шагов транзакции и вызывает каждый шаг поочерёдно</li>
<li>отслеживает состояние выполнения и в случае ошибки инициирует
выполнение компенсирующих операций.</li>
</ul></li>
<li>пример</li>
</ul>
<pre><code>
Принятие заказа. 
  Клиент отправляет запрос на создание заказа оркестратору.

Создание заказа. 
  Оркестратор вызывает OrderService для создания заказа.

Резервирование товара. 
  После успешного создания заказа оркестратор вызывает InventoryService для резервирования товара.

Обработка оплаты. 
  После резервирования товара оркестратор вызывает PaymentService для обработки оплаты.

Отправка уведомления. 
  После успешной обработки оплаты оркестратор вызывает NotificationService для отправки уведомления клиенту о подтверждении заказа.

</code></pre>
<figure>
<img src="images/img_45.png" alt="img_45.png" />
<figcaption aria-hidden="true">img_45.png</figcaption>
</figure>
<h4 id="хореография-1">Хореография</h4>
<ul>
<li>Choreography-based Saga
<ul>
<li>каждый микросервис отвечает за выполнение своего шага и вызывает
следующий микросервис через обмен сообщениями</li>
</ul></li>
<li>пример</li>
</ul>
<pre><code>
Принятие заказа. 
  Микросервис OrderService создаёт заказ и отправляет сообщение InventoryService для резервирования товара.

Назначение курьера. 
  InventoryService резервирует товар и отправляет сообщение PaymentService для обработки оплаты.

Подтверждение доставки. 
  PaymentService обрабатывает оплату и отправляет сообщение NotificationService для отправки уведомления.

Завершение заказа. 
  NotificationService отправляет уведомление клиенту о подтверждении заказа.


</code></pre>
<figure>
<img src="images/img_46.png" alt="img_46.png" />
<figcaption aria-hidden="true">img_46.png</figcaption>
</figure>
<h4 id="обеспечение-согласованности-данных-с-помощью-saga-1">Обеспечение
согласованности данных с помощью Saga</h4>
<ul>
<li><p>выполняется серия шагов, каждый из которых может быть выполнен
независимо.</p></li>
<li><p>В случае неудачи любой из шагов может быть отменён с помощью
компенсирующей операции, что обеспечивает целостность данных.</p></li>
<li><p>пример <img src="images/img_48.png" alt="img_48.png" /></p></li>
</ul>
<pre><code>
Процесс доставки заказа в системе CourierTrack включает следующие шаги:
Принятие заказа: создаётся новый заказ.
  Компенсирующая операция — отмена заказа.
  
Назначение курьера: курьеру назначается заказ.
  Компенсирующая операция — отмена назначения курьера.

Подтверждение доставки: курьер подтверждает доставку заказа.
  Компенсирующая операция — отмена подтверждения доставки.

Завершение заказа: заказ помечается как завершённый.
  Компенсирующая операция. Отмена завершения заказа.

</code></pre>
<h4 id="документирование-применения-saga-1">Документирование применения
Saga</h4>
<ul>
<li><p>включает описание всех шагов транзакции, компенсирующих операций
и моделей данных, используемых в процессе</p></li>
<li><p>пример</p></li>
</ul>
<pre><code>
Пример документации для CourierTrack
Название: Документация по применению Saga в системе CourierTrack
Введение: Эта документация описывает применение паттерна Saga в системе отслеживания курьеров CourierTrack. Документация включает описание шагов транзакции, компенсирующих операций и моделей данных.

Шаги транзакции и компенсирующие операции:
Принятие заказа:
  Операция: Создание нового заказа.
  Компенсирующая операция: Отмена заказа.

Назначение курьера:
  Операция: Назначение курьера на заказ.
  Компенсирующая операция: Отмена назначения курьера.

Подтверждение доставки:
  Операция: Подтверждение доставки заказа курьером.
  Компенсирующая операция: Отмена подтверждения доставки.

Завершение заказа:
  Операция: Завершение заказа.
  Компенсирующая операция: Отмена завершения заказа.
  
YAML
@startuml
start
:Принятие заказа;
if (успешно?) then (да)
  :Назначение курьера;
  if (успешно?) then (да)
    :Подтверждение доставки;
    if (успешно?) then (да)
      :Завершение заказа;
    else (нет)
      :Отмена подтверждения доставки;
      :Отмена назначения курьера;
      :Отмена заказа;
    endif
  else (нет)
    :Отмена назначения курьера;
    :Отмена заказа;
  endif
else (нет)
  :Отмена заказа;
endif
stop
@enduml

</code></pre>
<h3 id="api-gateway-1">API Gateway</h3>
<ul>
<li><p>API Gateway является единой точкой входа для клиентских
запросов.</p></li>
<li><p>Этот подход можно сравнить с руководителем в компании, который
передаёт задачи и информацию своим сотрудникам</p>
<ul>
<li>и предоставляет результаты работы другим направлениям</li>
</ul></li>
<li><p>API Gateway выполняет функции прокси-сервера, принимая все
клиентские запросы и маршрутизируя их к соответствующим
микросервисам.</p>
<ul>
<li>Позволяет скрыть внутреннюю структуру микросервисов от клиентов,
предоставляет единый интерфейс для взаимодействия с системой.</li>
<li>API Gateway также может выполнять множество дополнительных задач,
таких как трансформация запросов и ответов, кеширование, мониторинг,
логирование, управление сессиями, аутентификация и авторизация.</li>
</ul></li>
<li><p>обеспечивает оптимизацию маршрутизации запросов, эффективное
распределение нагрузки между микросервисами,</p>
<ul>
<li>а также интеграцию с системами аутентификации и авторизации.</li>
</ul></li>
<li><p>плюсы</p>
<ul>
<li>единая точка входа</li>
<li>безопасность</li>
<li>маршрутизация и балансировка нагрузки</li>
<li>мониторинг ми логирование</li>
</ul></li>
<li><p>минусы</p>
<ul>
<li>единая точка отказа</li>
<li>сложность</li>
</ul></li>
</ul>
<h4 id="управление-api-микросервисов-с-помощью-api-gateway-1">Управление
API микросервисов с помощью API Gateway</h4>
<ul>
<li>управляет всеми API вызовами и предоставляет множество функций для
оптимизации и защиты API микросервисов</li>
<li>может выполнять трансформацию запросов и ответов, обеспечивать
кеширование для улучшения производительности,
<ul>
<li>управлять сессиями пользователей и выполнять аутентификацию и
авторизацию запросов.</li>
</ul></li>
<li>пример</li>
</ul>
<pre><code>
Маршрутизация запросов: 
  API Gateway принимает запросы от клиентов и маршрутизирует их к соответствующим микросервисам. Например, запрос на создание заказа маршрутизируется к Order Service, а запрос на получение текущего местоположения курьера — к Location Service.

Аутентификация и авторизация: 
  API Gateway выполняет аутентификацию пользователей, проверяя их учётные данные, и авторизует запросы, проверяя права доступа к запрашиваемым ресурсам.

Кеширование: 
  API Gateway кеширует часто запрашиваемые данные, такие как списки доступных курьеров, чтобы уменьшить нагрузку на микросервисы и улучшить производительность системы.

Мониторинг и логирование: 
  API Gateway собирает метрики и логи всех запросов и ответов, что позволяет отслеживать производительность системы, выявлять проблемы и анализировать поведение пользователей.


</code></pre>
<figure>
<img src="images/img_49.png" alt="img_49.png" />
<figcaption aria-hidden="true">img_49.png</figcaption>
</figure>
<h4 id="оценка-различных-подходов-к-использованию-api-gateway-1">Оценка
различных подходов к использованию API Gateway</h4>
<ul>
<li>Монолитный API Gateway
<ul>
<li>плюсы: единая точка входа, централизованное управление
безопасностью</li>
<li>минусы единая точка отказа <img src="images/img_50.png"
alt="img_50.png" /></li>
</ul></li>
<li>Распределённый API Gateway
<ul>
<li>плюсы: уменьшение единой точки отказа, улучшенная масштабируемость и
производительность.</li>
<li>минусы: повышенная сложность управления и настройки, возможные
проблемы с согласованностью данных <img src="images/img_51.png"
alt="img_51.png" /></li>
</ul></li>
<li>Многослойный API Gateway
<ul>
<li>плюсы: улучшенная безопасность, улучшенная масштабируемость,
упрощенное управление и мониторинг, повышенная производительность.</li>
<li>минусы: повышенная сложность, трудности настройки, увеличение
времени отклика, затраты на инфраструктуру. <img src="images/img_52.png"
alt="img_52.png" /></li>
</ul></li>
<li>Serverless API Gateway
<ul>
<li>Плюсы: высокая масштабируемость, отсутствие необходимости управления
инфраструктурой, уменьшение затрат на ресурсы.</li>
<li>Минусы: возможные ограничения в функциональности и
производительности, зависимость от облачного провайдера.</li>
</ul></li>
</ul>
<h2
id="взаимодействие-микросервисов-с-использованием-kong-1">Взаимодействие
микросервисов с использованием Kong</h2>
<ul>
<li><p>API Gateway с открытым исходным кодом — Kong.</p></li>
<li><p>основные функции, которые API Gateway выполняет в микросервисной
архитектуре:</p>
<ul>
<li>Централизация маршрутизации запросов
<ul>
<li>API Gateway принимает все клиентские запросы и маршрутизирует их к
соответствующим микросервисам</li>
</ul></li>
<li>Управление аутентификацией и авторизацией</li>
<li>Балансировка нагрузки и распределение трафика
<ul>
<li>распределяет входящий трафик между несколькими экземплярами
микросервисов</li>
</ul></li>
<li>Обеспечение безопасности
<ul>
<li>шифрование данных, защиту от DDoS-атак и ограничение скорости
запросов</li>
</ul></li>
<li>Кеширование запросов
<ul>
<li>кешировать ответы на часто запрашиваемые ресурсы</li>
</ul></li>
</ul></li>
<li><p>Кто и как применяет API Gateway</p>
<ul>
<li>Netflix Zuul, Amazon API Gateway,NGINX API Gateway</li>
</ul></li>
</ul>
<h3 id="настройка-и-использование-api-gateway-kong-1">Настройка и
использование API Gateway — Kong</h3>
<ul>
<li><p>Kong — это популярный API Gateway с открытым исходным кодом,
который поддерживает множество плагинов</p>
<ul>
<li>для управления трафиком, аутентификации, авторизации и
мониторинга.</li>
<li>Компании используют этот паттерн для надёжного и безопасного
взаимодействия между микросервисами.</li>
</ul></li>
<li><p>https://konghq.com/</p></li>
<li><p>Шаг 1. Установка API Gateway Kong</p>
<ul>
<li>Установка Kong на Docker</li>
</ul></li>
</ul>
<pre><code>
docker pull kong
docker network create kong-net
docker run -d --name kong-database \
  --network=kong-net \
  -p 5432:5432 \
  -e &quot;POSTGRES_USER=kong&quot; \
  -e &quot;POSTGRES_DB=kong&quot; \
  -e &quot;POSTGRES_PASSWORD=kong&quot; \
  postgres:9.6

docker run -d --name kong \
  --network=kong-net \
  -e &quot;KONG_DATABASE=postgres&quot; \
  -e &quot;KONG_PG_HOST=kong-database&quot; \
  -e &quot;KONG_CASSANDRA_CONTACT_POINTS=kong-database&quot; \
  -p 8000:8000 \
  -p 8443:8443 \
  -p 8001:8001 \
  -p 8444:8444 \
  kong 

</code></pre>
<ul>
<li><p>Инициализация базы данных Kong
<code>docker exec -it kong kong migrations bootstrap</code></p></li>
<li><p>Шаг 2. Базовая конфигурация и настройка окружения</p>
<ul>
<li>Добавление сервиса и маршрута</li>
</ul></li>
</ul>
<pre><code>
curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data &#39;name=weather-service&#39; \
  --data &#39;url=http://weather-service:8000&#39;

curl -i -X POST \
  --url http://localhost:8001/services/weather-service/routes \
  --data &#39;paths[]=/weather&#39;

</code></pre>
<ul>
<li><p>Проверка конфигурации
<code>curl -i http://localhost:8000/weather</code></p></li>
<li><p>Шаг 3. Настройка маршрутизации запросов</p>
<ul>
<li>API Gateway позволяет настроить маршруты, которые определяют, как
запросы будут направляться к микросервисам.
<ul>
<li>Пример маршрутизации для сервиса WeatherNow
<ul>
<li>Добавление маршрутов для микросервисов:</li>
</ul>
<pre><code>  curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data &#39;name=sensor-service&#39; \
  --data &#39;url=http://sensor-service:8000&#39;

  curl -i -X POST \
  --url http://localhost:8001/services/sensor-service/routes \
  --data &#39;paths[]=/sensor&#39;

  curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data &#39;name=notification-service&#39; \
  --data &#39;url=http://notification-service:8000&#39;

  curl -i -X POST \
  --url http://localhost:8001/services/notification-service/routes \
  --data &#39;paths[]=/notification&#39;
</code></pre>
<ul>
<li>Настройка правил маршрутизации и редиректов
<ul>
<li>Правила маршрутизации:
<ul>
<li>Маршрутизация запросов по пути (path).</li>
<li>Маршрутизация запросов по методам HTTP (GET, POST, PUT,
DELETE).</li>
<li>Маршрутизация запросов по заголовкам.</li>
<li>Редиректы:</li>
<li>Настройка редиректов для определённых путей.</li>
<li>Управление временными и постоянными редиректами.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Шаг 4. Настройка балансировки нагрузки</p>
<ul>
<li>может распределять входящий трафик между несколькими экземплярами
микросервисов,
<ul>
<li>обеспечивая равномерную нагрузку и высокую доступность системы.</li>
</ul></li>
<li>Пример настройки балансировки нагрузки в Kong в WeatherNow
<ul>
<li><p>Добавление upstream сервера:</p>
<pre><code>   curl -i -X POST \
   --url http://localhost:8001/upstreams/ \
   --data &#39;name=weather-upstream&#39;</code></pre></li>
<li><p>Добавление целевых серверов:</p>
<pre><code> curl -i -X POST \
 --url http://localhost:8001/upstreams/weather-upstream/targets \
 --data &#39;target=weather-service1:8000&#39; \
 --data &#39;weight=100&#39;

 curl -i -X POST \
 --url http://localhost:8001/upstreams/weather-upstream/targets \
 --data &#39;target=weather-service2:8000&#39; \
 --data &#39;weight=100&#39;</code></pre></li>
<li><p>Использование алгоритмов балансировки</p>
<ul>
<li><strong>Round-robin</strong> распределяет запросы по кругу между
всеми доступными серверами.
<ul>
<li>Этот метод прост и эффективен, так как каждый сервер получает равное
количество запросов.
<ul>
<li>Если один из серверов выходит из строя, алгоритм продолжает
распределять запросы между оставшимися серверами.</li>
<li>Пример использования: Если у вас есть три сервера (Server A, Server
B, Server C),
<ul>
<li>первый запрос будет направлен на Server A, второй на Server B,
третий на Server C,</li>
<li>четвёртый снова на Server A и так далее.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>IP hash</strong> направляет запросы к серверу на основе хеша
IP-адреса клиента.
<ul>
<li>Этот метод позволяет всегда направлять запросы от одного и того же
клиента к одному и тому же серверу,
<ul>
<li>что может быть полезно для кеширования и сохранения сессий.</li>
<li>Пример использования: Если клиент с IP-адресом 192.168.1.1 делает
запрос, хеш этого IP-адреса будет определять,
<ul>
<li>к какому серверу будет направлен запрос.</li>
</ul></li>
<li>Например, хеш может указывать на Server B и все последующие запросы
от этого IP будут направляться на Server B.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="безопасность-мониторинг-и-отладка-api-gateway-1">Безопасность,
мониторинг и отладка API Gateway</h3>
<h4 id="управление-аутентификацией-и-авторизацией-1">Управление
аутентификацией и авторизацией</h4>
<ul>
<li>позволяет централизованно управлять аутентификацией и авторизацией,
<ul>
<li>обеспечивая контроль доступа к микросервисам.</li>
</ul></li>
<li>Внедрение механизмов аутентификации:
<ul>
<li>OAuth2: протокол для авторизации, который позволяет приложениям
получать ограниченный доступ к пользовательским ресурсам на
сервере.</li>
<li>JWT (JSON Web Token): стандарт токенов для передачи информации между
сторонами как JSON-объект в формате токена,
<ul>
<li>который подписан цифровой подписью для обеспечения
безопасности.</li>
</ul></li>
<li>Basic Auth: простой метод аутентификации, который передаёт учётные
данные в заголовках HTTP-запросов.</li>
</ul></li>
<li>Пример настройки OAuth2 в Kong для WeatherNow
<ul>
<li><p>Добавление OAuth2 плагина к сервису:</p>
<pre><code>   curl -i -X POST \
     --url http://localhost:8001/services/weather-service/plugins/ \
     --data &#39;name=oauth2&#39; \
     --data &#39;config.scopes=email&#39; \
     --data &#39;config.mandatory_scope=true&#39; \
     --data &#39;config.enable_authorization_code=true&#39;</code></pre></li>
<li><p>Создание клиента OAuth2:</p>
<pre><code> curl -i -X POST \
   --url http://localhost:8001/consumers/{consumer}/oauth2/ \
   --data &#39;name=weather-app&#39; \
   --data &#39;client_id=weather-client-id&#39; \
   --data &#39;client_secret=weather-client-secret&#39; \
   --data &#39;redirect_uris=http://localhost/callback&#39;</code></pre></li>
<li><p>Использование OAuth2 и JWT-токенов:</p>
<ul>
<li>Настройка OAuth2-провайдера.</li>
<li>Генерация и валидация JWT-токенов.</li>
</ul></li>
</ul></li>
<li>Пример настройки JWT в Kong для WeatherNow
<ul>
<li><p>Добавление JWT-плагина к сервису:</p>
<pre><code> curl -i -X POST \
   --url http://localhost:8001/services/weather-service/plugins/ \
    --data &#39;name=jwt&#39;</code></pre></li>
<li><p>Создание потребителя и привязка JWT-ключа:</p>
<pre><code> curl -i -X POST \
   --url http://localhost:8001/consumers/ \
   --data &#39;username=weather-consumer&#39;

   curl -i -X POST \
   --url http://localhost:8001/consumers/weather-consumer/jwt/ \
   --data &#39;key=weather-key&#39; \
   --data &#39;algorithm=HS256&#39;
</code></pre></li>
</ul></li>
</ul>
<h4 id="настройка-защиты-от-ddos-атак-1">Настройка защиты от
DDoS-атак</h4>
<ul>
<li>может обеспечить защиту от DDoS-атак путём лимитирования запросов
(Rate Limiting)
<ul>
<li>и блокировки подозрительного трафика для предотвращения перегрузки
сервиса.</li>
</ul></li>
<li>Пример настройки лимитирования запросов в Kong WeatherNow
<ul>
<li><p>Добавление плагина лимитирования запросов:</p>
<pre><code> curl -i -X POST \
   --url http://localhost:8001/services/weather-service/plugins/ \
   --data &#39;name=rate-limiting&#39; \
   --data &#39;config.minute=10&#39; \
   --data &#39;config.hour=500&#39;</code></pre></li>
<li><p>Настройка правил блокировки подозрительного трафика:</p>
<ul>
<li>Использование плагинов для блокировки IP-адресов, которые генерируют
подозрительный трафик.</li>
<li>Настройка правил для блокировки определённых типов запросов.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="мониторинг-метрик-на-api-gateway-1">Мониторинг метрик на API
Gateway</h4>
<ul>
<li><p>Ключевые метрики, которые следует собирать и анализировать при
мониторинге API Gateway</p></li>
<li><p>Метрики производительности</p>
<ul>
<li>Запросы в секунду (Requests per Second, RPS)
<ul>
<li>Количество запросов, обрабатываемых API Gateway в секунду.</li>
<li>Эта метрика помогает определить нагрузку на систему и выявить
пиковые моменты активности.</li>
</ul></li>
<li>Время отклика (Response Time)
<ul>
<li>Среднее время, затрачиваемое на обработку запросов.</li>
<li>Важно отслеживать как среднее время отклика, так и 95-й и 99-й
процентили для выявления долгих запросов.</li>
</ul></li>
<li>Время до первого байта (Time to First Byte, TTFB)
<ul>
<li>Время, прошедшее от отправки запроса до получения первого байта
ответа.</li>
<li>Высокий TTFB может указывать на проблемы с сервером или сетью.</li>
</ul></li>
</ul></li>
<li><p>Метрики ошибок</p>
<ul>
<li>Количество ошибок (Error Rate)
<ul>
<li>Процент запросов, завершившихся ошибками (например, HTTP 4xx и
5xx).</li>
<li>Высокий уровень ошибок может указывать на проблемы с API или
инфраструктурой.</li>
</ul></li>
<li>Виды ошибок (Error Types)
<ul>
<li>Распределение ошибок по типам (4xx — ошибки клиента, 5xx — ошибки
сервера).</li>
<li>Это помогает определить источник проблемы.</li>
</ul></li>
<li>Ошибки авторизации и аутентификации (Authentication and
Authorization Failures)
<ul>
<li>Количество запросов, не прошедших проверку аутентификации или
авторизации.</li>
<li>Высокий уровень таких ошибок может указывать на проблемы с
безопасностью.</li>
</ul></li>
</ul></li>
<li><p>Метрики безопасности</p>
<ul>
<li>Неудачные попытки входа (Failed Login Attempts)
<ul>
<li>Количество неудачных попыток входа может свидетельствовать о
возможных атаках.</li>
</ul></li>
<li>IP-адреса с наибольшим количеством запросов (Top Requesting IPs)
<ul>
<li>IP-адреса, с которых поступает наибольшее количество запросов.</li>
<li>Это помогает выявить потенциальные DDoS-атаки.</li>
</ul></li>
<li>Аномалии в трафике (Traffic Anomalies)
<ul>
<li>Внезапные изменения в объёме или характере трафика могут указывать
на атаки или другие проблемы безопасности.</li>
</ul></li>
</ul></li>
<li><p>Метрики использования ресурсов</p>
<ul>
<li>Память (Memory Usage)
<ul>
<li>Объём памяти, используемой API Gateway.</li>
<li>Высокое потребление памяти может привести к снижению
производительности или сбоям.</li>
</ul></li>
<li>Использование сети (Network Usage)
<ul>
<li>Объём входящего и исходящего трафика через API Gateway.</li>
<li>Помогает определить нагрузку на сеть и выявить проблемы с пропускной
способностью.</li>
</ul></li>
</ul></li>
<li><p>Метрики отказоустойчивости</p>
<ul>
<li>Время безотказной работы (Uptime)
<ul>
<li>Время, в течение которого API Gateway остаётся доступным и
функционирующим.</li>
<li>Помогает оценить надёжность системы.</li>
</ul></li>
<li>Частота отказов (Failure Frequency)
<ul>
<li>Количество отказов API Gateway за определённый период.</li>
<li>Высокая частота отказов указывает на проблемы с надёжностью.</li>
</ul></li>
</ul></li>
<li><p>Метрики производительности кеша</p>
<ul>
<li>Процент попаданий в кеш (Cache Hit Rate)
<ul>
<li>Процент запросов, которые обрабатываются из кеша.</li>
<li>Высокий процент попаданий в кеш улучшает производительность и
снижает нагрузку на сервер.</li>
</ul></li>
<li>Процент промахов в кеше (Cache Miss Rate)
<ul>
<li>Процент запросов, которые не были найдены в кеше и потребовали
обращения к исходному серверу.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="пример-использование-api-gateway-в-weathernow-1">Пример,
Использование API Gateway в WeatherNow</h4>
<ul>
<li><p>как использовать API Gateway для обеспечения маршрутизации
запросов,</p>
<ul>
<li>управления аутентификацией и авторизацией и обеспечения безопасности
в системе WeatherNow.</li>
</ul></li>
<li><p>API Gateway позволяет настроить маршрутизацию запросов к
различным микросервисам, обеспечивая их доступность и управление
трафиком.</p></li>
<li><p>Определение маршрутов для различных микросервисов</p>
<ul>
<li><p>Маршрутизация запросов к сервису данных о погоде:</p>
<pre><code>curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data &#39;name=weather-data-service&#39; \
  --data &#39;url=http://weather-data-service:8000&#39;

  curl -i -X POST \
  --url http://localhost:8001/services/weather-data-service/routes \
  --data &#39;paths[]=/weather-data&#39;</code></pre></li>
<li><p>Маршрутизация запросов к сервису уведомлений</p>
<pre><code>curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data &#39;name=notification-service&#39; \
  --data &#39;url=http://notification-service:8000&#39;

  curl -i -X POST \
  --url http://localhost:8001/services/notification-service/routes \
  --data &#39;paths[]=/notifications&#39;</code></pre></li>
<li><p>Маршрутизация запросов к сервису аналитики:</p>
<pre><code>curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data &#39;name=analytics-service&#39; \
  --data &#39;url=http://analytics-service:8000&#39;

  curl -i -X POST \
  --url http://localhost:8001/services/analytics-service/routes \
  --data &#39;paths[]=/analytics&#39;</code></pre></li>
<li><p>Пример настройки маршрутизации в конфигурационном файле
Kong:</p></li>
</ul>
<pre><code>services:
   - name: weather-data-service
     url: http://weather-data-service:8000
     routes:
     - paths:
       - /weather-data

   - name: notification-service
     url: http://notification-service:8000
     routes:
     - paths:
       - /notifications

   - name: analytics-service
     url: http://analytics-service:8000
     routes:
     - paths:
       - /analytics</code></pre></li>
<li><p>Настройка аутентификации пользователей</p></li>
<li><p>API Gateway может управлять аутентификацией и авторизацией,
обеспечивая безопасность и контроль доступа к микросервисам.</p>
<ul>
<li>Использование JWT для аутентификации:</li>
</ul></li>
</ul>
<pre><code>
  curl -i -X POST \
  --url http://localhost:8001/services/weather-data-service/plugins/ \
  --data &#39;name=jwt&#39;
    
  curl -i -X POST \
  --url http://localhost:8001/consumers/ \
  --data &#39;username=weather-consumer&#39;
    
  curl -i -X POST \
  --url http://localhost:8001/consumers/weather-consumer/jwt/ \
  --data &#39;key=weather-key&#39; \
  --data &#39;algorithm=HS256&#39;

</code></pre>
<ul>
<li>Управление правами доступа к различным сервисам</li>
</ul>
<pre><code>
curl -i -X POST \
  --url http://localhost:8001/services/weather-data-service/plugins/ \
  --data &#39;name=acl&#39; \
  --data &#39;config.whitelist=weather-admin&#39;
    
  curl -i -X POST \
  --url http://localhost:8001/consumers/weather-consumer/acls \
  --data &#39;group=weather-admin&#39;

</code></pre>
<ul>
<li>Обеспечение безопасности и защита данных
<ul>
<li>API Gateway может применять различные политики безопасности для
защиты данных и обеспечения надёжности системы.</li>
</ul></li>
<li>Настройка шифрования данных в транзите с использованием HTTPS:</li>
</ul>
<pre><code>
curl -i -X POST \
  --url http://localhost:8001/services/weather-data-service/plugins/ \
  --data &#39;name=ssl&#39; \
  --data &#39;config.cert=/path/to/cert.pem&#39; \
  --data &#39;config.key=/path/to/key.pem&#39;

</code></pre>
<ul>
<li>Настройка лимитирования запросов (Rate Limiting):</li>
</ul>
<pre><code>
  curl -i -X POST \
    --url http://localhost:8001/services/weather-data-service/plugins/ \
    --data &#39;name=rate-limiting&#39; \
    --data &#39;config.minute=100&#39; \
    --data &#39;config.hour=1000&#39;

</code></pre>
<ul>
<li>Настройка защиты от DDoS-атак:</li>
</ul>
<pre><code>
  curl -i -X POST \
   --url http://localhost:8001/services/weather-data-service/plugins/ \
   --data &#39;name=ip-restriction&#39; \
   --data &#39;config.whitelist=192.168.1.0/24&#39;

</code></pre>
<h2
id="взаимодействие-микросервисов-с-использованием-kafka-1">Взаимодействие
микросервисов с использованием Kafka</h2>
<ul>
<li>проблемы при использовании синхронного подхода
<ul>
<li>Синхронизация данных
<ul>
<li>пример, необходимость обеспечивать консистентность данных о погоде,
поступающих от различных источников (метеостанции, спутники, сенсоры
IoT),
<ul>
<li>создала задержки и несоответствия.</li>
<li>Конфликты данных возникали из-за одновременной обработки информации
с разной частотой обновления, что снижало точность прогнозов.</li>
</ul></li>
</ul></li>
<li>Масштабируемость
<ul>
<li>с увеличением числа пользователей и объёма данных система начала
сталкиваться с узкими местами.</li>
<li>Синхронные вызовы создавали задержки и ограничивали возможность
горизонтального масштабирования,
<ul>
<li>что ухудшало производительность и пользовательский опыт.</li>
</ul></li>
</ul></li>
<li>Управление трафиком
<ul>
<li>в пиковые моменты (например, крупные метеорологические события)
система перегружалась из-за увеличения количества запросов.</li>
<li>Синхронное решение не обеспечивало равномерное распределение
нагрузки, что приводило к перегрузкам и снижению доступности.</li>
</ul></li>
<li>Надёжность и устойчивость к сбоям
<ul>
<li>сбой одного из компонентов (например, сервера обработки данных)
влиял на всю систему.</li>
<li>Синхронные вызовы создавали цепочку зависимостей, где сбой одного
компонента блокировал работу других, что снижало общую устойчивость
системы.</li>
</ul></li>
</ul></li>
<li>Эти проблемы можно решить асинхронным взаимодействием,
<ul>
<li>которое уменьшает зависимость между сервисами, улучшает
производительность и масштабируемость системы</li>
</ul></li>
<li>Асинхронное взаимодействие эффективно реализуется с помощью Apache
Kafka,
<ul>
<li>которая предоставляет высокопроизводительный и надёжный брокер
сообщений.</li>
</ul></li>
</ul>
<h3 id="взаимодействие-между-микросервисами-1">Взаимодействие между
микросервисами</h3>
<ul>
<li>Синхронное взаимодействие
<ul>
<li>клиентский сервис отправляет запрос и ждёт ответа от
сервиса-получателя перед тем, как продолжить выполнение своей логики.
<ul>
<li>Обычно это реализуется через HTTP или RPC (Remote Procedure
Call).</li>
</ul></li>
<li>Примеры использования:
<ul>
<li>REST API: клиент отправляет HTTP-запрос к REST API сервиса и ждёт
ответа с данными.</li>
<li>gRPC: клиент вызывает удалённую процедуру и ждёт результата
выполнения.</li>
</ul></li>
</ul></li>
<li>Асинхронное взаимодействие
<ul>
<li>позволяет сервисам отправлять сообщения и события без необходимости
немедленного получения ответа
<ul>
<li>осуществляется через брокеры сообщений, очереди или системы
событийного взаимодействия</li>
</ul></li>
<li>Примеры использования:
<ul>
<li>Message Queueing: сервисы отправляют сообщения в очередь, и
получатели обрабатывают их по мере готовности.</li>
<li>Event Sourcing: изменения состояния системы сохраняются как
последовательность событий, которые могут быть обработаны
асинхронно.</li>
<li>Publish/Subscribe: издатели отправляют сообщения в топики, на
которые подписаны потребители, и все подписчики получают сообщения
асинхронно.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="основные-концепции-синхронного-взаимодействия-1">Основные
концепции синхронного взаимодействия</h3>
<ul>
<li>Синхронное взаимодействие
<ul>
<li>это подход к обмену данными между компонентами системы, при котором
клиент (или инициатор запроса)
<ul>
<li>ожидает завершения операции и получения ответа от сервера (или
обработчика запроса) до продолжения своей работы.</li>
</ul></li>
</ul></li>
<li>ключевые концепции:
<ul>
<li>запрос-Ответ (Request-Response)
<ul>
<li>плюсы: простой и понятный подход, обеспечивает чёткую
последовательность операций.</li>
<li>минусы: клиент блокируется, пока сервер не завершит обработку
запроса, что может привести к задержкам и снижению
производительности.</li>
</ul></li>
<li>Тайм-ауты (Timeouts)
<ul>
<li>тайм-ауты используются для ограничения времени ожидания ответа от
сервера.
<ul>
<li>Если сервер не отвечает в установленное время, клиент получает
ошибку тайм-аута.</li>
</ul></li>
<li>Плюсы: помогает избежать бесконечного ожидания и позволяет клиенту
обработать ошибки.</li>
<li>Минусы: тайм-ауты могут быть сложны в настройке и управлении,
особенно при высоких нагрузках и изменяющихся условиях сети.</li>
</ul></li>
<li>Блокировка (Blocking):
<ul>
<li>в синхронном взаимодействии клиентский поток блокируется до
получения ответа от сервера.
<ul>
<li>В этот период клиент не может выполнять другие операции.</li>
</ul></li>
<li>Плюсы: простота реализации и отладки.</li>
<li>Минусы: может привести к снижению производительности и отзывчивости
системы, особенно при высоких нагрузках.</li>
</ul></li>
<li>Зависимости (Dependencies):
<ul>
<li>при синхронном взаимодействии операции часто зависят друг от друга.
<ul>
<li>Если одна операция не завершена, последующие операции не могут быть
выполнены.</li>
</ul></li>
<li>Плюсы: позволяет легко отслеживать порядок выполнения операций и
управлять им.</li>
<li>Минусы: могут возникать узкие места и блокировки, особенно при сбоях
или перегрузках в системе.</li>
</ul></li>
<li>Управление состоянием (State Management):
<ul>
<li>управление состоянием может быть сложным, поскольку состояние может
изменяться в зависимости от результата каждого запроса.</li>
<li>Плюсы: лёгкость в управлении состоянием при небольших масштабах и
простой архитектуре.</li>
<li>Минусы: может стать сложным при увеличении масштабов системы и
увеличении числа взаимодействующих компонентов.</li>
</ul></li>
<li>Изоляция ошибок (Error Isolation):
<ul>
<li>ошибки, возникающие в одном компоненте, могут передаваться и влиять
на другие компоненты,
<ul>
<li>поскольку клиент ожидает завершения всей цепочки операций.</li>
</ul></li>
<li>Плюсы: простота обработки ошибок при небольших системах.</li>
<li>Минусы: ошибки могут распространяться по всей системе, что усложняет
управление и отладку.</li>
</ul></li>
<li>Параллелизм (Parallelism):
<ul>
<li>синхронное взаимодействие ограничивает возможности параллельного
выполнения операций, поскольку клиент блокируется до получения
ответа.</li>
<li>Плюсы: упрощает поток выполнения операций в определённом
порядке.</li>
<li>Минусы: ограничивает возможности масштабирования и параллельного
выполнения задач.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="основные-концепции-асинхронного-взаимодействия-1">Основные
концепции асинхронного взаимодействия</h3>
<ul>
<li>Асинхронное взаимодействие между микросервисами — важная
составляющая современных распределённых систем.
<ul>
<li>Оно позволяет микросервисам «общаться» без необходимости
немедленного ответа, что значительно улучшает масштабируемость и
надёжность системы.</li>
</ul></li>
<li>основные концепции асинхронного взаимодействия, в том числе
сообщения, события, очереди.
<ul>
<li>Сообщения
<ul>
<li>представляют собой единицы данных, которые отправляются от одного
микросервиса к другому.</li>
<li>Могут содержать информацию о событиях, данных или командах для
выполнения определённых действий.</li>
</ul></li>
<li>События
<ul>
<li>это уведомления о произошедших изменениях в системе, позволяют
микросервисам реагировать на изменения состояния системы.</li>
<li>Например, событие может указывать на то, что новый пользователь
зарегистрировался или что обновились данные о погоде.</li>
</ul></li>
<li>Очереди
<ul>
<li>используются для временного хранения сообщений или событий до тех
пор, пока получатель не будет готов их обработать.</li>
<li>обеспечивают надёжную доставку и помогают справляться с пиковыми
нагрузками, распределяя обработку сообщений во времени.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="пуш-push-и-пул-pull-подходы-1">Пуш (Push) и Пул (Pull)
подходы</h4>
<ul>
<li>Push-подход
<ul>
<li>отправитель данных (продюсер) активно отправляет данные получателю
(консьюмеру).</li>
<li>Подход часто используется в моделях Publish/Subscribe и Event
Sourcing.</li>
<li>пример: WeatherNow: сервисы, отвечающие за публикацию данных о
погоде, отправляют обновления в топики Kafka,
<ul>
<li>на которые подписаны другие сервисы (например, уведомления и
аналитика).</li>
</ul></li>
</ul></li>
<li>Pull-подход</li>
<li>получатель данных (консьюмер) активно запрашивает данные у
отправителя (продюсера) или из хранилища (например, очереди
сообщений).</li>
<li>Подход часто используется в моделях Message Queueing.</li>
<li>пример: WeatherNow: сервисы обработки данных запрашивают обновления
из очереди сообщений,
<ul>
<li>чтобы обрабатывать данные о погоде по мере их поступления. <img
src="images/img_53.png" alt="img_53.png" /></li>
</ul></li>
<li>пример</li>
</ul>
<pre><code>
Описание архитектуры
Сбор данных:
Сенсоры и источники данных (Sensors and Data Sources): данные о погоде поступают от различных сенсоров, внешних API и спутников. 
  Эти источники отправляют данные в брокер сообщений.

Message Broker (Kafka): брокер сообщений (например, Apache Kafka) используется для приёма и хранения входящих данных 
  о погоде от различных источников. Брокер сообщений гарантирует надёжную доставку данных и масштабируемость системы.

Обработка данных:
Data Processing: сервис обработки данных извлекает сообщения из брокера, обрабатывает их и сохраняет в хранилище событий (Event Store). 
  Обработанные данные затем публикуются обратно в брокер для дальнейшего использования другими сервисами.

Event Store: события находятся в хранилище событий, что позволяет отслеживать изменения состояния системы и выполнять анализ данных.

Уведомления и аналитика:
Notification and Analysis: сервисы уведомлений и аналитики подписываются на обновления данных о погоде из брокера сообщений.
  Сервис уведомлений отправляет пользователям предупреждения о значительных изменениях погоды, а сервис аналитики анализирует данные и помещает результаты в хранилище событий.

Взаимодействие с пользователями:
User Interaction: пользователи взаимодействуют с системой через мобильное или веб-приложение. 
  Они отправляют запросы на получение текущей погоды через API Gateway. API Gateway запрашивает последние данные у брокера сообщений и передаёт их пользователям для отображения в приложениях.

</code></pre>
<h4 id="паттерны-асинхронного-взаимодействия-1">Паттерны асинхронного
взаимодействия</h4>
<ul>
<li>Message Queueing (Очередь сообщений)
<ul>
<li>модель взаимодействия, при которой сообщения отправляются в очередь,
где они хранятся до тех пор,
<ul>
<li>пока получатель (консьюмер) не будет готов их обработать.</li>
</ul></li>
<li>Пример. Погодные данные от различных сенсоров отправляются в очередь
сообщений и обрабатываются консьюмерами, которые обновляют базу данных.
<img src="images/img_54.png" alt="img_54.png" /></li>
</ul></li>
<li>Event Sourcing (Хранение событий)
<ul>
<li>паттерн, при котором состояние системы сохраняется как
последовательность событий.
<ul>
<li>Каждое изменение состояния записывается как событие, и текущее
состояние системы можно восстановить путём проигрывания всех
событий.</li>
</ul></li>
<li>Пример. Каждое обновление погодных данных записывается как событие,
которое затем обрабатывается для обновления конечного состояния системы.
<img src="images/img_55.png" alt="img_55.png" /></li>
</ul></li>
<li>Publish/Subscribe (Публикация/Подписка)
<ul>
<li>это модель взаимодействия, при которой издатели отправляют сообщения
в один или несколько топиков,
<ul>
<li>на которые подписаны консьюмеры. Все подписчики получают сообщения
асинхронно.</li>
</ul></li>
<li>Пример. Сервисы, отвечающие за публикацию погодных данных,
отправляют обновления в топик,
<ul>
<li>на который подписаны другие сервисы (например, уведомления и
аналитика).</li>
</ul></li>
</ul></li>
<li>Choreography (Хореография)
<ul>
<li>это паттерн, при котором каждый микросервис реагирует на события и
производит собственные события для других микросервисов.</li>
<li>Взаимодействие координируется без центрального контроля.</li>
<li>Пример. Сервисы обмена данными о погоде реагируют на события, такие
как обновления данных от сенсоров,
<ul>
<li>и отправляют собственные события (например, оповещения о плохой
погоде). <img src="images/img_56.png" alt="img_56.png" /></li>
</ul></li>
</ul></li>
<li>Orchestration (Оркестрация)
<ul>
<li>это паттерн, при котором централизованный компонент (оркестратор)
управляет взаимодействием между микросервисами,
<ul>
<li>инициируя и контролируя выполнение задач.</li>
</ul></li>
<li>Пример. Центральный сервис оркестрации управляет последовательностью
шагов для обработки и распространения данных о погоде,
<ul>
<li>начиная с получения данных от сенсоров и заканчивая отправкой
уведомлений пользователям.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="openapi-vs-asyncapi-1">OpenAPI vs AsyncAPI</h3>
<ul>
<li><p>OpenAPI и AsyncAPI — два популярных стандарта, которые помогают
разработчикам описывать синхронные и асинхронные API
соответственно.</p></li>
<li><p>OpenAPI</p>
<ul>
<li>это спецификация для описания RESTful API, которая позволяет
разработчикам документировать эндпоинты, методы, параметры и ответы
API.</li>
<li>широко используется для описания синхронных взаимодействий между
сервисами.</li>
<li>Плюсы:
<ul>
<li>Улучшенная документация
<ul>
<li>стандартизированный формат позволяет легко документировать и
понимать структуру API.</li>
</ul></li>
<li>Инструменты и генерация кода
<ul>
<li>существуют многочисленные инструменты для автоматической генерации
кода, клиентских библиотек и документации на основе спецификаций
OpenAPI.</li>
</ul></li>
<li>Совместимость
<ul>
<li>поддержка различных протоколов HTTP и интеграция с популярными
платформами и фреймворками.</li>
</ul></li>
</ul></li>
<li>Пример. В WeatherNow OpenAPI используется для документирования
RESTful API, который предоставляет данные о текущей погоде
пользователям.</li>
</ul></li>
</ul>
<pre><code>
openapi: &#39;3.0.0&#39;
info:
  title: WeatherNow API
  version: &#39;1.0.0&#39;
paths:
  /weather:
    get:
      summary: Get current weather
      responses:
        &#39;200&#39;:
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  temperature:
                    type: number
                  humidity:
                    type: number
                  timestamp:
                    type: string
                    format: date-time

</code></pre>
<ul>
<li>AsyncAPI
<ul>
<li>это спецификация для документирования и проектирования асинхронных
API.</li>
<li>Подобно OpenAPI для синхронных API, AsyncAPI позволяет описывать
структуры сообщений, каналы и взаимодействия между компонентами в
асинхронной системе.</li>
<li>Плюсы:
<ul>
<li>Улучшенная документация
<ul>
<li>стандартизированный формат позволяет легко документировать и
понимать структуру и взаимодействие асинхронных систем.</li>
</ul></li>
<li>Инструменты и генерация кода
<ul>
<li>существуют инструменты для автоматической генерации кода, клиентских
библиотек и документации на основе спецификаций AsyncAPI.</li>
</ul></li>
<li>Совместимость
<ul>
<li>поддержка различных протоколов и брокеров сообщений — Kafka, MQTT,
AMQP.</li>
</ul></li>
</ul></li>
<li>Пример. В WeatherNow спецификация AsyncAPI используется для
документирования взаимодействий между микросервисами
<ul>
<li>публикация данных о погоде в топики Kafka и подписка на эти топики
для получения</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
asyncapi: &#39;2.0.0&#39;
info:
  title: WeatherNow Async API
  version: &#39;1.0.0&#39;
servers:
  production:
    url: api.weathernow.com
    protocol: kafka
channels:
  weather-updates:
    description: Channel for publishing weather updates
    publish:
      summary: Publish weather data
      operationId: publishWeatherData
      message:
        contentType: application/json
        payload:
          type: object
          properties:
            temperature:
              type: number
            humidity:
              type: number
            timestamp:
              type: string
              format: date-time

</code></pre>
<ul>
<li>Kafka — уникальна среди популярных брокеров сообщений, потому что:
<ul>
<li>не использует стандартный внешний протокол (как AMQP или MQTT);</li>
<li>сама определяет свой собственный формат взаимодействия (wire
protocol);</li>
<li>Kafka — это и платформа, и протокол в одном.</li>
</ul></li>
<li>RabbitMQ, MQTT-брокеры и другие — разделены
<ul>
<li>RabbitMQ, ActiveMQ, Qpid → работают по AMQP (Advanced Message
Queuing Protocol)</li>
<li>Mosquitto, EMQX, HiveMQ → работают по MQTT</li>
<li>NATS → имеет свой протокол, но обычно указывается как “протокол
NATS”, а не “брокер NATS”</li>
</ul></li>
</ul>
<figure>
<img src="images/img_57.png" alt="img_57.png" />
<figcaption aria-hidden="true">img_57.png</figcaption>
</figure>
<h3 id="kafka-для-асинхронного-обмена-1">Kafka для асинхронного
обмена</h3>
<ul>
<li>Apache Kafka
<ul>
<li>это распределённая стриминговая платформа, разработанная для
публикации, подписки, хранения и обработки потоков данных в реальном
времени.</li>
<li>один из ключевых инструментов для обработки больших данных</li>
</ul></li>
<li>помогает решить следующие проблемы
<ul>
<li>Задержки в обработке данных
<ul>
<li>позволяет обрабатывать данные в режиме реального времени,
распределяя нагрузку</li>
<li>и обеспечивая быструю передачу данных между источниками и
потребителями.</li>
</ul></li>
<li>Масштабируемость
<ul>
<li>легко масштабируется горизонтально, добавляя новые брокеры и разделы
(англ. partitions)</li>
</ul></li>
<li>Надёжность и устойчивость к сбоям
<ul>
<li>обеспечивает высокую надёжность и устойчивость к сбоям благодаря
репликации данных и возможностям восстановления после сбоев</li>
</ul></li>
<li>Управление трафиком и балансировка нагрузки
<ul>
<li>обеспечивает эффективное управление трафиком и балансировку
нагрузки, равномерно распределяя сообщения между потребителями</li>
</ul></li>
</ul></li>
<li>Преимущества Apache Kafka
<ul>
<li>Высокая производительность
<ul>
<li>Kafka может обрабатывать миллионы сообщений в секунду — идеально для
систем с большим объёмом данных.</li>
</ul></li>
<li>Масштабируемость
<ul>
<li>Kafka позволяет горизонтально масштабировать кластер, добавляя новые
брокеры, что обеспечивает высокую производительность и надёжность даже
при увеличении нагрузки.</li>
</ul></li>
<li>Надёжность
<ul>
<li>Kafka поддерживает репликацию данных между брокерами, что
обеспечивает устойчивость к сбоям и высокую доступность системы.</li>
</ul></li>
<li>Долговременное хранение
<ul>
<li>Kafka хранит сообщения в течение определённого времени, что
позволяет воспроизводить данные и анализировать события задним
числом.</li>
</ul></li>
<li>Поддержка различных моделей взаимодействия
<ul>
<li>Kafka поддерживает модели Publish/Subscribe, Event Sourcing и
Message Queueing.</li>
</ul></li>
</ul></li>
<li>Архитектура и основные компоненты Kafka
<ul>
<li>Брокеры (Brokers)
<ul>
<li>Узлы в кластере Kafka, которые хранят и обрабатывают данные.</li>
<li>Каждый брокер отвечает за управление одним или несколькими разделами
(англ. partitions) топиков.</li>
</ul></li>
<li>Топики (Topics)
<ul>
<li>Логические каналы, по которым передаются сообщения.</li>
<li>Каждый топик может состоять из нескольких разделов для параллельной
обработки.</li>
<li>Назначение — организация сообщений по категориям, обеспечение
параллельной обработки данных.</li>
</ul></li>
<li>Продюсеры (Producers)
<ul>
<li>Клиенты, которые публикуют сообщения в топики.</li>
<li>Продюсеры могут отправлять данные в один или несколько топиков
одновременно.</li>
<li>Занимаются публикацией данных в топики, выбирают разделы для
отправки сообщений (например, по ключу).</li>
</ul></li>
<li>Зоокипер (ZooKeeper)
<ul>
<li>Сервис для координации и управления кластером Kafka.</li>
<li>ZooKeeper используется для хранения метаданных о топиках, брокерах и
смещениях консьюмеров.</li>
<li>Предназначен для управления конфигурацией кластера, координации
работы брокеров, поддержки лидерства разделов.</li>
</ul></li>
</ul></li>
</ul>
<figure>
<img src="images/img_58.png" alt="img_58.png" />
<figcaption aria-hidden="true">img_58.png</figcaption>
</figure>
<h4 id="альтернативы-kafka-1">Альтернативы Kafka</h4>
<ul>
<li>RabbitMQ
<ul>
<li>open-source брокер сообщений, который реализует протокол AMQP
(Advanced Message Queuing Protocol).</li>
<li>Он поддерживает надёжную передачу сообщений, масштабируемость и
гибкость в настройке.</li>
<li>подходит для систем, требующих сложной маршрутизации и гибкой
конфигурации очередей.</li>
<li>Плюсы: поддержка сложных маршрутов, гибкая конфигурация очередей,
поддержка различных протоколов (AMQP, MQTT, STOMP).</li>
<li>Минусы: менее масштабируемый по сравнению с Kafka, сложнее
обеспечить высокую производительность при большом объёме данных.</li>
</ul></li>
<li>ActiveMQ
<ul>
<li>open-source брокер сообщений, реализующий Java Message Service (JMS)
API.</li>
<li>Он также поддерживает другие протоколы обмена сообщениями и
предоставляет возможности для интеграции с Java-приложениями и другими
системами.</li>
<li>Подходит для систем, требующих поддержки множества протоколов и
языков программирования.</li>
<li>Плюсы: поддержка различных протоколов и языков программирования,
гибкость в настройке.</li>
<li>Минусы: менее масштабируемый и производительный по сравнению с
Kafka, есть сложности в управлении и настройке.</li>
</ul></li>
</ul>
<h3 id="настройка-кластера-kafka-1">Настройка кластера Kafka</h3>
<ul>
<li>Настройка кластера Kafka включает установку и конфигурацию
необходимых компонентов (Kafka и ZooKeeper),
<ul>
<li>а также создание и управление топиками</li>
</ul></li>
<li>Шаг 1. Установка Kafka и ZooKeeper
<ul>
<li>скачать https://kafka.apache.org/downloads</li>
<li>распаковать tar -xzf kafka_2.13-2.8.0.tgz</li>
<li>ZooKeeper необходим для координации и управления кластером Kafka.
<ul>
<li>Конфигурационный файл ZooKeeper находится в
config/zookeeper.properties.</li>
<li>Start ZooKeeper - # bin/zookeeper-server-start.sh
config/zookeeper.properties</li>
</ul></li>
<li>Основной конфигурационный файл Kafka находится в
config/server.properties.
<ul>
<li>Убедитесь, что все необходимые параметры настроены, включая ID
брокера, директорию хранения логов и адрес ZooKeeper.
<ul>
<li>Start Kafka Broker - # bin/kafka-server-start.sh
config/server.properties</li>
</ul></li>
</ul></li>
</ul></li>
<li>Шаг 2. Запуск ZooKeeper и Kafka
<ul>
<li>Запустите ZooKeeper с использованием предоставленного скрипта.
<ul>
<li>bin/zookeeper-server-start.sh config/zookeeper.properties</li>
</ul></li>
<li>После запуска ZooKeeper запустите Kafka-брокер.
<ul>
<li>bin/kafka-server-start.sh config/server.properties</li>
</ul></li>
</ul></li>
<li>Шаг 3. Создание топиков
<ul>
<li>Используйте команду kafka-topics.sh для создания нового топика.
<ul>
<li>Укажите параметры — имя топика, количество разделов и фактор
репликации (англ. replication factor).
<ul>
<li>bin/kafka-topics.sh –create –topic weather-data –bootstrap-server
localhost:9092 –partitions 3 –replication-factor 1</li>
</ul></li>
</ul></li>
<li>Проверьте, что топик был успешно создан.
<ul>
<li>bin/kafka-topics.sh –list –bootstrap-server localhost:9092</li>
</ul></li>
<li>Команда –describe позволяет получить подробную информацию о топике,
включая количество разделов, фактор репликации и статус разделов.
<ul>
<li>bin/kafka-topics.sh –describe –topic my-topic –bootstrap-server
localhost:9092</li>
</ul></li>
<li>Топики в Kafka могут быть настроены с различными параметрами для
оптимизации производительности и надёжности.
<ul>
<li>retention.ms:
<ul>
<li>Определяет время хранения сообщений в топике.</li>
<li>Пример: хранить сообщения в течение 7 дней (604800000 миллисекунд).
<ul>
<li>bin/kafka-topics.sh –alter –topic my-topic –config
retention.ms=604800000 –bootstrap-server localhost:9092</li>
</ul></li>
</ul></li>
<li>cleanup.policy:
<ul>
<li>Определяет политику очистки сообщений (например, удаление старых
сообщений или компактирование).</li>
<li>Пример: настроить политику очистки на удаление (delete).
<ul>
<li>bin/kafka-topics.sh –alter –topic my-topic –config
cleanup.policy=delete</li>
</ul></li>
</ul></li>
<li>min.insync.replicas:
<ul>
<li>Определяет минимальное количество реплик, которые должны подтвердить
запись, прежде чем продюсер получит подтверждение.</li>
<li>Пример: установить минимальное количество реплик на 2.
<ul>
<li>bin/kafka-topics.sh –alter –topic my-topic –config
min.insync.replicas=2 –bootstrap-server localhost:9092</li>
</ul></li>
</ul></li>
</ul></li>
<li>Разделы позволяют распределять данные топика по нескольким брокерам
для обеспечения параллельной обработки и масштабируемости.
<ul>
<li>добавить разделы к существующему топику с помощью команды –alter.
<ul>
<li>bin/kafka-topics.sh –alter –topic my-topic –partitions 5
–bootstrap-server localhost:9092
<ul>
<li>alter: указывает, что необходимо изменить существующий топик.</li>
<li>partitions: новое количество разделов.</li>
</ul></li>
</ul></li>
<li>Для эффективного использования ресурсов кластера важно обеспечить
равномерное распределение разделов по брокерам.</li>
<li>Команда kafka-reassign-partitions.sh помогает в балансировке
разделов.
<ul>
<li>bin/kafka-reassign-partitions.sh –generate –zookeeper localhost:2181
–topics-to-move-json-file topics-to-move.json –broker-list “0,1,2”
<ul>
<li>generate: генерирует план переассигнования разделов.</li>
<li>zookeeper: адрес сервера ZooKeeper.</li>
<li>topics-to-move-json-file: файл JSON, содержащий список топиков для
переассигнования.</li>
<li>broker-list: список брокеров, среди которых будут распределены
разделы.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>Шаг 4. Настройка продюсеров и консьюмеров в общем виде
<ul>
<li><p>Настройте микросервисы, которые будут выступать в роли
продюсеров, для публикации данных в топики.</p>
<ul>
<li>Используйте клиентские библиотеки Kafka для отправки сообщений.</li>
</ul>
<pre><code> Properties props = new Properties();
 props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
 props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
 props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

 Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
 producer.send(new ProducerRecord&lt;&gt;(&quot;weather-data&quot;, &quot;key&quot;, &quot;value&quot;));
 producer.close();</code></pre></li>
<li><p>Настройте микросервисы, которые будут выступать в роли
консьюмеров, для подписки на топики и обработки сообщений.</p>
<pre><code> Properties props = new Properties();
 props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
 props.put(&quot;group.id&quot;, &quot;weather-consumers&quot;);
 props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
 props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
 props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);

 Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
 consumer.subscribe(Arrays.asList(&quot;weather-data&quot;));

 while (true) {
   ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100));
   for (ConsumerRecord&lt;String, String&gt; record : records)
     System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());
 }
</code></pre>
<figure>
<img src="images/img_59.png" alt="img_59.png" />
<figcaption aria-hidden="true">img_59.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="интеграция-kafka-с-микросервисами-java-1">Интеграция Kafka с
микросервисами Java</h3>
<figure>
<img src="images/img_60.png" alt="img_60.png" />
<figcaption aria-hidden="true">img_60.png</figcaption>
</figure>
<ul>
<li>Настройка продюсера
<ul>
<li>Установка зависимостей pom.xml</li>
</ul>
<pre><code>  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
    &lt;version&gt;2.8.0&lt;/version&gt;
  &lt;/dependency&gt;</code></pre>
<ul>
<li>Конфигурация продюсера
<ul>
<li>адреса брокеров, сериализаторы ключей и значений.</li>
</ul>
<pre><code>Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre></li>
</ul></li>
<li>Настройка консьюмера
<ul>
<li>Установка зависимостей</li>
</ul>
<pre><code>  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
    &lt;version&gt;2.8.0&lt;/version&gt;
  &lt;/dependency&gt;</code></pre>
<ul>
<li>Конфигурация консьюмера
<ul>
<li>адреса брокеров, десериализаторы ключей и значений, идентификатор
группы консьюмеров.</li>
</ul>
<pre><code>Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;group.id&quot;, &quot;weather-consumers&quot;);
props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);

Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
consumer.subscribe(Arrays.asList(&quot;weather-data&quot;));</code></pre></li>
</ul></li>
<li>Отправка и получение сообщений
<ul>
<li><p>Публикация данных сенсоров (Sensors aka SensorProducer)</p>
<pre><code>ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;weather-data&quot;, &quot;sensor1&quot;, &quot;temperature=25,humidity=60&quot;);
producer.send(record);
producer.close();</code></pre></li>
<li><p>Обработка данных и уведомления (DataProcessor и
NotificationService aka DataProcessorConsumer и
NotificationConsumer)</p>
<ul>
<li><p>Сервис обработки данных считывает данные из топика, обрабатывает
их и публикует результаты в новый топик.</p></li>
<li><p>Сервис уведомлений подписывается на этот топик и отправляет
уведомления пользователям.</p>
<pre><code>// Консьюмер для обработки данных
Consumer&lt;String, String&gt; dataConsumer = new KafkaConsumer&lt;&gt;(props);
dataConsumer.subscribe(Arrays.asList(&quot;weather-data&quot;));
while (true) {
  ConsumerRecords&lt;String, String&gt; records = dataConsumer.poll(Duration.ofMillis(100));
  for (ConsumerRecord&lt;String, String&gt; record : records) {
    // Обработка данных
    String processedData = processData(record.value());
    // Публикация обработанных данных
    ProducerRecord&lt;String, String&gt; processedRecord = new ProducerRecord&lt;&gt;(&quot;processed-weather-data&quot;, record.key(), processedData);
    producer.send(processedRecord);
  }
}

// Консьюмер для уведомлений
Consumer&lt;String, String&gt; notificationConsumer = new KafkaConsumer&lt;&gt;(props);
notificationConsumer.subscribe(Arrays.asList(&quot;processed-weather-data&quot;));
while (true) {
  ConsumerRecords&lt;String, String&gt; records = notificationConsumer.poll(Duration.ofMillis(100));
  for (ConsumerRecord&lt;String, String&gt; record : records) {
    // Отправка уведомлений
    sendNotification(record.value());
  }
}</code></pre></li>
</ul></li>
<li><p>Аналитика данных (AnalyticsService aka AnalyticsConsumer)</p>
<ul>
<li><p>Сервис аналитики подписывается на топик с обработанными данными и
выполняет анализ</p>
<pre><code>// Консьюмер для аналитики
 Consumer&lt;String, String&gt; analyticsConsumer = new KafkaConsumer&lt;&gt;(props);
 analyticsConsumer.subscribe(Arrays.asList(&quot;processed-weather-data&quot;));
 while (true) {
   ConsumerRecords&lt;String, String&gt; records = analyticsConsumer.poll(Duration.ofMillis(100));
   for (ConsumerRecord&lt;String, String&gt; record : records) {
     // Анализ данных
     analyzeData(record.value());
     // Сохранение результатов анализа
     saveAnalysisResults(record.value());
   }
 }</code></pre>
<figure>
<img src="images/img_61.png" alt="img_61.png" />
<figcaption aria-hidden="true">img_61.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul>
<h3 id="мониторинг-и-отладка-работы-kafka-в-продакшене-1">Мониторинг и
отладка работы Kafka в продакшене</h3>
<ul>
<li>позволяет отслеживать состояние системы, выявлять и устранять
проблемы, оптимизировать производительность.
<ul>
<li>Основные аспекты мониторинга — отслеживание метрик
производительности, состояния брокеров и топиков.</li>
</ul></li>
<li>Kafka Manager</li>
<li>Веб-интерфейс для управления и мониторинга кластера Kafka.
<ul>
<li>Функции: мониторинг состояния брокеров, топиков, продюсеров и
консьюмеров, управление топиками и разделами.</li>
<li>Установка и настройка: Kafka Manager можно установить из
официального репозитория Kafka Manager.</li>
</ul></li>
<li>Prometheus и Grafana
<ul>
<li>система мониторинга и алертинга с открытым исходным кодом, Grafana —
инструмент визуализации данных.</li>
<li>Функции: сбор метрик Kafka, создание дашбордов для визуализации
данных, настройка алертов.</li>
<li>Установка и настройка: Prometheus и Grafana можно установить из
официальных репозиториев Prometheus и Grafana.</li>
</ul></li>
<li>JMX Exporter
<ul>
<li>инструмент для экспорта метрик Kafka в формате, совместимом с
Prometheus.</li>
<li>Функции: экспорт метрик JVM и Kafka для мониторинга с помощью
Prometheus.</li>
<li>Установка и настройка: JMX Exporter можно установить из официального
репозитория JMX Exporter.</li>
</ul></li>
<li>Основные метрики для мониторинга Kafka
<ul>
<li>Производительность продюсеров и консьюмеров
<ul>
<li>Метрики: количество отправленных/полученных сообщений, задержка
отправки/получения сообщений, скорость обработки сообщений.</li>
<li>Инструменты: Kafka Manager, Prometheus, Grafana.</li>
</ul></li>
<li>Состояние брокеров
<ul>
<li>Метрики: загрузка CPU и памяти, количество открытых файловых
дескрипторов, время отклика, состояние дисков.</li>
<li>Инструменты: Prometheus, Grafana.</li>
</ul></li>
<li>Состояние топиков и разделов
<ul>
<li>Метрики: количество сообщений в топиках, задержка в потреблении
(англ. consumer lag), распределение разделов по брокерам.</li>
<li>Инструменты: Kafka Manager, Prometheus, Grafana.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="отладка-работы-kafka-1">Отладка работы Kafka</h4>
<ul>
<li><p>состоит из анализа логов, тестирования топиков и сообщений,
использования инструментов для диагностики и устранения
проблем.</p></li>
<li><p>Kafka CLI (Command Line Interface) - набор команд</p>
<ul>
<li>Функции: создание и управление топиками, просмотр информации о
брокерах и топиках, тестирование продюсеров и консьюмеров.</li>
<li>Примеры команд:
<ul>
<li>Создание топика:
<ul>
<li>bin/kafka-topics.sh –create –topic weather-data –bootstrap-server
localhost:9092 –partitions 3 –replication-factor 1</li>
</ul></li>
<li>Просмотр списка топиков:
<ul>
<li>bin/kafka-topics.sh –list –bootstrap-server localhost:9092</li>
</ul></li>
<li>Тестирование продюсера:
<ul>
<li>bin/kafka-console-producer.sh –topic weather-data –bootstrap-server
localhost:9092</li>
</ul></li>
<li>Тестирование консьюмера:
<ul>
<li>bin/kafka-console-consumer.sh –topic weather-data –bootstrap-server
localhost:9092 –from-beginning</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Kafka Tool - Графический интерфейс для управления и мониторинга
Kafka.</p>
<ul>
<li>Функции: просмотр и управление топиками, отправка и получение
сообщений, анализ логов.</li>
<li>Установка и настройка: Kafka Tool можно скачать с официального сайта
Kafka Tool.</li>
</ul></li>
<li><p>Анализ логов</p>
<ul>
<li>Конфигурация логирования:
<ul>
<li>Настройте логирование Kafka для записи информации о работе брокеров,
продюсеров и консьюмеров.</li>
<li>Конфигурационные файлы логирования находятся в
config/log4j.properties.</li>
</ul></li>
<li>Просмотр логов:
<ul>
<li>Проанализируйте логи для выявления и устранения проблем.</li>
<li>Логи брокеров, продюсеров и консьюмеров можно найти в директориях,
указанных в конфигурационных файлах.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="создание-и-использование-helm-чартов-в-kubernetes-1">Создание и
использование Helm-чартов в Kubernetes</h2>
<ul>
<li>Kubernetes и Helm для оркестрации контейнеров</li>
</ul>
<h3 id="оркестрация-контейнеров-1">Оркестрация контейнеров</h3>
<ul>
<li>Оркестрация контейнеров
<ul>
<li>это процесс автоматизации развёртывания, управления, масштабирования
и сетевого взаимодействия контейнеризированных приложений.</li>
</ul></li>
<li>Основные задачи оркестрации контейнеров
<ul>
<li>Автоматическое развёртывание и управление</li>
<li>Масштабирование</li>
<li>Обнаружение сервисов и балансировка нагрузки</li>
<li>Управление конфигурацией и секретами</li>
<li>Мониторинг и восстановление</li>
</ul></li>
<li>примеры
<ul>
<li>Kubernetes
<ul>
<li>самая популярная и мощная система оркестрации контейнеров,
разработанная Google</li>
</ul></li>
<li>Docker Swarm
<ul>
<li>встроенная в Docker система оркестрации</li>
</ul></li>
<li>Apache Mesos и Marathon
<ul>
<li>Mesos — это система распределённого управления ресурсами, которая
может использоваться для оркестрации контейнеров</li>
<li>Marathon - фреймворк для развёртывания контейнеризированных
приложений</li>
</ul></li>
</ul></li>
</ul>
<h3 id="kubernetes">Kubernetes</h3>
<ul>
<li>Kubernetes
<ul>
<li>это открытая система для автоматизации развёртывания,
масштабирования контейнеризированных приложений и управления ими <img
src="images/img_62.png" alt="img_62.png" /></li>
</ul></li>
<li>Основные компоненты
<ul>
<li>Кластер
<ul>
<li>Состоит из одного или нескольких мастер-узлов и рабочих узлов
(nodes)</li>
</ul></li>
<li>Мастер-узлы
<ul>
<li>Управляют состоянием кластера, отвечают за планирование и
координацию работы контейнеров</li>
</ul></li>
<li>Рабочие узлы
<ul>
<li>Запускают контейнеры и управляют ими</li>
</ul></li>
<li>Под (Pod)
<ul>
<li>Наименьшая единица в Kubernetes, представляющая собой один или
несколько контейнеров, которые работают вместе</li>
</ul></li>
<li>Службы (Services)
<ul>
<li>Обеспечивают постоянный доступ к наборам подов, абстрагируя сетевые
детали</li>
</ul></li>
<li>Конфигурации (ConfigMaps) и секреты (Secrets</li>
<li>Контроллеры (Controller Managers)
<ul>
<li>Управляют состоянием приложений, обеспечивают автоматическое
восстановление и масштабирование</li>
</ul></li>
</ul></li>
</ul>
<h3 id="helm-2">Helm</h3>
<ul>
<li><p>Helm</p></li>
<li><p>это пакетный менеджер для Kubernetes, который позволяет легко
управлять развёртыванием, обновлением и удалением приложений.</p></li>
<li><p>Helm упрощает управление Kubernetes-приложениями, предоставляет
удобный способ определения, установки и обновления
Kubernetes-ресурсов</p></li>
<li><p>помощь от Helm в:</p>
<ul>
<li>Сложность развёртывания
<ul>
<li>создают Helm-чарт, который пакетирует все конфигурации
Kubernetes-ресурсов в едином наборе шаблонов.</li>
<li>Используется команда <strong>helm install</strong> для развёртывания
приложения с использованием Helm-чарта</li>
</ul></li>
<li>Управление версиями
<ul>
<li>обновлять приложения и управлять версиями с помощью команды helm
upgrade</li>
<li>откатывать изменения с помощью helm rollback</li>
</ul></li>
<li>Масштабируемость
<ul>
<li>менять конфигурации для масштабирования приложения — нужно просто
исправить значения в values.yaml и обновить релиз. <img
src="images/img_63.png" alt="img_63.png" /></li>
</ul></li>
</ul></li>
</ul>
<h4 id="основные-компоненты-helm-1">Основные компоненты Helm</h4>
<ul>
<li>Чарты (Charts)
<ul>
<li>пакеты Helm, содержащие все необходимые описания Kubernetes-ресурсов
для развёртывания приложения</li>
<li>включают шаблоны YAML-файлов, которые определяют конфигурацию и
ресурсы Kubernetes — Pods, Services, Deployments и другие</li>
<li>могут включать зависимости и скрипты для предварительной и
последующей настройки.</li>
<li>позволяют пакетировать все необходимые конфигурации и зависимости
приложения в один пакет,
<ul>
<li>что делает развёртывание приложений и управление ими более удобным и
повторяемым</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
 # Chart.yaml
 apiVersion: v2
 name: quickdelivery
 description: A Helm chart for QuickDelivery microservice
 type: application
 version: 1.0.0
 appVersion: 1.0.0

 # values.yaml
 replicaCount: 3
 image:
   repository: quickdelivery/microservice
   tag: latest
   pullPolicy: IfNotPresent
 service:
   type: ClusterIP
   port: 8080

 # templates/deployment.yaml
 apiVersion: apps/v1
 kind: Deployment
 metadata:
   name: {{ .Release.Name }}-deployment
 spec:
   replicas: {{ .Values.replicaCount }}
   selector:
     matchLabels:
       app: {{ .Release.Name }}
   template:
     metadata:
       labels:
         app: {{ .Release.Name }}
     spec:
       containers:
         - name: {{ .Chart.Name }}
           image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot;
           ports:
             - containerPort: 8080

</code></pre>
<ul>
<li>Репозитории (Repositories)
<ul>
<li>хранилища, где размещаются чарты.</li>
<li>упрощают доступ к чартам и управление ими, помогают легко находить и
использовать готовые решения для распространённых задач,</li>
<li>позволяют делиться чартами с другими пользователями и
командами.</li>
<li>могут быть публичными или частными.
<ul>
<li>Публичные репозитории (например, Artifact Hub) предоставляют доступ
к большому количеству готовых чартов для различных приложений и
сервисов.</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
 # Добавление репозитория
 helm repo add bitnami https://charts.bitnami.com/bitnami

 # Обновление списка чартов из репозиториев
 helm repo update

 # Поиск чарта в репозитории
 helm search repo bitnami
 

</code></pre>
<ul>
<li>Релизы (Releases)
<ul>
<li>развёрнутые инстансы чартов в кластере Kubernetes.</li>
<li>Каждый раз, когда чарт устанавливается в кластер, создаётся новый
релиз.</li>
<li>Его можно обновлять, отменять и удалять, то есть эффективно
управлять жизненным циклом приложений.</li>
<li>позволяют управлять состоянием развёрнутых приложений, обеспечивают
контроль версий и возможность отката.</li>
<li>Это особенно полезно для управления обновлениями и восстановлением в
случае проблем.</li>
</ul></li>
</ul>
<pre><code>
 # Установка чарта и создание релиза
 helm install quickdelivery ./quickdelivery-chart

 # Просмотр списка релизов
 helm list

 # Обновление релиза
 helm upgrade quickdelivery ./quickdelivery-chart

 # Откат к предыдущей версии релиза
 helm rollback quickdelivery 1

 # Удаление релиза
 helm uninstall quickdelivery
 

</code></pre>
<figure>
<img src="images/img_64.png" alt="img_64.png" />
<figcaption aria-hidden="true">img_64.png</figcaption>
</figure>
<ul>
<li>Зачем нужен Helm
<ul>
<li>Управление приложениями
<ul>
<li>Позволяет легко развёртывать, обновлять и удалять приложения.</li>
</ul></li>
<li>Управление зависимостями
<ul>
<li>Обеспечивает управление зависимостями между компонентами
приложения.</li>
</ul></li>
<li>Версионирование и откаты
<ul>
<li>Позволяет управлять версиями приложений и откатываться к предыдущим
версиям при необходимости.</li>
</ul></li>
<li>Консистентность и воспроизводимость
<ul>
<li>Гарантирует, что развёртывания будут идентичными во всех
средах.</li>
</ul></li>
</ul></li>
<li>Структура Helm-чарта
<ul>
<li>состоит из нескольких файлов и директорий</li>
<li>Chart.yaml
<ul>
<li>основной файл, содержащий метаданные чартов.</li>
<li>Определяет информацию о чарте — имя, версия, описание и другие
метаданные.</li>
</ul>
<pre><code> apiVersion: v2
 name: my-chart
 description: A Helm chart for Kubernetes
 type: application
 version: 1.0.0
 appVersion: 1.0.0</code></pre>
<ul>
<li>appVersion: версия приложения, которую развёртывает этот чарт.</li>
</ul></li>
<li>values.yaml
<ul>
<li>файл конфигурации с параметрами по умолчанию.</li>
<li>Содержит значения конфигурации, которые могут быть изменены при
установке чарта для адаптации к различным средам.
<ul>
<li>replicaCount: количество реплик приложения.</li>
<li>image: настройки Docker-образа.</li>
<li>service: настройки сервиса Kubernetes.</li>
</ul>
<pre><code> replicaCount: 2
 image:
 repository: my-docker-repo/my-app
 tag: latest
 pullPolicy: IfNotPresent
 service:
 type: ClusterIP
 port: 80</code></pre></li>
<li>templates/
<ul>
<li>директория с шаблонами ресурсов Kubernetes.</li>
<li>Тут находятся файлы, которые описывают ресурсы Kubernetes, —
Deployment, Service, ConfigMap и другие.</li>
<li>.Values.replicaCount : использует значение из файла
values.yaml.</li>
<li>.Release.Name : имя релиза Helm.</li>
</ul>
<pre><code> # templates/deployment.yaml
 apiVersion: apps/v1
 kind: Deployment
 metadata:
   name: {{ .Release.Name }}-deployment
 spec:
   replicas: {{ .Values.replicaCount }}
   selector:
     matchLabels:
       app: {{ .Release.Name }}
   template:
     metadata:
       labels:
         app: {{ .Release.Name }}
     spec:
     containers:
       - name: {{ .Chart.Name }}
         image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot;
         ports:
           - containerPort: 80</code></pre></li>
</ul></li>
<li>charts/
<ul>
<li>директория для зависимых чартов. Здесь могут находиться другие
чарты, от которых зависит текущий.</li>
<li>Это позволяет организовать сложные приложения с несколькими
компонентами.</li>
<li>dependencies: список зависимых чартов, которые необходимы для
развёртывания текущего чарта.
<ul>
<li>Эти зависимости автоматически скачиваются в директорию charts/ при
выполнении команды helm dependency update.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<pre><code># Внутри Chart.yaml
dependencies:
- name: mysql
 version: &quot;1.6.4&quot;
 repository: &quot;https://charts.bitnami.com/bitnami&quot;
 condition: mysql.enabled</code></pre>
<ul>
<li>requirements.yaml
<ul>
<li>файл, в котором указываются зависимости чартов.</li>
<li>Позволяет определить, какие другие чарты необходимы для
развёртывания текущего.
<ul>
<li>dependencies: список зависимых чартов с указанием их версий и
репозиториев.</li>
</ul></li>
</ul></li>
</ul>
<pre><code> dependencies:
 - name: redis
   version: &quot;14.8.8&quot;
   repository: &quot;https://charts.bitnami.com/bitnami&quot;
</code></pre>
<ul>
<li>пример</li>
</ul>
<pre><code>
Пример структуры Helm-чарта:
    quickdelivery/
      Chart.yaml
      values.yaml
      templates/
        deployment.yaml
        service.yaml
      charts/
      requirements.yaml
     
Пример шаблона Deployment:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-{{ .Chart.Name }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-{{ .Chart.Name }}
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-{{ .Chart.Name }}
    spec:
      containers:
      - name: {{ .Chart.Name }}
        image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot;
        ports:
        - containerPort: {{ .Values.service.port }}
     
Пример шаблона templates/service.yaml 

apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-service
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: 8080
  selector:
    app: {{ .Release.Name }

</code></pre>
<h4 id="создание-helm-чарта-для-quickdelivery-1">Создание Helm-чарта для
QuickDelivery</h4>
<ul>
<li>Создание нового чарта
<ul>
<li>Задача: Создать базовую структуру Helm-чарта, которая будет
содержать все необходимые файлы и директории для конфигурации
приложения.
<ul>
<li>helm create quickdelivery
<ul>
<li>создаст структуру каталогов и файлов, необходимых для чартов.</li>
<li>получите преднастроенные директории для шаблонов Kubernetes,
конфигурационные файлы и метаданные чарта.</li>
<li>Это помогает стандартизировать структуру и упростить работу с
чартами в будущем</li>
</ul></li>
</ul></li>
</ul></li>
<li>Редактирование Chart.yaml
<ul>
<li>Задача: Указать основные метаданные для вашего приложения, такие как
имя, версия и описание.</li>
<li>В файле Chart.yaml укажите метаданные вашего приложения — имя,
версию и описание.
<ul>
<li>Этот файл определяет ваш чарт и делает его уникальным.</li>
<li>Эти данные полезны для документирования версий чарта и управления
ими.</li>
</ul>
<pre><code> name: quickdelivery
 version: 0.1.0
 description: A Helm chart for QuickDelivery application</code></pre></li>
</ul></li>
<li>Конфигурация values.yaml
<ul>
<li>Задача: Задать параметры конфигурации по умолчанию для вашего
приложения.</li>
<li>В файле values.yaml укажите
<ul>
<li>параметры конфигурации по умолчанию, такие как настройки базы
данных, API-ключи и другие переменные.</li>
<li>Этот файл позволяет централизованно управлять конфигурацией вашего
приложения, облегчая кастомизацию при развёртывании</li>
</ul></li>
</ul>
<pre><code>image:
 repository: quickdelivery/app
 tag: latest

service:
 type: ClusterIP
 port: 80</code></pre></li>
<li>Создание шаблонов
<ul>
<li>Задача: Создать шаблоны ресурсов Kubernetes, которые будут
использоваться для развёртывания вашего приложения</li>
<li>В директории templates создайте файлы шаблонов для ресурсов
Kubernetes — Deployment, Service, ConfigMap.</li>
<li>Используйте язык шаблонов Go для динамической подстановки значений
из values.yaml.</li>
</ul>
<pre><code>Пример шаблона Deployment:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-deployment
  labels:
    app: {{ .Chart.Name }}
spec:
  replicas: 2
  template:
    metadata:
     labels:
       app: {{ .Chart.Name }}
  spec:
    containers:
    - name: {{ .Chart.Name }}
      image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot;
      ports:
      - containerPort: {{ .Values.service.port }}</code></pre></li>
</ul>
<h4 id="развёртывание-helm-чарта-для-quickdelivery-1">Развёртывание
Helm-чарта для QuickDelivery</h4>
<ul>
<li>Инициализация Helm
<ul>
<li>Задача: Подготовить Helm для работы с кластером Kubernetes.
<ul>
<li>helm init
<ul>
<li>Эта команда инициализирует Helm в вашем кластере Kubernetes,
устанавливая необходимый для работы Helm сервер — Tiller (для Helm v2).
<ul>
<li>Это первый шаг для работы с чартами в вашем кластере.</li>
<li>Если вы используете Helm v3, данный шаг не применим.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>Установка чартов
<ul>
<li>Задача: Развернуть приложение QuickDelivery в кластере Kubernetes с
помощью Helm-чарта.
<ul>
<li>helm install quickdelivery –name quickdelivery
<ul>
<li>Эта команда установит чарт в кластере, создавая все необходимые
ресурсы Kubernetes, такие как Deployment, Service, ConfigMap и
другие.</li>
<li>Helm автоматически подставит значения из values.yaml и развернёт
приложение.</li>
<li>Это упрощает процесс развёртывания и обеспечивает
консистентность.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Проверка развёртывания
<ul>
<li>Задача: Убедиться, что приложение успешно развёрнуто и работает.
<ul>
<li>kubectl get all -l app=quickdelivery
<ul>
<li>Эта команда покажет все ресурсы Kubernetes, связанные с вашим
приложением, и их текущий статус.</li>
<li>Это важно для подтверждения успешного развёртывания и для отладки в
случае проблем</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h4 id="обновление-helm-чарта-1">Обновление Helm-чарта</h4>
<ul>
<li>Внесение изменений в чарт
<ul>
<li>Обновите файлы шаблонов или values.yaml в соответствии с новыми
требованиями</li>
</ul></li>
<li>Обновление развёрнутого приложения
<ul>
<li>Задача: Применить изменения в кластере без прерывания работы
приложения.
<ul>
<li>helm upgrade quickdelivery quickdelivery
<ul>
<li>Эта команда обновит развёрнутое приложение, применив новые
конфигурации и шаблоны.</li>
<li>Helm управляет процессом обновления, обеспечивая плавное и
безопасное развёртывание новых версий.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Проверка обновления
<ul>
<li>kubectl get all -l app=quickdelivery</li>
</ul></li>
</ul>
<h3 id="cloud-native-computing-foundation-cncf-1">Cloud Native Computing
Foundation (CNCF)</h3>
<ul>
<li>loud Native Computing Foundation (CNCF) — это организация, созданная
под эгидой Linux Foundation в 2015 году с целью продвижения и развития
технологий,
<ul>
<li>ориентированных на облачные и контейнеризированные приложения.</li>
</ul></li>
<li>Основная миссия CNCF заключается в обеспечении возможностей для
создания масштабируемых, управляемых и легко
<ul>
<li>разворачиваемых приложений в облачной среде</li>
</ul></li>
<li>Ключевые направления деятельности
<ul>
<li>Поддержка открытых стандартов</li>
<li>Развитие экосистемы</li>
<li>Образование и обучение</li>
</ul></li>
<li>Важнейшие проекты CNCF
<ul>
<li>Контейнеризация и оркестрация
<ul>
<li>Kubernetes: Система оркестрации контейнеров, которая автоматизирует
развёртывание, масштабирование и управление контейнеризированными
приложениями.</li>
<li>containerd: Высокопроизводительный runtime для управления жизненным
циклом контейнеров.</li>
<li>CRI-O: Лёгкий контейнерный runtime, специально разработанный для
Kubernetes.</li>
</ul></li>
<li>Сеть и прокси
<ul>
<li>Envoy: Прокси-сервер и service mesh для управления трафиком между
микросервисами.</li>
<li>Cilium: Программа для сетевой безопасности и подключения на основе
eBPF.</li>
<li>Flannel: Простая и быстрая overlay сеть для Kubernetes.</li>
</ul></li>
<li>Мониторинг и алертинг
<ul>
<li>Prometheus: Система мониторинга и алертинга, разработанная для сбора
и анализа метрик с различных систем и сервисов.</li>
<li>Thanos: Система для высокодоступного и масштабируемого мониторинга с
Prometheus.</li>
<li>Jaeger: Система для трассировки распределённых транзакций и анализа
производительности.</li>
</ul></li>
<li>Логирование и управление данными
<ul>
<li>Fluentd: Инструмент для сбора, обработки и передачи логов.</li>
<li>Elasticsearch: Система для полнотекстового поиска и анализа
данных.</li>
<li>Vitess: Масштабируемая система для управления базами данных
MySQL.</li>
</ul></li>
<li>Управление сервисами и обнаружение
<ul>
<li>etcd: Система распределённого ключа-значения для координации и
управления конфигурацией.</li>
<li>CoreDNS: Плагинная DNS-система, интегрированная с Kubernetes.</li>
<li>Linkerd: Легковесный service mesh для обеспечения безопасности,
наблюдаемости и управления трафиком.</li>
</ul></li>
<li>Безопасность
<ul>
<li>SPIFFE: Спецификация для предоставления криптографически проверяемых
удостоверений для узлов и сервисов в динамичной инфраструктуре.</li>
<li>SPIRE: Инструмент для реализации SPIFFE в различных средах и
платформах.</li>
<li>Notary: Система для подписания и проверки целостности контейнерных
образов.</li>
</ul></li>
<li>Сборка и CI/CD
<ul>
<li>Helm: Пакетный менеджер для Kubernetes, упрощающий развёртывание
приложений.</li>
<li>Argo: Инструмент для CI/CD и оркестрации рабочих процессов в
Kubernetes.</li>
<li>Tekton: Система для создания CI/CD конвейеров на основе
Kubernetes.</li>
</ul></li>
<li>Обеспечение надёжности и тестирование
<ul>
<li>Chaos Mesh: Платформа для тестирования устойчивости к отказам и
симуляции различных сбоев в Kubernetes.</li>
<li>LitmusChaos: Инструмент для тестирования надёжности и симуляции
различных сбоев в облачных системах.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="cncf-landscape-1">CNCF Landscape</h4>
<ul>
<li>интерактивный инструмент CNCF Landscape, чтобы пользователи могли
исследовать экосистему облачных технологий.
<ul>
<li>Он визуализирует различные проекты и инструменты, спонсируемые CNCF,
и помогает ориентироваться в сложной</li>
</ul></li>
<li>Основные функции CNCF Landscape
<ul>
<li>Обзор ландшафта <img src="images/img_65.png"
alt="img_65.png" /></li>
<li>Поиск и фильтрация <img src="images/img_66.png"
alt="img_66.png" /></li>
<li>Интерактивная карта <img src="images/img_67.png"
alt="img_67.png" /></li>
<li>Сравнение проектов</li>
<li>Образовательные ресурсы</li>
</ul></li>
</ul>
<h4 id="интеграция-cncf-инструментов-в-проекты-1">Интеграция
CNCF-инструментов в проекты</h4>
<ul>
<li>Поиск инструмента
<ul>
<li>Зайдите на landscape.cncf.io.</li>
<li>В строке поиска введите monitoring или Prometheus.</li>
<li>Найдите и выберите проект Prometheus в разделе Monitoring &amp;
Observability.</li>
</ul></li>
<li>Понимание назначения инструмента
<ul>
<li>Перейдите на официальную страницу Prometheus, кликнув на ссылку на
landscape.cncf.io.</li>
<li>Ознакомьтесь с документацией, особенно с разделами Overview и
Getting Started.</li>
<li>Посмотрите, какие задачи решает Prometheus, такие как сбор и анализ
метрик, алертинг и визуализация данных.</li>
</ul></li>
<li>Применение Prometheus в проекте
<ul>
<li>установка Prometheus:
<ul>
<li>Разверните Prometheus в вашем Kubernetes-кластере. Можно
использовать Helm-чарт для упрощения установки:</li>
</ul>
<pre><code>   helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
   helm repo update
   helm install prometheus prometheus-community/prometheus</code></pre></li>
<li>Конфигурация скрапинга метрик
<ul>
<li>Настройте Prometheus на сбор метрик с микросервисов WeatherNow.
Добавьте микросервисы в конфигурацию Prometheus:</li>
</ul>
<pre><code> scrape_configs:
   - job_name: &#39;weather-service&#39;
     static_configs:
       - targets: [&#39;weather-service:80&#39;]</code></pre></li>
<li>Интеграция с микросервисами:
<ul>
<li>-Включите экспортёры метрик в микросервисах. Например, для Python
используйте библиотеку prometheus_client:</li>
</ul>
<pre><code>from prometheus_client import start_http_server, Summary

 # Создание метрики
 REQUEST_TIME = Summary(&#39;request_processing_seconds&#39;, &#39;Time spent processing request&#39;)

 @REQUEST_TIME.time()
 def process_request(request):
     # Обработка запроса
     pass

 if __name__ == &#39;__main__&#39;:
     start_http_server(8000)
     # Симуляция обработки запроса
     while True:
         process_request(None)</code></pre></li>
<li>Визуализация данных:
<ul>
<li>Используйте Grafana для визуализации метрик, собранных Prometheus.
<ul>
<li>Установите Grafana и настройте его на использование Prometheus в
качестве источника данных.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Обновления</li>
</ul>
<pre><code>
 helm repo update
 helm upgrade prometheus prometheus-community/prometheus     

</code></pre>
<h2 id="service-mesh-1">Service Mesh</h2>
<ul>
<li>это выделенный слой инфраструктуры для управления сетевыми
взаимодействиями между микросервисами.
<ul>
<li>Он обеспечивает надёжное и безопасное общение между сервисами,
позволяя автоматизировать маршрутизацию запросов,
<ul>
<li>балансировку нагрузки, управление трафиком и мониторинг. <img
src="images/img_68.png" alt="img_68.png" /></li>
</ul></li>
</ul></li>
<li>Основные преимущества использования Service Mesh:
<ul>
<li>Управление трафиком: Service Mesh позволяет гибко управлять трафиком
между микросервисами, обеспечивая маршрутизацию и балансировку
нагрузки</li>
<li>Обеспечение безопасности: Service Mesh обеспечивает безопасность
взаимодействий между микросервисами, предоставляя возможность шифрования
трафика и аутентификации запросов</li>
<li>Мониторинг и трассировка: Service Mesh предоставляет инструменты для
мониторинга и трассировки запросов</li>
<li>Обеспечение надёжности: Service Mesh помогает повысить надёжность
системы, обеспечивая автоматическое переключение на резервные экземпляры
сервисов в случае сбоев</li>
</ul></li>
</ul>
<h3 id="основные-концепты-service-mesh-1">Основные концепты Service
Mesh</h3>
<figure>
<img src="images/img_69.png" alt="img_69.png" />
<figcaption aria-hidden="true">img_69.png</figcaption>
</figure>
<h3 id="основные-элементы-конфигурации-istio-1">Основные элементы
конфигурации Istio</h3>
<ul>
<li>Istio — это открытая платформа для подключения, управления и защиты
микросервисов.
<ul>
<li>Она обеспечивает многочисленные функции: маршрутизацию трафика,
балансировку нагрузки, аутентификацию и авторизацию, мониторинг и
трассировку запросов.</li>
</ul></li>
</ul>
<figure>
<img src="images/img_70.png" alt="img_70.png" />
<figcaption aria-hidden="true">img_70.png</figcaption>
</figure>
<ul>
<li>Istio два ключевых компонента:
<ul>
<li>Envoy Proxy — это прокси-сервер на основе паттерна Sidecar, который
размещается рядом с каждым микросервисом.</li>
<li>Он отвечает за маршрутизацию трафика, балансировку нагрузки,
мониторинг и безопасность. Среди его функций:
<ul>
<li>управление сетевым трафиком между сервисами,</li>
<li>отслеживание запросов и ответов,</li>
<li>установка политик безопасности и шифрование трафика.</li>
</ul></li>
</ul></li>
<li>Istiod — это основной сервис управления в архитектуре Istio.
<ul>
<li>Он объединяет функции нескольких ключевых компонентов системы в
единое целое.</li>
<li>Istiod появился в версии Istio 1.5 и заменил отдельные сервисы,
такие как Pilot, Citadel и Galley.</li>
<li>Он упрощает установку, управление и эксплуатацию Istio. Среди его
функций:
<ul>
<li>Управление трафиком.
<ul>
<li>Конфигурирует и управляет прокси-серверами Envoy, обеспечивая
маршрутизацию, балансировку нагрузки, и отказоустойчивость для сетевого
трафика между микросервисами.</li>
</ul></li>
<li>Безопасность.
<ul>
<li>Управляет безопасностью сетевого взаимодействия, включая выдачу и
ротацию сертификатов X.509, обеспечивая шифрование трафика с
использованием mTLS (mutual TLS).</li>
</ul></li>
<li>Валидация конфигураций.
<ul>
<li>Проверяет и валидирует конфигурации Istio, гарантируя их
корректность и соответствие политикам безопасности и маршрутизации.</li>
</ul></li>
<li>Мониторинг и телеметрия.
<ul>
<li>Обеспечивает сбор метрик и логов для мониторинга состояния системы и
диагностики проблем.</li>
</ul></li>
</ul></li>
</ul></li>
<li>ключевые элементы <img src="images/img_71.png"
alt="img_71.png" /></li>
</ul>
<h3 id="создание-и-настройка-service-mesh-с-istio-1">Создание и
настройка Service Mesh с Istio</h3>
<ul>
<li>Шаг 1: Установка Istio CLI
<ul>
<li>то установка командной строки Istio (Istio CLI), которая позволяет
взаимодействовать с Istio и управлять его настройками.</li>
<li>Скачайте и установите Istio CLI:</li>
</ul>
<pre><code> curl -L https://istio.io/downloadIstio | sh -
 cd istio-&lt;version&gt;
 export PATH=$PWD/bin:$PATH</code></pre>
<ul>
<li>Istio CLI (istioctl) предоставляет инструменты для установки и
управления Istio в вашем кластере Kubernetes.</li>
<li>Без него невозможно развернуть и настраивать Istio.</li>
</ul></li>
<li>Шаг 2: Развёртывание Istio в Kubernetes
<ul>
<li>Подготовка кластера Kubernetes:
<ul>
<li>Этот шаг подразумевает установку всех необходимых компонентов Istio
— контроля плоскости и плоскости данных.</li>
<li>Убедитесь, что у вас есть работающий кластер Kubernetes</li>
<li>использовать Minikube для локального тестирования или другой кластер
Kubernetes для более масштабных проектов.
<ul>
<li>minikube start</li>
</ul></li>
</ul></li>
<li>Установка Istio в кластер:
<ul>
<li>развёртывает Istio в вашем кластере Kubernetes с использованием
демопрофиля, который включает все основные компоненты Istio.</li>
<li>Это упрощённый способ начать работу с Istio и протестировать его
функциональность.
<ul>
<li>istioctl install –set profile=demo -y</li>
</ul></li>
</ul></li>
<li>Проверка установки:
<ul>
<li>kubectl get pods -n istio-system</li>
</ul></li>
</ul></li>
<li>Шаг 3: Включение автоматической вставки Sidecar
<ul>
<li>Sidecar-прокси
<ul>
<li>это компоненты, которые добавляются к каждому поду и обеспечивают
маршрутизацию и контроль трафика.
<ul>
<li>Включение автоматической вставки позволяет автоматически добавлять
Sidecar-прокси к новым подам в выбранном пространстве имён</li>
</ul></li>
</ul></li>
<li>Включение автоматической вставки sidecar-прокси для namespace, где
будут работать микросервисы
<ul>
<li>kubectl label namespace default istio-injection=enabled</li>
</ul></li>
</ul></li>
<li>Шаг 4: Деплой микросервисов с Istio
<ul>
<li>когда Istio установлено и настроено, можете развернуть свои
микросервисы.
<ul>
<li>При развёртывании микросервисов с включённой вставкой Sidecar, Istio
автоматически добавит прокси к каждому поду</li>
</ul></li>
<li>пример деплоя</li>
</ul>
<pre><code>Создайте файл quickdelivery-deployment.yaml с конфигурацией деплоя:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: quickdelivery-service
  labels:
    app: quickdelivery
spec:
  replicas: 3
  selector:
    matchLabels:
      app: quickdelivery
  template:
    metadata:
      labels:
        app: quickdelivery
    spec:
      containers:
      - name: quickdelivery
        image: quickdelivery:latest
        ports:
        - containerPort: 80

Этот файл описывает конфигурацию для развёртывания микросервиса QuickDelivery в Kubernetes. Он отображает информацию о количестве реплик, образе контейнера и портах.
Применение конфигурации:
Применение конфигурации развёртывает микросервис QuickDelivery в кластере Kubernetes с автоматической вставкой Sidecar-прокси для управления трафиком.

kubectl apply -f quickdelivery-deployment.yaml</code></pre></li>
<li>Шаг 5: Настройка маршрутизации и балансировки нагрузки
<ul>
<li><p>необходимо настроить маршрутизацию и балансировку нагрузки для
управления трафиком между микросервисами</p></li>
<li><p>VirtualService</p>
<ul>
<li>определяет правила маршрутизации для трафика, направляемого на
сервисы.
<ul>
<li>С его помощью можно настроить маршрутизацию на основе различных
параметров, таких как заголовки HTTP, веса запросов и других.</li>
</ul></li>
</ul></li>
<li><p>DestinationRule</p>
<ul>
<li>определяет политики для трафика, направляемого на определённые
версии или подгруппы сервисов.
<ul>
<li>Это может включать в себя балансировку нагрузки, выбор версий
сервисов и другие параметры.</li>
</ul></li>
</ul></li>
<li><p>Создание VirtualService и DestinationRule:</p>
<pre><code>Для управления трафиком создайте файл quickdelivery-traffic.yaml:

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
name: quickdelivery
spec:
hosts:
- quickdelivery
  http:
- route:
  - destination:
    host: quickdelivery
    subset: v1
 ---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
name: quickdelivery
spec:
host: quickdelivery
subsets:
- name: v1
  labels:
  version: v1</code></pre></li>
<li><p>Применение конфигурации:</p>
<ul>
<li>настраивает маршрутизацию и балансировку нагрузки для микросервисов
QuickDelivery, обеспечивая гибкость и контроль над трафиком.
<ul>
<li>kubectl apply -f quickdelivery-traffic.yaml</li>
</ul></li>
</ul></li>
</ul></li>
<li>Шаг 6: Настройка мониторинга
<ul>
<li>Установка Prometheus и Grafana:
<ul>
<li>Prometheus собирает метрики с микросервисов и компонентов Istio, а
Grafana предоставляет визуализацию этих метрик.</li>
<li>Убедитесь, что Prometheus и Grafana установлены вместе с Istio
<ul>
<li>kubectl get pods -n istio-system</li>
</ul></li>
</ul></li>
<li>Настройка метрик и дашбордов:
<ul>
<li>Откройте Grafana и добавьте дашборды для мониторинга Istio:
<ul>
<li>kubectl -n istio-system port-forward $(kubectl -n istio-system get
pod -l app=grafana -o jsonpath=‘{.items[0].metadata.name}’)
3000:3000</li>
</ul></li>
</ul></li>
<li>Мониторинг состояния микросервисов:
<ul>
<li>Используйте дашборды Grafana для мониторинга производительности и
состояния микросервисов</li>
</ul></li>
</ul></li>
<li>Шаг 7: Трассировка запросов
<ul>
<li>Jaeger — это система для распределённой трассировки с открытым
исходным кодом, разработанная для мониторинга и отладки транзакций в
распределённых системах.
<ul>
<li>Jaeger помогает отслеживать путь запросов через микросервисы и
анализировать проблемы производительности.</li>
<li>Интерфейс Jaeger предоставляет визуализацию трассировок, что
помогает анализировать и оптимизировать путь запросов.</li>
</ul></li>
<li>Установка Jaeger для трассировки:
<ul>
<li>Убедитесь, что Jaeger установлен вместе с Istio:
<ul>
<li>kubectl get pods -n istio-system</li>
</ul></li>
</ul></li>
<li>Настройка трассировки:
<ul>
<li>Откройте интерфейс Jaeger для просмотра трассировки запросов:
<ul>
<li>kubectl -n istio-system port-forward $(kubectl -n istio-system get
pod -l app=jaeger -o jsonpath=‘{.items[0].metadata.name}’)
16686:16686</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="service-discovery-1">Service Discovery</h2>
<ul>
<li><p>Service Discovery — это механизм, позволяющий микросервисам
автоматически находить друг друга в динамической среде</p></li>
<li><p>В контексте Kubernetes и Istio, Service Discovery решает
несколько задач:</p>
<ul>
<li>Автоматическое обнаружение сервисов
<ul>
<li>новые экземпляры микросервисов автоматически регистрируются в
системе и становятся доступными для других сервисов.</li>
</ul></li>
<li>Обновление информации о сервисах
<ul>
<li>при изменении состояния сервисов (например, масштабировании)
информация автоматически обновляется, обеспечивая актуальные данные о
доступных экземплярах.</li>
</ul></li>
<li>Упрощение конфигурации
<ul>
<li>разработчикам и операторам не нужно вручную управлять конфигурациями
для каждого изменения в инфраструктуре.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="настройка-service-discovery-с-istio-1">Настройка Service
Discovery с Istio</h3>
<ul>
<li>Шаг 1: Настройка Kubernetes DNS
<ul>
<li>Kubernetes использует встроенный механизм DNS для Service
Discovery</li>
<li>Каждый сервис в кластере получает DNS-имя, которое можно
использовать для его обнаружения и взаимодействия.
<ul>
<li>kubectl get svc -n kube-system
<ul>
<li>Вы должны увидеть сервис kube-dns или coredns.</li>
</ul></li>
</ul></li>
<li>DNS-сервис отвечает за разрешение DNS-имён сервисов в кластере.
<ul>
<li>Без работающего DNS-сервиса микросервисы не смогут находить друг
друга по именам.</li>
</ul></li>
</ul></li>
<li>Шаг 2: Деплой микросервисов
<ul>
<li><p>разворачивание микросервисов OrderService и DeliveryService в
кластере Kubernetes.</p></li>
<li><p>Создание файлов конфигурации для микросервисов</p>
<pre><code>Создание файлов конфигурации для микросервисов:

  # orderservice-deployment.yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
   name: orderservice
   labels:
     app: orderservice
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: orderservice
    template:
      metadata:
        labels:
          app: orderservice
      spec:
        containers:
        - name: orderservice
          image: quickdelivery/orderservice:latest
          ports:
          - containerPort: 8080
     ---
  # deliveryservice-deployment.yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: deliveryservice
    labels:
      app: deliveryservice
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: deliveryservice
    template:
      metadata:
        labels:
          app: deliveryservice
      spec:
        containers:
        - name: deliveryservice
          image: quickdelivery/deliveryservice:latest
          ports:
          - containerPort: 8080</code></pre></li>
<li><p>Применение конфигурации для развёртывания:</p>
<ul>
<li>kubectl apply -f orderservice-deployment.yaml</li>
<li>kubectl apply -f deliveryservice-deployment.yaml</li>
</ul></li>
</ul></li>
<li>Шаг 3: Создание сервисов для микросервисов
<ul>
<li>Чтобы микросервисы могли находить друг друга, необходимо создать
Kubernetes-сервисы.</li>
<li>Создание файлов конфигурации для сервисов:</li>
</ul>
<pre><code># orderservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: orderservice
spec:
  selector:
    app: orderservice
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
 ---
# deliveryservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: deliveryservice
spec:
  selector:
    app: deliveryservice
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080</code></pre>
<ul>
<li>Применение конфигурации для создания сервисов:
<ul>
<li>kubectl apply -f orderservice-service.yaml</li>
<li>kubectl apply -f deliveryservice-service.yaml</li>
</ul></li>
</ul></li>
<li>Шаг 4: Взаимодействие микросервисов через Service Discovery
<ul>
<li>Микросервисы могут использовать DNS-имена для взаимодействия после
настройки деплоя и сервисов.</li>
<li>Пример кода для взаимодействия:</li>
</ul></li>
</ul>
<pre><code>
import requests

delivery_service_url = &quot;http://deliveryservice.default.svc.cluster.local&quot;
response = requests.get(f&quot;{delivery_service_url}/deliver&quot;, params={&quot;order_id&quot;: 123})

if response.status_code == 200:
    print(&quot;Delivery scheduled successfully&quot;)
else:
    print(&quot;Failed to schedule delivery&quot;)

</code></pre>
<ul>
<li>Шаг 5: Интеграция Istio с Service Discovery
<ul>
<li><p>Istio автоматически обнаруживает все сервисы в кластере и может
использовать эту информацию для управления трафиком и
маршрутизацией.</p></li>
<li><p>Создание VirtualService для маршрутизации трафика между
сервисами:</p>
<pre><code>apiVersion: networking.istio.io/v1alpha3
 kind: VirtualService
 metadata:
   name: order-to-delivery
 spec:
   hosts:
   - deliveryservice
   http:
   - route:
     - destination:
         host: deliveryservice
         subset: v1</code></pre></li>
<li><p>Применение конфигурации для настройки маршрутизации:</p>
<ul>
<li>kubectl apply -f order-to-delivery-virtualservice.yaml
<ul>
<li>Команда создаёт правила маршрутизации для трафика, направляемого к
DeliveryService.</li>
<li>Это позволяет контролировать, как трафик направляется между
микросервисами.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="feature-toggling-1">Feature Toggling</h2>
<ul>
<li><p>Feature Toggling (или Feature Flags) — это подход, который
позволяет включать и отключать функциональные возможности</p>
<ul>
<li>приложения без необходимости развёртывания нового кода.</li>
<li>Это особенно полезно для управления рисками при выпуске новых
функций и проведения экспериментов.</li>
</ul></li>
<li><p>возникает необходимость тестирования новых версий микросервисов в
производственной среде без влияния на всех пользователей.</p></li>
<li><p>Feature Toggling — это практика, при которой функциональные
возможности приложения могут быть включены или выключены</p>
<ul>
<li>во время выполнения без изменения исходного кода.</li>
</ul></li>
<li><p>Feature Toggling позволяет:</p>
<ul>
<li>Выпускать новые функции постепенно
<ul>
<li>новые функции можно включать только для части пользователей, чтобы
оценить их работу и устранить возможные проблемы.</li>
</ul></li>
<li>Проводить A/B-тестирование
<ul>
<li>версии функции могут быть протестированы на разных группах
пользователей для оценки их эффективности.</li>
</ul></li>
<li>Управлять рисками
<ul>
<li>возможность быстро отключить проблемную функцию, если она вызывает
ошибки или негативные последствия для пользователей.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="настройка-feature-toggling-с-istio-1">Настройка Feature Toggling
с Istio</h3>
<ul>
<li>Шаг 1: Установка Istio Убедитесь, что Istio установлен и настроен в
вашем кластере Kubernetes.
<ul>
<li>Если Istio ещё не установлен, следуйте инструкциям по установке
Istio из предыдущего раздела.</li>
</ul></li>
<li>Шаг 2: Настройка новых версий микросервисов
<ul>
<li>Создайте и примените конфигурации деплоя для новых версий
микросервисов.</li>
<li>Пример для новой версии сервиса доставки:</li>
</ul></li>
</ul>
<pre><code>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: delivery-service-v2
  labels:
    app: delivery
    version: v2
spec:
  replicas: 3
  selector:
    matchLabels:
      app: delivery
      version: v2
  template:
    metadata:
      labels:
        app: delivery
        version: v2
    spec:
      containers:
      - name: delivery
        image: quickdelivery/delivery-service:v2
        ports:
        - containerPort: 80

</code></pre>
<ul>
<li><p>kubectl apply -f delivery-service-v2-deployment.yaml</p></li>
<li><p>Шаг 3: Настройка маршрутизации трафика с Istio</p>
<ul>
<li>Используйте Istio VirtualService для управления маршрутизацией
трафика между различными версиями сервиса доставки.</li>
<li>Например, можно настроить маршрутизацию 10% трафика на новую версию
v2.</li>
</ul></li>
</ul>
<pre><code>
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: delivery-service
spec:
  hosts:
  - delivery-service
  http:
  - route:
    - destination:
        host: delivery-service
        subset: v1
      weight: 90
    - destination:
        host: delivery-service
        subset: v2
      weight: 10

</code></pre>
<ul>
<li><p>kubectl apply -f delivery-service-virtualservice.yaml</p></li>
<li><p>Шаг 4: Мониторинг и управление Feature Toggling</p>
<ul>
<li>Используйте мониторинг и логи Istio для отслеживания поведения новых
версий микросервисов.</li>
<li>В случае выявления проблем можно быстро изменить конфигурацию и
перенаправить трафик обратно на стабильную версию.</li>
</ul></li>
<li><p>Шаг 5: Полное переключение на новую версию</p>
<ul>
<li>После успешного тестирования новой версии можно плавно переключить
весь трафик на неё, обновив конфигурацию VirtualService:</li>
</ul></li>
</ul>
<pre><code>
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: delivery-service
spec:
  hosts:
  - delivery-service
  http:
  - route:
    - destination:
        host: delivery-service
        subset: v2
      weight: 100

</code></pre>
<ul>
<li><p>kubectl apply -f delivery-service-virtualservice.yaml</p></li>
<li><p>Итоги</p>
<ul>
<li>Service Mesh — это выделенный слой инфраструктуры для управления
сетевыми взаимодействиями между микросервисами.
<ul>
<li>Он обеспечивает надёжное и безопасное общение между сервисами,
позволяя автоматизировать маршрутизацию запросов, балансировку нагрузки,
управление трафиком и мониторинг.</li>
</ul></li>
<li>Istio — это открытая платформа для подключения, управления и защиты
микросервисов.
<ul>
<li>Она обеспечивает многочисленные функции: маршрутизацию трафика,
балансировку нагрузки, аутентификацию и авторизацию, мониторинг и
трассировку запросов.</li>
</ul></li>
<li>Service Discovery — это механизм, позволяющий микросервисам
автоматически находить друг друга в динамической среде.</li>
<li>Feature Toggling (или Feature Flags) — это подход, который позволяет
включать и отключать функциональные возможности приложения без
необходимости развёртывания нового кода.
<ul>
<li>Это особенно полезно для управления рисками при выпуске новых
функций и проведении экспериментов.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="сicd-процессы-1">СI/CD-процессы</h2>
<ul>
<li>CI/CD — это набор практик и методологий, который направлен на
автоматизацию процессов разработки,
<ul>
<li>тестирования и развёртывания программного обеспечения.</li>
<li>CI/CD рассматривают как единый подход. На практике он состоит из
трёх этапов, которые в свою очередь, состоят из шагов</li>
</ul></li>
<li>CI/CD предшествует два шага:
<ul>
<li>Планирование (Plan)
<ul>
<li>На этом этапе команды разработки определяют, какие изменения или
новые функции необходимо реализовать.</li>
<li>Планирование включает обсуждение требований, создание задач и
распределение работы между разработчиками.</li>
</ul></li>
<li>Написание кода (Code)</li>
</ul></li>
</ul>
<h3 id="continuous-integration-ci-1">Continuous Integration (CI)</h3>
<ul>
<li>процесс непрерывной интеграции предполагает регулярное
интегрирование изменений в общую кодовую базу
<ul>
<li>и автоматические проверки нового кода на наличие ошибок и
конфликтов.</li>
</ul></li>
<li>Шаг 1. Работа с системой контроля версий (Code)
<ul>
<li>разработчики фиксируют изменения кода в системе контроля версий</li>
</ul></li>
<li>Шаг 2. Сборка (Build)
<ul>
<li>когда разработчик вносит изменения в код, эти изменения
автоматически интегрируются в центральный репозиторий</li>
</ul></li>
<li>Шаг 3. Автоматическое тестирование (Automated Testing)
<ul>
<li>После сборки система CI запускает автоматические тесты, чтобы
проверить корректность новых изменений</li>
</ul></li>
</ul>
<h3 id="continuous-delivery-cd-1">Continuous Delivery (CD)</h3>
<ul>
<li>Непрерывная доставка предполагает автоматизацию развёртывания и
тестирования.
<ul>
<li>Она помогает добиться того, чтобы каждая версия программного
обеспечения была готова к выпуску в любое время.</li>
</ul></li>
<li>Шаг 4. Подготовка к развёртыванию (Release) (продолжение предыдущих
шагов)
<ul>
<li>все тесты прошли успешно, приложение нужно подготовить к
развёртыванию.</li>
<li>система создаст сборки и пакеты, которые нужны для
развёртывания.</li>
</ul></li>
<li>Шаг 5. Развёртывание в тестовые среды (Staging/Pre-production
Deployment).
<ul>
<li>Готовое приложение развёртывается в тестовых средах, где выполняются
дополнительные проверки и тесты</li>
</ul></li>
</ul>
<h3 id="continuous-deployment-1">Continuous Deployment</h3>
<ul>
<li><p>Постоянное развёртывание предполагает, что каждое успешное
изменение автоматически развёртывается в рабочую среду.</p></li>
<li><p>Шаг 6. Автоматическое развёртывание (Production Deployment)</p>
<ul>
<li>Как только изменение прошло процессы CI и CD, система автоматически
доставляет его конечным пользователям.</li>
</ul></li>
</ul>
<figure>
<img src="images/img_72.png" alt="img_72.png" />
<figcaption aria-hidden="true">img_72.png</figcaption>
</figure>
<h3 id="pipeline-as-code-1">Pipeline as Code</h3>
<ul>
<li><blockquote>
<p>конвейер CI/CD — это набор этапов (build, test, deploy), которые
автоматически выполняются для доставки изменений кода.</p>
</blockquote></li>
<li><blockquote>
<p>Pipeline as Code (PaC) — это подход, при котором конвейеры CI/CD
описывают с помощью кода. Управляют ими тоже через код.</p>
</blockquote></li>
<li>Когда команда использует PaC, конвейеры CI/CD описывают в текстовых
файлах
<ul>
<li>например, YAML или JSON. Файлы хранят в системах контроля версий
вместе с исходным кодом приложения.</li>
</ul></li>
<li>Преимущества Pipeline as Code
<ul>
<li>Повторяемость: Автоматизированные конвейер</li>
<li>Гибкость</li>
<li>Версионирование</li>
<li>Прозрачность: Кодовые конвейеры предоставляют чёткую документацию
процессов CI/CD</li>
<li>Масштабируемость</li>
<li>Подверженность ошибкам</li>
</ul></li>
<li>Когда стоит применять PaC
<ul>
<li>Большие и сложные проекты</li>
<li>Частые изменения и развёртывания</li>
<li>Команды с высокой ротацией</li>
<li>Высокие требования к качеству и безопасности.</li>
<li>Наличие инфраструктуры как кода (IaC)</li>
</ul></li>
<li>Когда PaC себя не оправдает
<ul>
<li>Маленькие проекты</li>
<li>Редкие изменения и развёртывания</li>
<li>Нет опыта и ресурсов
<ul>
<li>нет специалистов по DevOps или CI/CD,</li>
</ul></li>
<li>Сложные интеграции
<ul>
<li>проект зависит от множества внешних систем и инструментов</li>
</ul></li>
</ul></li>
</ul>
<h3 id="cicd-pac-и-devops-1">CI/CD, PaC и DevOps</h3>
<ul>
<li><p>DevOps — это культурная и профессиональная методология, которая
направлена на интеграцию</p></li>
<li><p>и взаимодействие разработчиков программного обеспечения (Dev) и
специалистов по эксплуатации и обслуживанию (Ops). <img
src="images/img_73.png" alt="img_73.png" /></p></li>
<li><p>CI/CD</p>
<ul>
<li>Это практика, которая направлена на автоматизацию сборки,
тестирования и развёртывания программного обеспечения.</li>
<li>CI/CD-пайплайны гарантируют, что каждое изменение, внесённое в код,
автоматически тестируется и готовится к развёртыванию.</li>
</ul></li>
<li><p>Pipeline as Code</p>
<ul>
<li>PaC представляет собой практику, при которой все шаги CI/CD
описывают в виде кода.</li>
<li>Это обеспечивает повторяемость и автоматизацию процессов сборки,
тестирования и развёртывания.</li>
<li>Pipeline as Code позволяет командам разрабатывать, тестировать и
поддерживать CI/CD-пайплайны точно так же, как основной код
приложения.</li>
</ul></li>
<li><p>DevOps</p>
<ul>
<li>DevOps объединяет культурные изменения, практики и инструменты,
которые помогают повысить способность
<ul>
<li>организации быстро доставлять приложения и услуги.</li>
</ul></li>
<li>DevOps-практики включают в себя автоматизацию процессов,
междисциплинарное сотрудничество и постоянное улучшение.
<ul>
<li>Они делают разработку и эксплуатацию ПО более эффективными и
надёжными.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="как-настроить-базовый-cicd-конвейер-1">Как настроить базовый
CI/CD-конвейер</h3>
<ul>
<li><p>Jenkins - инструмент для автоматизации сборки и
развёртывания.</p></li>
<li><p>альтернативы Jenkins</p>
<ul>
<li>GitLab CI/CD</li>
<li>Travis CI — облачный сервис для CI/CD,</li>
<li>Azure DevOps — инструмент от Microsoft</li>
<li>GitHub Actions — инструмент для автоматизации рабочих процессов
непосредственно в GitHub</li>
</ul></li>
<li><p>Почему Jenkins</p>
<ul>
<li>Широкая популярность и активное сообщество</li>
<li>Гибкость и расширяемость</li>
<li>Надёжность</li>
</ul></li>
</ul>
<h4 id="как-создать-простой-и-эффективный-конвейер-jenkins">Как создать
простой и эффективный конвейер Jenkins</h4>
<ul>
<li>Шаг 1. Установите и настройте Jenkins
<ul>
<li>Загрузите Jenkins и установите его на ваш сервер или локальную
машину.</li>
<li>Инструкции по установке можно найти на официальном сайте
https://www.jenkins.io/doc/book/installing/.</li>
<li>Запустите Jenkins и выполните начальную настройку, следуя
инструкциям на экране.</li>
<li>Как установить плагины
<ul>
<li>Git Plugin — это плагин для интеграции Jenkins с системой контроля
версий Git.
<ul>
<li>Он позволяет Jenkins взаимодействовать с репозиториями Git для
клонирования, извлечения и отслеживания изменений кода.</li>
</ul></li>
<li>Pipeline Plugin — это плагин для создания и управления Jenkins
Pipeline.
<ul>
<li>Он позволяет описывать конвейеры сборки, тестирования и
развёртывания в виде кода. Использует язык скриптов Groovy.</li>
</ul></li>
<li>Docker Pipeline Plugin — это плагин для интеграции Docker с Jenkins
Pipeline.
<ul>
<li>Он позволяет запускать Docker-контейнеры и выполнять команды внутри
этих контейнеров как часть конвейера.</li>
</ul></li>
<li>Перейдите в «Управление Jenkins» —&gt; «Управление плагинами».</li>
<li>В разделе «Доступные» найдите «Git Plugin» и установите его.</li>
</ul></li>
</ul></li>
<li>Шаг 2. Создайте Pipeline as Code в Jenkins
<ul>
<li>В разделе «Pipeline» выберите «Pipeline script» и добавьте следующий
скрипт:
<ul>
<li>Checkout — этот этап клонирует репозиторий с исходным кодом.</li>
<li>Build — использует Docker-образ с Maven для сборки проекта.</li>
<li>Test — запускает тесты, используя тот же Docker-образ.</li>
<li>Deploy — использует Docker Compose, чтобы развернуть
приложение.</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
pipeline {
    agent any

    stages {
        stage(&#39;Checkout&#39;) {
            steps {
                git &#39;https://github.com/username/QuickDelivery.git&#39;
            }
        }
        stage(&#39;Build&#39;) {
            steps {
                script {
                    docker.image(&#39;maven:3.6.3&#39;).inside {
                        sh &#39;mvn clean install&#39;
                    }
                }
            }
        }
        stage(&#39;Test&#39;) {
            steps {
                script {
                    docker.image(&#39;maven:3.6.3&#39;).inside {
                        sh &#39;mvn test&#39;
                    }
                }
            }
        }
        stage(&#39;Deploy&#39;) {
            steps {
                script {
                    docker.image(&#39;docker:latest&#39;).inside {
                        sh &#39;docker-compose up -d&#39;
                    }
                }
            }
        }
    }

    post {
        always {
            junit &#39;target/surefire-reports/*.xml&#39;
            archiveArtifacts artifacts: &#39;target/*.jar&#39;, fingerprint: true
        }
    }
}

</code></pre>
<h4 id="что-ещё-можно-автоматизировать-1">Что ещё можно
автоматизировать?</h4>
<ul>
<li><p>Сборка (Build):</p>
<ul>
<li>Компиляция исходного кода.</li>
<li>Сборка артефактов — например, JAR-файлов для Java, бинарных файлов
для C++.</li>
<li>Выполнение статического анализа кода — например, линтинг.</li>
<li>Создание Docker-образов.</li>
</ul></li>
<li><p>Тестирование (Testing)</p></li>
<li><p>Развёртывание (Deployment):</p>
<ul>
<li>Развёртывание приложения в разных средах — development, staging,
production.</li>
<li>Обновление существующих развёртываний.</li>
<li>Выполнение миграций баз данных.</li>
<li>Настройка инфраструктуры — например, развёртывание виртуальных машин
или контейнеров.</li>
</ul></li>
<li><p>Мониторинг и уведомления (Monitoring and Notifications):</p>
<ul>
<li>Настройка мониторинга состояния приложений и инфраструктуры.</li>
<li>Уведомление команды о статусе выполнения задач — успех или
сбой.</li>
<li>Отправка уведомлений на почту, в корпоративный мессенджер или в
другие каналы связи.</li>
</ul></li>
<li><p>Управление зависимостями (Dependency Management):</p>
<ul>
<li>Установка и обновление зависимостей.</li>
<li>Проверка, насколько совместимы версии зависимостей.</li>
</ul></li>
<li><p>Проверка кода (Code Review and Quality Assurance):</p>
<ul>
<li>Автоматический код-ревью.</li>
<li>Запуск статического анализа кода.</li>
<li>Проверка соблюдения стандартов кодирования.</li>
</ul></li>
<li><p>Безопасность (Security):</p>
<ul>
<li>Выполнение сканирования на уязвимости.</li>
<li>Проверка безопасности зависимостей.</li>
<li>Управление секретами и ключами доступа.</li>
</ul></li>
<li><p>Доставка (Delivery):</p>
<ul>
<li>Публикация артефактов в репозитории — например, публикация библиотек
в Maven Central или PyPI.</li>
</ul></li>
</ul>
<h4 id="как-автоматизировать-cicd-конвейеры-с-помощью-скриптов-1">Как
автоматизировать CI/CD-конвейеры с помощью скриптов</h4>
<ul>
<li>Скрипты для управления зависимостями
<ul>
<li>Создайте скрипт install_dependencies.sh:</li>
</ul></li>
</ul>
<pre><code>
#!/bin/bash
apt-get update
apt-get install -y docker docker-compose

</code></pre>
<ul>
<li>скрипты для сборки и тестирования
<ul>
<li>Создайте скрипт build_and_test.sh:</li>
</ul></li>
</ul>
<pre><code>
#!/bin/bash
mvn clean install
mvn test

</code></pre>
<ul>
<li>Скрипты для развёртывания
<ul>
<li>Создайте скрипт deploy.sh:</li>
</ul></li>
</ul>
<pre><code>
#!/bin/bash
docker-compose up -d

</code></pre>
<ul>
<li>Интеграция скриптов в Jenkins Pipeline
<ul>
<li>Обновите «Pipeline script», чтобы использовать созданные
скрипты:</li>
</ul></li>
</ul>
<pre><code>
pipeline {
    agent any

    stages {
        stage(&#39;Install Dependencies&#39;) {
            steps {
                sh &#39;sh scripts/install_dependencies.sh&#39;
            }
        }
        stage(&#39;Checkout&#39;) {
            steps {
                git &#39;https://github.com/username/QuickDelivery.git&#39;
            }
        }
        stage(&#39;Build and Test&#39;) {
            steps {
                sh &#39;sh scripts/build_and_test.sh&#39;
            }
        }
        stage(&#39;Deploy&#39;) {
            steps {
                sh &#39;sh scripts/deploy.sh&#39;
            }
        }
    }

    post {
        always {
            junit &#39;target/surefire-reports/*.xml&#39;
            archiveArtifacts artifacts: &#39;target/*.jar&#39;, fingerprint: true
        }
    }
}

</code></pre>
<h4 id="как-настроить-мониторинг-cicd-конвейера-1">Как настроить
мониторинг CI/CD-конвейера</h4>
<ul>
<li>Мониторинг позволит:
<ul>
<li>Отслеживать статус выполнения сборок и развёртываний.</li>
<li>Вовремя выявлять и устранять проблемы.</li>
<li>Анализировать производительность и эффективность процессов.</li>
<li>Получать уведомления о сбоях и проблемах.</li>
</ul></li>
<li>Инструменты для мониторинга Jenkins
<ul>
<li>Built-in Jenkins Monitoring.
<ul>
<li>Jenkins предоставляет базовые возможности мониторинга через
веб-интерфейс</li>
</ul></li>
<li>Prometheus и Grafana</li>
<li>Jenkins Monitoring Plugins:
<ul>
<li>Monitoring Plugin — это плагин для мониторинга метрик Jenkins.
Например, он позволит отслеживать использование CPU, памяти и
диска.</li>
<li>Prometheus Plugin — это плагин для экспорта метрик Jenkins в
Prometheus.</li>
</ul></li>
</ul></li>
<li>Как настроить мониторинг с помощью с Prometheus и Grafana
<ul>
<li>Установите Prometheus и Grafana. Можете установить Prometheus и
Grafana на сервере или использовать Docker-контейнеры для их
развёртывания.
<ul>
<li>docker run -d –name prometheus -p 9090:9090 prom/prometheus</li>
<li>docker run -d –name grafana -p 3000:3000 grafana/grafana</li>
</ul></li>
<li>Установите Prometheus Plugin в Jenkins.
<ul>
<li>Для этого перейдите в «Управление Jenkins» —&gt; «Управление
плагинами».</li>
<li>В разделе «Доступные» найдите и установите «Prometheus Plugin».</li>
</ul></li>
<li>Настройте Prometheus для сбора метрик Jenkins. Добавьте конфигурацию
для сбора метрик Jenkins в Prometheus:</li>
</ul>
<pre><code>scrape_configs:
  - job_name: &#39;jenkins&#39;
    static_configs:
      - targets: [&#39;&lt;jenkins_server_ip&gt;:&lt;jenkins_server_port&gt;/prometheus&#39;]</code></pre>
<ul>
<li>Настройте Grafana для визуализации метрик Jenkins. Перейдите в
интерфейс Grafana и добавьте Prometheus в качестве источника данных.
<ul>
<li>Затем создайте новый дашборд и добавьте панели для визуализации
метрик Jenkins
<ul>
<li>например, для статуса сборок, времени выполнения сборок,
использования ресурсов и так далее.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Примеры метрик для мониторинга
<ul>
<li>Статус сборок:
<ul>
<li>Количество успешных, неудачных и пропущенных сборок.</li>
<li>Время выполнения сборок.</li>
<li>Длительность отдельных этапов конвейера.</li>
</ul></li>
<li>Использование ресурсов:
<ul>
<li>Загрузка CPU.</li>
<li>Использование памяти.</li>
<li>Использование дискового пространства.</li>
</ul></li>
<li>Другие метрики:
<ul>
<li>Количество запущенных задач.</li>
<li>Время ожидания задач в очереди.</li>
<li>Ошибки и предупреждения в логах сборок.</li>
</ul></li>
</ul></li>
<li>Как настроить уведомления
<ul>
<li>Jenkins Email Notifications. В разделе конфигурации Jenkins добавьте
«Email Extension Plugin»
<ul>
<li>Затем настройте параметры SMTP-сервера и добавьте email-адреса для
уведомлений.</li>
</ul></li>
<li>Grafana Alerts. 2. В интерфейсе Grafana настройте правила алертинга
для критических метрик.
<ul>
<li>Затем добавьте каналы уведомлений — например, почту или
корпоративный мессенджер.</li>
</ul></li>
</ul></li>
<li>Пример настройки уведомлений в Jenkins</li>
</ul>
<pre><code>
pipeline {
    agent any

    tools {
        jdk &#39;JDK11&#39;
    }

    environment {
        DOCKER_IMAGE = &#39;quickdelivery/app&#39;
    }

    stages {
        stage(&#39;Checkout&#39;) {
            steps {
                git &#39;https://github.com/your-repo/quickdelivery.git&#39;
            }
        }
        stage(&#39;Build&#39;) {
            steps {
                script {
                    docker.image(&#39;maven:3.6.3-jdk-11&#39;).inside {
                        sh &#39;mvn clean package&#39;
                    }
                }
            }
        }
        stage(&#39;Test&#39;) {
            steps {
                script {
                    docker.image(&#39;maven:3.6.3-jdk-11&#39;).inside {
                        sh &#39;mvn test&#39;
                    }
                }
            }
        }
        stage(&#39;Build Docker Image&#39;) {
            steps {
                script {
                    sh &#39;docker build -t ${DOCKER_IMAGE} .&#39;
                }
            }
        }
        stage(&#39;Push Docker Image&#39;) {
            steps {
                script {
                    withCredentials([string(credentialsId: &#39;dockerhub-password&#39;, variable: &#39;DOCKERHUB_PASSWORD&#39;)]) {
                        sh &#39;echo $DOCKERHUB_PASSWORD | docker login -u your-dockerhub-username --password-stdin&#39;
                        sh &#39;docker push ${DOCKER_IMAGE}&#39;
                    }
                }
            }
        }
        stage(&#39;Deploy&#39;) {
            steps {
                script {
                    sh &#39;docker run -d -p 8080:8080 ${DOCKER_IMAGE}&#39;
                }
            }
        }
    }

    post {
        always {
            emailext (
                subject: &quot;Build ${currentBuild.fullDisplayName}&quot;,
                body: &quot;Check console output at ${env.BUILD_URL} to view the results.&quot;,
                recipientProviders: [[$class: &#39;DevelopersRecipientProvider&#39;]]
            )
        }
        failure {
            emailext (
                subject: &quot;Build ${currentBuild.fullDisplayName} FAILED&quot;,
                body: &quot;Build failed. Check console output at ${env.BUILD_URL} to view the results.&quot;,
                recipientProviders: [[$class: &#39;DevelopersRecipientProvider&#39;]]
            )
        }
    }
}


</code></pre>
<h2 id="микросервисы-и-процесс-взаимодействия-1">Микросервисы и процесс
взаимодействия</h2>
<ul>
<li>gRPC фреймворки
<ul>
<li>gRPC, Apache Thrift, JSON-RPC</li>
</ul></li>
<li>сервисы обмена сообщениями
<ul>
<li>RabbitMQ, Apache Kafka, Amazon SQS (Simple Queue Service)</li>
</ul></li>
<li>Инструменты обеспечения согласованности и целостности данных
<ul>
<li>Согласованность в конечном итоге (Eventual Consistency)
<ul>
<li>гарантирует, что при необходимом времени все реплики данных придут к
одному и тому же значению</li>
</ul></li>
<li>Строгая согласованность (Strong Consistency)
<ul>
<li>гарантирует, что все операции чтения возвращают последнюю
запись</li>
</ul></li>
<li>Партицирование данных
<ul>
<li>разделение большого набора данных на более мелкие и управляемые
части (партиции), распределённые между несколькими узлами.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="распределённые-транзакции-1">Распределённые транзакции</h3>
<ul>
<li><p>когда операции охватывают несколько сервисов, обеспечение
согласованности и целостности данных требует управления распределёнными
транзакциями</p></li>
<li><p>Распределённые транзакции сложны из-за необходимости поддерживать
свойства ACID (Atomicity, Consistency, Isolation, Durability) в
различных сервисах</p></li>
<li><p>Распределённые транзакции координируют выполнение операций в
нескольких сервисах</p></li>
<li><p>Протокол двухфазной фиксации (2 Phase Commit, 2PC)</p>
<ul>
<li>Фаза подготовки
<ul>
<li>отправляет сообщение prepare всем участвующим сервисам с просьбой
подготовиться к фиксации транзакции</li>
<li>каждый сервис отвечает голосованием (зафиксировать или прервать) в
зависимости от того, сможет ли он успешно зафиксировать транзакцию.</li>
</ul></li>
<li>Фаза фиксации
<ul>
<li>если все сервисы голосуют за фиксацию, координатор отправляет
сообщение о фиксации всем сервисам, указывая им на фиксацию
транзакции</li>
<li>если кто-то проголосовал за отказ, рассылка всем сообщение об отказе
(откатить транзакцию)</li>
</ul></li>
<li>Проблемы 2PC
<ul>
<li>блокировка - перегруз координатора</li>
<li>производительность - задержки из-за необходимости многократных
обходов между координатором и участниками.</li>
</ul></li>
</ul></li>
<li><p>Паттерн Saga</p>
<ul>
<li>управление распределёнными транзакциями, разбивая их на серию более
мелких, компенсируемые транзакции</li>
<li>преимущества
<ul>
<li>Неблокируемость</li>
<li>масштабируемость</li>
</ul></li>
</ul></li>
</ul>
<h3 id="стратегии-развёртывания-1">Стратегии развёртывания</h3>
<ul>
<li>Стратегии развёртывания определяют, как новые версии микросервисов
будут вводиться в эксплуатацию, минимизируя риски и обеспечивая
непрерывность работы системы.
<ul>
<li>Docker, Kubernetes</li>
</ul></li>
<li>Традиционные
<ul>
<li>простой процесс обновления приложения на месте
<ul>
<li>делается путём остановки службы, развёртывания нового кода и
перезапуска службы.</li>
<li>характерен для монолитных систем</li>
</ul></li>
</ul></li>
</ul>
<h4 id="cовременные-стратегии-развёртывания-1">Cовременные стратегии
развёртывания</h4>
<ul>
<li><p>«сине-зелёные», «канареечные» и скользящие релизы
(deployments).</p></li>
<li><p>Основой всех современных методов развёртывания приложений
является контейнеризация.</p></li>
<li><p>Сине-зелёные релизы (Blue-Green)</p>
<ul>
<li>поддерживаются два идентичных окружения (синее и зелёное)</li>
<li>синее работает и обслуживает продакшн,</li>
<li>зелёное используется для развёртывания и тестирования новой
версии.</li>
<li>когда новая версия прошла тестирование в зелёном окружении, трафик
переключается на него.</li>
<li>Синяя среда теперь простаивает и может быть использована для
следующего обновления.</li>
<li>преимуществами являются отсутствие простоев и простой откат</li>
<li>Однако для реализации такого метода нужно поддерживать две
идентичные среды</li>
</ul></li>
<li><p>Канареечные релизы (Canary)</p>
<ul>
<li>новая версия разворачивается на каком-то количестве серверов
(канареечные серверы)
<ul>
<li>Туда направляют небольшой процент трафика</li>
</ul></li>
<li>Развёртывание отслеживают на предмет ошибок и, если проблем не
обнаружено, туда направляют всё больше трафика</li>
<li>В конце концов новая версия разворачивается на всех серверах.</li>
<li>позволяет проводить мониторинг и тестирование в реальных условиях с
минимальным риском
<ul>
<li>и ограничивает влияние потенциальных проблем небольшой базой
пользователей <img src="images/img_74.png" alt="img_74.png" /></li>
</ul></li>
</ul></li>
<li><p>Скользящие релизы (Rolling)</p>
<ul>
<li>экземпляры приложения постепенно обновляются по одному или
небольшими партиями без простоев</li>
<li>обеспечивает постоянное обслуживание трафика одними экземплярами, в
то время как другие находятся в процессе обновления.</li>
<li>обеспечивается постоянная доступность сервиса и снижается риск сбоев
за счёт обновления небольшими порциями</li>
<li>необходимость тщательной координации, чтобы обеспечить бесперебойное
обновление и механизмы отката.</li>
</ul></li>
</ul>
<pre><code>
Пример манифеста Kubernetes для скользящего развёртывания приложения

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:latest
        ports:
        - containerPort: 80 

</code></pre>
<ul>
<li>Балансировка нагрузки
<ul>
<li>методы автоматического масштабирования сервисов помогают выдерживать
значительные нагрузки в часы пик,
<ul>
<li>а балансировщики нагрузки — автоматически распределять входящие
запросы между этими экземплярами сервиса.</li>
</ul></li>
</ul></li>
<li>Безопасность
<ul>
<li>Внедрение HTTPS, использование OAuth2/OpenID Connect для
аутентификации и авторизации,
<ul>
<li>обеспечение шифрования данных при передаче и в процессе
хранения.</li>
</ul></li>
</ul></li>
<li>Мониторинг и наблюдение
<ul>
<li>Использование инструментов мониторинга (Prometheus, Grafana),
централизованного логирования (стек ELK),
<ul>
<li>распределённой трассировки (Jaeger, Zipkin) для отслеживания
взаимодействия с сервисами.</li>
</ul></li>
<li>Для каждого сервиса может потребоваться своя конфигурация
мониторинга и протоколирования.</li>
</ul></li>
<li>Хранение данных
<ul>
<li>NoSQL для масштабируемости, реляционных баз данных для
транзакционной согласованности, соответствующее разделение данных.</li>
<li>микросервис может иметь уникальные требования к хранению данных, что
требует гибкого подхода к выбору технологий и инструментов</li>
</ul></li>
<li>API-менеджмент
<ul>
<li>Использование API-шлюзов (Kong, Apigee), документирование API с
помощью инструментов (Swagger/OpenAPI),
<ul>
<li>внедрение версионности для управления изменениями API.</li>
</ul></li>
<li>задачи
<ul>
<li>Централизованно управлять доступом, маршрутизацией запросов,
мониторингом и безопасностью API,</li>
<li>обеспечивать балансировку нагрузки и защиту от атак</li>
<li>документирование (Автоматизировать процесс документирования помогают
инструменты Swagger/OpenAPI и Postman.)</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>API-менеджмент (управление API) — это процесс создания, публикации,
мониторинга, управления и обеспечения<br />
безопасности интерфейсов прикладного программирования (API) в безопасной
и масштабируемой среде</p>
</blockquote></li>
<li>Тестирование и валидация
<ul>
<li>Автоматизированные тестовые конвейеры</li>
<li>Mocking и stubbing помогают изолировать микросервисы, имитируя
поведение зависимостей, что упрощает тестирование и выявление
проблем.</li>
</ul></li>
<li>DevOps-практики
<ul>
<li>Использование конвейеров CI/CD для автоматизированного тестирования
и развёртывания, внедрение IaC с инструментами (Terraform, Ansible) для
управления инфраструктурой.</li>
</ul></li>
<li>Версионирование и совместимость
<ul>
<li>Обеспечение совместимости различных версий микросервисов друг с
другом — важная задача при миграции</li>
<li>номера версий - MAJOR.MINOR.PATCH</li>
<li>Важно обеспечивать обратную совместимость новых версий API с
предыдущими.</li>
</ul></li>
</ul>
<h3 id="настройка-github-kubernetes-1">Настройка Github Kubernetes</h3>
<ul>
<li>Создайте Personal Access Token (PAT)
https://github.com/settings/tokens . Создавайте class с правом
read:packages</li>
<li>далее генерим base64
<ul>
<li>echo -n
“AntonVolkov71:github_pat_11AOT2NFI045lVQLEA458k_ZQLMd2oJHvN9b…..” |
base64 -w 0</li>
</ul></li>
<li>minikube - все действия в PowerShell от администратора
<ul>
<li>установка minikube
https://kubernetes.io/ru/docs/tasks/tools/install-minikube/#minikube-before-you-begin-1</li>
<li>стартуем
<ul>
<li>minikube start</li>
<li>kubectl config use-context minikube</li>
</ul></li>
<li>далее запускаем Кубер
<ul>
<li>kubectl apply -f src/kubernetes/namespace.yaml</li>
</ul></li>
<li>проверка
<ul>
<li>kubectl get ns</li>
</ul></li>
<li>создаем секретики
<ul>
<li>kubectl apply -f src/kubernetes/dockerconfigsecret.yaml</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
# Принудительное удаление всех ресурсов в namespace
kubectl delete all --all -n cinemaabyss

# Или пересоздаем namespace полностью
kubectl delete namespace cinemaabyss
kubectl create namespace cinemaabyss

# Создаем namespace (если удалили)
kubectl apply -f src/kubernetes/namespace.yaml

# Применяем по порядку:
kubectl apply -f src/kubernetes/configmap.yaml
kubectl apply -f src/kubernetes/secret.yaml
kubectl apply -f src/kubernetes/dockerconfigsecret.yaml
kubectl apply -f src/kubernetes/postgres-init-configmap.yaml
kubectl apply -f src/kubernetes/postgres.yaml

# Ждем пока postgres запустится
kubectl get pods -n cinemaabyss -w

# Когда postgres будет Ready, применяем остальное
kubectl apply -f src/kubernetes/kafka/kafka.yaml
kubectl apply -f src/kubernetes/monolith.yaml
kubectl apply -f src/kubernetes/movies-service.yaml
kubectl apply -f src/kubernetes/events-service.yaml
kubectl apply -f src/kubernetes/proxy-service.yaml
Проверяем:
bash
kubectl get pods -n cinemaabyss
kubectl get pods -n cinemaabyss -w


## Елис нужно
kubectl delete -f src/kubernetes/events-service.yaml
kubectl delete -f src/kubernetes/movies-service.yaml
kubectl delete -f src/kubernetes/proxy-service.yaml
kubectl delete -f src/kubernetes/monolith.yaml
kubectl delete -f src/kubernetes/postgres.yaml
kubectl delete -f src/kubernetes/kafka/kafka.yaml

# Ждем полного удаления
kubectl get pvc -n cinemaabyss

# Удаляем PVC если остались
kubectl delete pvc -l app=postgres -n cinemaabyss

Проверим прогресс:
# Смотрим статус скачивания
kubectl describe pod zookeeper-0 -n cinemaabyss
kubectl describe pod kafka-0 -n cinemaabyss

# Смотрим события
kubectl get events -n cinemaabyss --sort-by=&#39;.lastTimestamp&#39; --watch

Ускорим процесс - проверим образы в minikube:
# Проверим какие образы уже есть в minikube
minikube ssh &quot;docker images | grep -E &#39;(zookeeper|kafka)&#39;&quot;

# Принудительно скачаем образы
minikube ssh &quot;docker pull wurstmeister/zookeeper&quot;
minikube ssh &quot;docker pull wurstmeister/kafka:2.13-2.7.0&quot;

Ожидаемое время:
Zookeeper: 2-5 минут
Kafka: 5-10 минут (больше размер)

Пока ждем, можем проверить другие сервисы:
kubectl get pods -n cinemaabyss

# Если они не запустились, исправим теги
kubectl delete -f src/kubernetes/events-service.yaml
kubectl delete -f src/kubernetes/proxy-service.yaml

# Затем применяем заново
kubectl apply -f src/kubernetes/events-service.yaml
kubectl apply -f src/kubernetes/proxy-service.yaml

# Когда kafka запустится, проверим логи
kubectl logs kafka-0 -n cinemaabyss -f

# Проверим создание топиков
kubectl exec -it kafka-0 -n cinemaabyss -- /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092

# Посмотреть логи последние
kubectl get events -n cinemaabyss --sort-by=&#39;.lastTimestamp&#39;

# Настройка ingress
 minikube addons enable ingress
 
# Смотрим поды ingress-nginx
kubectl get pods -n ingress-nginx -w

# Или проверяем статус
kubectl get all -n ingress-nginx

# Удаляем ingress addon
minikube addons disable ingress

# Ждем удаления
kubectl delete namespace ingress-nginx

# Смотрим события ingress
kubectl get events -n ingress-nginx --sort-by=.lastTimestamp --watch

  kubectl apply -f src/kubernetes/ingress.yaml

  - Добавьте в /etc/hosts
   127.0.0.1 cinemaabyss.example.com
   
  - Вызовите
    minikube tunnel

- теперь ДОСТУПНЫ  https://cinemaabyss.example.com/api/movies

</code></pre>
<h3 id="helm-3">Helm</h3>
<ul>
<li>запуск
<ul>
<li>helm install cinemaabyss .–namespace cinemaabyss
–create-namespace</li>
</ul></li>
<li>удаление
<ul>
<li>helm uninstall cinemaabyss –namespace cinemaabyss</li>
</ul></li>
<li>Обновляем helm релиз
<ul>
<li>helm upgrade cinemaabyss .-n cinemaabyss</li>
</ul></li>
<li>Проверьте развертывание:
<ul>
<li>kubectl get pods -n cinemaabyss</li>
<li>minikube tunnel</li>
</ul></li>
<li>логи
<ul>
<li>kubectl get pods -n cinemaabyss</li>
<li>kubectl get service events-service -n cinemaabyss kubectl describe
service events-service -n cinemaabyss</li>
</ul></li>
<li>Посмотреть логи конкретного pod
<ul>
<li>kubectl logs <pod-name> -n cinemaabyss</li>
<li>kubectl logs postgres-0 -n cinemaabyss</li>
<li>kubectl logs events-service-5944bf88d9-pzs7t -n cinemaabyss</li>
</ul></li>
<li>Описать pod для детальной информации
<ul>
<li>kubectl describe pod <pod-name> -n cinemaabyss</li>
</ul></li>
</ul>
<h3 id="circuit-breaker-1">Circuit Breaker</h3>
<ul>
<li>Аналогия: Представьте себе автоматический выключатель в
электрической системе.
<ul>
<li>Когда возникает перегрузка, он “разрывает” цепь, чтобы предотвратить
повреждение оборудования.</li>
</ul></li>
<li>Состояния Circuit Breaker
<ul>
<li>CLOSED (Закрыт) - нормальная работа
<ul>
<li>Все запросы проходят к целевому сервису</li>
<li>Ведутся счетчики ошибок</li>
</ul></li>
<li>OPEN (Открыт) - “разрыв цепи”</li>
<li>Запросы немедленно отклоняются без обращения к целевому сервису</li>
<li>Возвращаются заранее подготовленные fallback-ответы</li>
<li>HALF-OPEN (Полуоткрыт) - тестирование восстановления
<ul>
<li>Пропускается ограниченное количество запросов</li>
<li>Если они успешны - возврат в CLOSED</li>
<li>Если есть ошибки - возврат в OPEN</li>
</ul></li>
</ul></li>
<li>Зачем это нужно?
<ul>
<li>Предотвращение каскадных отказов - один упавший сервис не “тянет” за
собой всю систему</li>
<li>Экономия ресурсов - не тратим время на ожидание ответов от
неработающих сервисов</li>
<li>Улучшение user experience - быстрый fallback вместо долгого ожидания
таймаута</li>
<li>Автоматическое восстановление - система сама тестирует, когда сервис
восстановился</li>
</ul></li>
<li>Конфигурация Circuit Breaker в Istio</li>
</ul>
<pre><code>
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: movies-cb
  namespace: cinemaabyss
spec:
  host: movies-service  # К какому сервису применяем правила
  trafficPolicy:
    # НАСТРОЙКИ ПУЛА СОЕДИНЕНИЙ
    connectionPool:
      tcp:
        maxConnections: 1          # Максимум одновременных TCP-соединений
      http:
        http1MaxPendingRequests: 1 # Максимум HTTP-запросов в очереди
        maxRequestsPerConnection: 1 # Максимум запросов на одно соединение
    
    # НАСТРОЙКИ ДЕТЕКЦИИ АНОМАЛИЙ
    outlierDetection:
      consecutive5xxErrors: 1      # После 1 ошибки 5xx - исключаем хост
      interval: 1s                 # Период проверки (очень агрессивный!)
      baseEjectionTime: 3m         # Минимальное время исключения хоста
      maxEjectionPercent: 100      # Можем исключить до 100% хостов

</code></pre>
<ul>
<li>запуск</li>
</ul>
<pre><code>

helm repo add istio https://istio-release.storage.googleapis.com/charts
helm repo update

helm install istio-base istio/base -n istio-system --set defaultRevision=default --create-namespace
helm install istio-ingressgateway istio/gateway -n istio-system
helm install istiod istio/istiod -n istio-system --wait

helm install cinemaabyss .\src\kubernetes\helm --namespace cinemaabyss --create-namespace

kubectl label namespace cinemaabyss istio-injection=enabled --overwrite

kubectl get namespace -L istio-injection

kubectl apply -f .\src\kubernetes\circuit-breaker-config.yaml -n cinemaabyss

</code></pre>
<ul>
<li>тестирование
<ul>
<li>kubectl apply -f
https://raw.githubusercontent.com/istio/istio/release-1.25/samples/httpbin/sample-client/fortio-deploy.yaml
-n cinemaabyss</li>
</ul>
<pre><code>  $FORTIO_POD = kubectl get pods -n cinemaabyss | Select-String &quot;fortio&quot; | ForEach-Object { $_.ToString().Split()[0] }
  Write-Host &quot;Fortio Pod: $FORTIO_POD&quot;</code></pre>
<ul>
<li>kubectl exec -n cinemaabyss fortio-deploy-b6757cbbb-7c9qg -c fortio
– fortio load -c 50 -qps 0 -n 500 -loglevel Warning
http://movies-service:8081/api/movies</li>
<li>kubectl exec -n cinemaabyss fortio-deploy-5c948d95cf-hcr9k -c fortio
– fortio load -c 50 -qps 0 -n 500 -loglevel Warning
http://movies-service:8081/api/movies</li>
<li>kubectl exec -n cinemaabyss fortio-deploy-5c948d95cf-hcr9k -c
istio-proxy – pilot-agent request GET stats | Select-String
“movies-service” | Select-String “pending”</li>
</ul></li>
<li>даляем все</li>
</ul>
<pre><code>bash
choco install istioctl
istioctl uninstall --purge
kubectl delete namespace istio-system
kubectl delete all --all -n cinemaabyss
kubectl delete namespace cinemaabyss

</code></pre>
<h2 id="цифровая-трансформация-1">Цифровая трансформация</h2>
<ul>
<li><p>Цифровая трансформация — это комплексное внедрение цифровых
технологий в деятельность компании.</p>
<ul>
<li>Это не просто обновление оборудования или программного обеспечения,
а глубокое изменение процессов,</li>
<li>взаимодействия с клиентами и в результате всей бизнес-модели.</li>
</ul></li>
<li><p>Автоматизация и цифровизация — это этапы в жизни компании,
которые могут привести к цифровой трансформации</p></li>
<li><p>При автоматизации часть бизнес-процессов в такой компании
проходит через информационные системы, а часть может работать
по-старому</p>
<ul>
<li>бизнес не зависит от цифровых технологий и может легко работать без
них</li>
</ul></li>
<li><p>При цифровизации компания постепенно отказывается от аналоговых
процессов и переводит данные о клиентах и ведении бизнеса в цифровую
форму</p>
<ul>
<li>Бизнес уже не сможет обойтись без цифровых инструментов в случае
сбоя</li>
</ul></li>
<li><p>При цифровой трансформации компания напрямую зарабатывает на
цифровых продуктах.</p>
<ul>
<li>Продажи становятся невозможными без сайта и мобильного
приложения.</li>
</ul></li>
</ul>
<h3 id="формирование-стратегии-цифровой-трансформации-1">Формирование
стратегии цифровой трансформации</h3>
<ul>
<li><p>Стратегия — это основа цифровой трансформации.</p>
<ul>
<li>Обычно это большая презентация и несколько дополнительных документов
<ul>
<li>цели на несколько лет и способы их достижения</li>
<li>взгляд на компанию «сверху», детальный план достижения целей
определяется позже.</li>
</ul></li>
</ul></li>
<li><p>Шаги для формирования стратегии <img src="images/img_75.png"
alt="img_75.png" /></p></li>
<li><p>Шаг 1. Определить цели трансформации</p>
<ul>
<li>анализ рынка и конкурентов, исследование компании и мировых трендов
в отрасли, рекомендации консалтинговых компаний</li>
<li>бизнес-стратегия, которую должны определить акционеры и
топ-менеджмент.</li>
</ul></li>
<li><p>Шаг 2. Описать текущую и целевую бизнес-модель</p>
<ul>
<li>зафиксировать нынешнюю бизнес-модель и описать план изменений</li>
</ul></li>
<li><blockquote>
<p>Бизнес-модель — это описание того, как организация создаёт ценность
для рынка и извлекает прибыль. она определяет партнёров, действия для
заработка, ресурсы для работы, ценностное предложение для рынка,
взаимоотношения с клиентами и их деление по сегментам, каналы продаж,
структуру затрат, потоки дохода.</p>
</blockquote></li>
<li><p>Бизнес-модель удобно представить в Business Model Canvas</p></li>
<li><p>текущая <img src="images/img_76.png" alt="img_76.png" /></p></li>
<li><p>по плану <img src="images/img_77.png"
alt="img_77.png" /></p></li>
<li><p>Шаг 3. Описать текущую и целевую архитектуру</p>
<ul>
<li>сначала определяют, из каких систем она состоит и какие процессы
обслуживает.
<ul>
<li>Для этого нужно описать текущую архитектуру.</li>
<li>А описание целевой архитектуры поможет понять, что именно нужно
изменить в IT-ландшафте для достижения целей.</li>
<li>С этим помогут карты IT-ландшафта и схемы интеграции приложений.
<img src="images/img_78.png" alt="img_78.png" /></li>
</ul></li>
</ul></li>
<li><p>Шаг 4. Спланировать изменения</p>
<ul>
<li>стратегические изменения планируются на несколько лет вперёд в
формате проекта или целой программы</li>
</ul></li>
</ul>
<h2 id="текущее-и-целевое-состояние-бизнеса-1">Текущее и целевое
состояние бизнеса</h2>
<ul>
<li>На самом высоком уровне выстраивается корпоративная архитектура
(enterprise architecture)
<ul>
<li>Это практика проектирования, планирования и управления структурой
организации.</li>
<li>Она охватывает все уровни работы компании, начиная с
бизнес-процессов и заканчивая IT-инфраструктурой, и связывает их с
целями и стратегией организации</li>
</ul></li>
</ul>
<h3 id="бизнес-архитектура-компании-1">Бизнес-архитектура компании</h3>
<ul>
<li>Под бизнес-архитектурой подразумевается связь между структурой
бизнеса,
<ul>
<li>стратегией развития и архитектурой информационных систем.</li>
<li>Это понятие иллюстрирует схема в виде пирамиды, где на верхнем
уровне находятся бизнес-цели <img src="images/img_79.png"
alt="img_79.png" /></li>
</ul></li>
<li>пирамидальная структура компании N
<ul>
<li>Бизнес-цель</li>
</ul></li>
</ul>
<pre><code>
Компания N выходит на рынок B2C со стриминг-сервисом. 
Чтобы достичь этой цели, ей потребуется сформулировать маркетинговую стратегию для продвижения и привлечения клиентов. 
Топ-менеджмент определил, что привлекать клиентов нужно через digital-каналы: 
  например, размещать контекстную рекламу, которая должна вести клиентов на лендинги.

</code></pre>
<ul>
<li>Бизнес-архитектура</li>
</ul>
<pre><code>
С учётом бизнес-цели в существующую архитектуру бизнеса нужно будет встроить подразделение digital-маркетинга. 
Сейчас компания привлекает клиентов традиционным способом: 
  в основном через профильные мероприятия.
То есть на предприятии нет экспертизы маркетинговых кампаний через digital.

Чтобы преодолеть это препятствие, можно, например, привлечь сторонние маркетинговые агентства. 
Для этого потребуется создать отдельный бизнес-процесс, за который будет отвечать определённое подразделение.
Но это решение не позволит нарастить свою компетенцию и будет требовать постоянных затрат.

В долгосрочной перспективе выгоднее создать подразделение digital-маркетинга,
 которое будет и работать с агентствами, и наращивать свою экспертизу через самостоятельные запуски рекламных кампаний.


</code></pre>
<ul>
<li>IT-архитектура</li>
</ul>
<pre><code>
Бизнес-цель компании диктует изменения в архитектуре бизнеса, а это, в свою очередь, повлечёт за собой и трансформацию IT-архитектуры.

Чтобы новому digital-подразделению провести первую кампанию, 
потребуется лендинг, на который будут вести ссылки из рекламы, и базовые знания табличных редакторов, чтобы проанализировать результаты.
Лендинг маркетолог с дизайнером соберут на блочном конструкторе сайтов, а данные выгрузят в Excel. 
Но по мере роста продукта, компетенций подразделения и усложнения процессов для digital-маркетинга 
может понадобиться целая система запуска рекламных кампаний и оценки их эффективности, 
а также методы и инструменты оценки эффективности подрядчиков и многое другое.ё

</code></pre>
<h3 id="бизнес-возможности-компании-1">Бизнес-возможности компании</h3>
<ul>
<li><p>В действительности при стратегическом подходе к изменениям в
бизнес-архитектуре нужно определить все необходимые изменения.</p>
<ul>
<li>Чтобы этого достичь, можно использовать описание бизнес-возможностей
(англ. business capability) компании.</li>
</ul></li>
<li><p>Бизнес-возможности — это способность бизнеса осуществлять
определённые действия.</p></li>
<li><p>Бизнес-возможности описывают, что делает или может делать
бизнес.</p></li>
<li><p>Этим они отличаются от бизнес-процессов, в которых описаны именно
шаги по достижению целей.</p></li>
<li><p>Это понятие активно применяется во фреймворке корпоративной
архитектуры TOGAF.</p></li>
<li><p>Бизнес-возможности для компании N</p>
<ul>
<li>На высоком уровне - бизнес-возможность «Продажи и маркетинг».</li>
<li>Из описания бизнес-архитектуры выделяется возможность «Управление
маркетингом».</li>
<li>В компании работает привлечение партнёров через конференции — это
можно выделить в возможность «Ивент-маркетинг B2B».</li>
<li>А вот возможности привлекать клиентов через цифровые каналы в
компании сейчас нет — этого нужно достичь через трансформацию.
<ul>
<li>Бизнес компании N нуждается в этом и способен на такую
трансформацию, а значит — это бизнес-возможность компании
«Digital-маркетинг B2C».</li>
</ul></li>
</ul></li>
<li><p>Карта бизнес-возможностей <img src="images/img_80.png"
alt="img_80.png" /></p>
<ul>
<li>Бизнес-возможности полезно собирать в отдельный артефакт — карту
бизнес-возможностей (business capability map)</li>
<li>описывает все возможности, которые уже есть в компании, и те,
которые будут в её целевом состоянии</li>
<li>крупных компаний бизнес-возможностей обычно много, и карты
получаются достаточно объёмными.</li>
</ul></li>
<li><p>Карта текущих бизнес-возможностей <img src="images/img_81.png"
alt="img_81.png" /></p>
<ul>
<li>проанализировав оргструктуру, в результате выделила главные
бизнес-возможности компании N по группам:
<ul>
<li>производство контента,</li>
<li>продажи и маркетинг,</li>
<li>взаимодействие с клиентами,</li>
<li>взаимодействие с партнёрами,</li>
<li>поддержка бизнеса.</li>
</ul></li>
<li>Теперь можно выделить различные группы бизнес-возможностей, которые
важны для компании.</li>
<li><figure>
<img src="images/img_82.png" alt="img_82.png" />
<figcaption aria-hidden="true">img_82.png</figcaption>
</figure></li>
</ul></li>
<li><p>Целевая карта бизнес-возможностей</p>
<ul>
<li>Следующим этапом нужно выделить бизнес-возможности, которые помогут
реализовать цель цифровой трансформации — создать стриминг-сервис и
выйти на рынок B2C.</li>
<li>И добавить новые бизнес-возможности в карту текущих</li>
</ul></li>
<li><p>карта бизнес-возможностей после добавления тех, которые
потребуются для трансформации бизнеса компании N:</p>
<ul>
<li><figure>
<img src="images/img_83.png" alt="img_83.png" />
<figcaption aria-hidden="true">img_83.png</figcaption>
</figure></li>
</ul></li>
<li><p>Целевая структура компании</p>
<ul>
<li>как измениться структура компании</li>
<li>Направление B2C — новое для компании. В первую очередь нужно создать
стриминг-платформу,
<ul>
<li>которая и обеспечит продажи B2C-клиентам. Для этого можно создать
отдельное управление по модели внутреннего стартапа.
<ul>
<li>Отдел продуктового развития и сопровождения</li>
<li>Отдел технического развития и сопровождения</li>
<li>подразделение маркетинга и цифровых продаж.</li>
<li><figure>
<img src="images/img_84.png" alt="img_84.png" />
<figcaption aria-hidden="true">img_84.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Потоки создания ценности</p>
<ul>
<li>Чтобы понять, какие бизнес-возможности важны, а какие нет, — нужно
сравнить их с этапами потока создания ценностей.</li>
<li>Поток создания ценности (англ. value stream)
<ul>
<li>это последовательность действий, или этапов создания ценности,
которые организация выполняет для удовлетворения потребности
клиента.</li>
<li>Клиентом может быть как внешний, так и внутренний заинтересованный
субъект, отвечающий за поддержку создания ценности в организации.</li>
<li><figure>
<img src="images/img_85.png" alt="img_85.png" />
<figcaption aria-hidden="true">img_85.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul>
<h2 id="текущая-и-целевая-архитектура-1">Текущая и целевая
архитектура</h2>
<ul>
<li><p>для нас IT-ландшафт — это совокупность всех информационных
технологий и систем в организации, включая оборудование,</p>
<ul>
<li>программное обеспечение и их взаимодействие, поддерживающие
бизнес-процессы</li>
</ul></li>
<li><p>Информационная архитектура, или архитектура данных, отражает
взаимодействие с данными:</p>
<ul>
<li>с какими данными работает компания, какие есть правила и политики
работы с данными и как они распределяются по системам внутри
компании.</li>
</ul></li>
<li><p>Архитектура приложений показывает, какие есть приложения, как они
взаимодействуют друг с другом</p></li>
<li><p>А техническая архитектура подразумевает аппаратное обеспечение,
то есть инфраструктуру, центры обработки данных,</p>
<ul>
<li>серверы, на которых работают приложения</li>
</ul></li>
</ul>
<h3 id="обзор-основных-классов-it-систем-компаний-1">Обзор основных
классов IT-систем компаний</h3>
<ul>
<li>Универсальные системы
<ul>
<li>они охватывают ключевые бизнес-процессы, такие как управление
ресурсами и аналитика, которые необходимы
<ul>
<li>для эффективного функционирования любой организации независимо от её
отрасли</li>
</ul></li>
<li>ERP (Enterprise Resource Planning)
<ul>
<li>системы для планирования ресурсов предприятия и управления ими.</li>
<li>Например, SAP и 1C ERP
<ul>
<li>включают в себя практически все бизнес-процессы компании или в
значительной степени замыкают процессы на себя</li>
<li>в одном месте обеспечить управление производством, трудовое
планирование, логистику, бухгалтерию,</li>
<li>финансовый менеджмент, управление активами и множество других
функций.</li>
<li>!!! В целом есть тренд на отказ от ERP-систем и перенос функций в
системы поменьше</li>
</ul></li>
</ul></li>
<li>BPMS (Business Process Management System)
<ul>
<li>системы управления бизнес-процессами</li>
<li>Например, Camunda BPM
<ul>
<li>системы позволяют визуализировать бизнес-процессы в какой-то
нотации, например BPMN, и обеспечивать их автоматизацию</li>
</ul></li>
</ul></li>
<li>CRM (Customer Relationship Management)
<ul>
<li>актуальны практически для любой компании, где есть процессы
продаж</li>
<li>отвечают за организацию взаимодействия с клиентами и все этапы
продажи — от поиска клиента до заключения сделки</li>
<li>CRM-системы могут быть «коробочными» или разрабатываться
самостоятельно</li>
</ul></li>
<li>MDM (Master Data Management)
<ul>
<li>Чтобы обеспечить общие правила и единый источник истины, часто
бывает нужна MDM-система. В ней данные всегда
<ul>
<li>находятся в наиболее правильном состоянии для других систем
компании.</li>
</ul></li>
</ul></li>
<li>BI (Business Intellegence)
<ul>
<li>системы сбора и обработки аналитической информации о работе
компании</li>
<li>позволяют принимать решения на основе данных о клиентах, продажах,
закупках, рисках и других его элементах.</li>
</ul></li>
</ul></li>
<li>Специфичные системы
<ul>
<li>PLM (Product Lifecycle Management)
<ul>
<li>система управления жизненным циклом продукта — от конструирования до
производства и утилизации</li>
<li>Например, Teamcenter</li>
</ul></li>
<li>PDM (Product Data Management)
<ul>
<li>позволяет работать с автоматизированным проектированием для сбора
информации о версиях узлов изделия
<ul>
<li>и вести разработку изделия полностью в цифровом виде</li>
</ul></li>
</ul></li>
<li>MES (Manufacturing Execution Eystem)
<ul>
<li>системы для управления самим процессом производства на заводах и
фабриках.</li>
</ul></li>
<li>SCADA (Supervisory Control and Data Acquisition)
<ul>
<li>Системы для сбора данных с различных устройств в процессе
производства и управления линиями, станками с ЧПУ и так далее.</li>
<li>В производственных компаниях SCADA, MES и ERP часто интегрированы
между собой.</li>
</ul></li>
<li>АБС (Автоматизированная банковская система)
<ul>
<li>системы отвечают за работу с транзакциями по счетам, за учёт по
банковских продуктам и специализированную бухгалтерию банка.</li>
<li>Например, ЦФТ. <img src="images/img_86.png" alt="img_86.png" /></li>
</ul></li>
</ul></li>
</ul>
<h3 id="описание-текущей-и-целевой-архитектуры-1">Описание текущей и
целевой архитектуры</h3>
<h4 id="карта-it-ландшафта-1">Карта IT-ландшафта</h4>
<ul>
<li>Одним из инструментов визуализации архитектуры могут быть различные
кластерные карты, например карта IT-ландшафта
<ul>
<li>В колонках указываются бизнес-подразделения, в строках —
бизнес-возможности, а на пересечении — IT-системы</li>
</ul></li>
<li>Рассмотрим построение карты IT-ландшафта для компании N. У нас есть
информация о следующих приложениях в компании:
<ul>
<li>Система производства контента.
<ul>
<li>В ней работают продюсеры, которые отвечают за производство
контента.</li>
<li>Разрабатывают систему несколько программистов из IT-отдела.
Клиент-серверная система, приложение на Windows разработаны на QT (C++)
и сервер на Java Spring.</li>
</ul></li>
<li>CRM-система на платформе Bitrix.
<ul>
<li>Системой пользуются менеджеры по продажам, работающие с каналами.
Поддержка осуществляется внутри IT-отдела.</li>
</ul></li>
<li>Сайт. Собственная разработка на PHP.
<ul>
<li>Поддерживается разработчиками из IT-отдела.</li>
</ul></li>
<li>1С: Зарплата и управление персоналом.
<ul>
<li>В системе работают HR-отдел и бухгалтерия, поддерживается
разработчиком внутри IT-отдела.</li>
</ul></li>
<li>1С: Бухгалтерия
<ul>
<li>Используют бухгалтеры, поддерживается разработчиком внутри
отдела.</li>
</ul></li>
</ul></li>
<li>В ходе разработки карты и общения с представителями компании
выяснилось,
<ul>
<li>что система производства контента имеет значительно больше
функциональных возможностей, чем казалось изначально:
<ul>
<li>Она имеет модуль проектного управления, где продюсеры заводят проект
на производство контента, планируют его график и отслеживают ход
выполнения проекта.</li>
<li>В ней есть модуль управления партнёрами, где ведутся
партнёры-производители контента и подрядчики, выполняющие различные
функции проекта.</li>
<li>Документооборот по оплате услуг тоже происходит в этой системе:
бухгалтеры вручную загружают документы из системы для отражения в
бухгалтерской программе для учёта.</li>
<li>Сотрудники отдела кадров работают с проектами и сотрудниками
проектов, которые работают во внутреннем штате, чтобы верно начислять
зарплату, так как она зависит от участия сотрудников в конкретных
проектах.</li>
<li>Сотрудники юридического отдела следят за договорами с
партнёрами-подрядчиками — юридический документооборот также происходит
через эту систему.</li>
<li>Исторически весь каталог контента компании ведётся здесь, так как
контент связан с проектом на его производство.</li>
<li>В CRM менеджеры по продажам ведут сделки по продаже контента,
маркетологи проводят кампании привлечения и заносят обращения от
клиентов (лиды) на мероприятиях.</li>
<li>Для послепродажного обслуживания сотрудники отдела заносят обращения
клиентов. <img src="images/img_87.png" alt="img_87.png" /></li>
</ul></li>
</ul></li>
</ul>
<h4 id="целевая-карта-ландшафта-1">Целевая карта ландшафта</h4>
<ul>
<li>На этом уровне можно определить такие основные функциональные
возможности:
<ul>
<li>Медиаплатформа будет включать в себя новые возможности по разработке
digital-продуктов, маркетингу, новым процессам разработки и
сопровождения, дата-аналитике.
<ul>
<li>Кроме того, есть пересечения в функциях медиаплатформы и системы
производства контента в части управления библиотекой контента.</li>
</ul></li>
<li>Есть ожидания по возможности digital-онбординга партнёров и
упрощению сопровождения партнёров
<ul>
<li>это потребует существенного изменения системы производства
контента.</li>
<li>Партнёры, чей контент будет представлен на платформе, будут получать
отчисления от количества просмотров.</li>
</ul></li>
<li>Библиотека контента ведётся в системе производства. Поэтому
управлению по работе с клиентами тоже понадобится работать с контентом,
<ul>
<li>чтобы исключать риски нарушения условий договора с клиентами при
использовании контента на платформе. <img src="images/img_88.png"
alt="img_88.png" /></li>
</ul></li>
</ul></li>
</ul>
<h4 id="платформы-в-разработке-и-архитектуре-компаний-1">Платформы в
разработке и архитектуре компаний</h4>
<ul>
<li>Под платформой в организации часто подразумевается некоторый
организационно-технический компонент в структуре компании,
<ul>
<li>который позволяет быстрее и проще реализовывать типовые
изменения.</li>
</ul></li>
</ul>
<h4 id="диаграмма-интеграции-приложений-1">Диаграмма интеграции
приложений</h4>
<ul>
<li><p>бизнес-процессы затрагивают много систем и подразделений, то это
часто приводит к интеграциям между приложениями</p></li>
<li><p>полезно построить диаграмму интеграции. Для такой схемы можно
использовать любую нотацию, например C4 или UML,</p>
<ul>
<li>но на стратегическом уровне достаточно обобщённой схемы без
детализации всех потоков данных.</li>
</ul></li>
<li><p>лучше акцентировать внимание на одной-двух основных системах,
вокруг которых происходят взаимодействия</p></li>
<li><p>Диаграмму интеграции можно построить, анализируя карту
IT-ландшафта по пересечениям систем, проведя интервью</p>
<ul>
<li>с представителями компании или по текущей документации и выявленным
функциональным возможностям, которые определены в ходе первичного
анализа.</li>
</ul></li>
<li><p>Текущая диаграмма интеграции приложений</p>
<ul>
<li>На диаграмме указываются основные бизнес-сущности и типы операций на
информационных потоках.</li>
<li>Если компания имеет большое число систем и категорий пользователей,
то можно показать только системы и их взаимодействие. <img
src="images/img_89.png" alt="img_89.png" /></li>
</ul></li>
<li><p>Целевая диаграмма интеграции приложений</p>
<ul>
<li>Нужно определить изменения, которые произойдут, чтобы достичь
стратегической цели по созданию платформы</li>
<li>На этом этапе точно можно сказать, что потребуются изменения в
системе производства контента по нескольким причинам:</li>
<li>Медиаплатформе нужен доступ к библиотеке контента.</li>
<li>Работа с партнёрами ведётся вручную — хочется предоставить
компаниям-партнёрам личный кабинет для более удобной
<ul>
<li>работы с компанией в рамках производства контента. <img
src="images/img_90.png" alt="img_90.png" /></li>
</ul></li>
</ul></li>
</ul>
<h2 id="планирование-стратегических-изменений-1">Планирование
стратегических изменений</h2>
<ul>
<li><p>Определение действий и сроков реализации — последний этап
подготовки стратегии изменений</p></li>
<li><p>Изменения в подразделениях, бизнес-возможностях и IT-системах —
определили. Теперь нужно:</p>
<ul>
<li>Спланировать этапы реализации и общие задачи.</li>
<li>Определить сроки этапов.</li>
<li>Определить ответственные подразделения компании.</li>
<li>Оценить предварительную стоимость трансформации на стратегическом
горизонте планирования.</li>
</ul></li>
<li><p>Для этого подходит дорожная карта — roadmap, или роадмап</p>
<ul>
<li>На уровне стратегии это ещё неточный план — лишь общие направления
реализации</li>
<li><figure>
<img src="images/img_91.png" alt="img_91.png" />
<figcaption aria-hidden="true">img_91.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="дорожная-карта-цифровой-трансформации-1">Дорожная карта цифровой
трансформации</h3>
<ul>
<li>для визуализации изменений можно создать дорожную карту цифровой
трансформации — Digital Transformation Roadmap
<ul>
<li>шаги и сроки реализации — без детализации работ</li>
<li>поможет наглядно представить шаги преобразования, оценить ресурсы,
сроки и скорректировать подходы</li>
</ul></li>
<li>пример вариант роадмапа трансформации компании на ближайшие годы по
кварталам:
<ul>
<li>2024-й:
<ul>
<li>Определение целей.</li>
<li>Разработка бизнес-архитектуры.</li>
<li>Разработка IT-архитектуры.</li>
<li>Планирование изменений.</li>
</ul></li>
<li>2025-й:
<ul>
<li>Создание бизнес-подразделений на основе новой бизнес-архитектуры, в
том числе найм IT-команд.</li>
<li>Разработка первой версии платформы и определение дальнейшей
стратегии развития продукта после её запуска.</li>
<li>Модернизация системы производства контента для совместной работы с
библиотекой к моменту запуска платформы.</li>
<li>Определение стратегии развития платформы.</li>
</ul></li>
<li>2026-й:
<ul>
<li>Масштабирование платформы для пользователей и работа над
монетизацией.</li>
<li>Модернизация системы производства контента для быстрого привлечения
партнёров. <img src="images/img_92.png" alt="img_92.png" /><br />
<img src="images/img_117.png" alt="img_117.png" /></li>
</ul></li>
</ul></li>
</ul>
<h3 id="различные-подходы-1">Различные подходы</h3>
<h4 id="проектный-подход-1">Проектный подход</h4>
<ul>
<li>Проект — это временное предприятие, предназначенное для создания
уникальных продуктов, услуг или результатов.
<ul>
<li>В частности, IT-проект — это проект в сфере создания, внедрения или
применения информационных технологий.</li>
</ul></li>
<li>характеристики проекта
<ul>
<li>Ограничен во времени.</li>
<li>Приводит к заранее определённому результату по изначально
определённым требованиям.</li>
<li>Состоит из последовательных шагов.</li>
<li>Требует ограниченных ресурсов — например, людей и денег на
реализацию. Центральным ресурсом проекта является бюджет.</li>
<li>Состоит из трёх этапов — планирования, исполнения и управления.</li>
</ul></li>
<li><blockquote>
<p>Проектное управление и проектный подход отвечают на вопрос: «Как
реализовать заданный результат к определённой дате в рамках доступного
бюджета и ресурсов?».</p>
</blockquote></li>
<li>Проектом управляет менеджер проекта — Project Manager, PM
<ul>
<li>и ключевые участники
<ul>
<li>Команда проекта. Люди, которые будут реализовывать проект.</li>
<li>Спонсор. Подразделение или человек, которые предоставляют ресурсы
для проекта.</li>
<li>Заказчик. Подразделение или человек, которые будут использовать
результат проекта.</li>
<li>Заинтересованные стороны. Люди и организации, прямо или косвенно
оказывающие влияние на ход проекта и его результаты.
<ul>
<li>Их часто называют стейкхолдерами.</li>
</ul></li>
</ul></li>
</ul></li>
<li>В крупных организациях ведут много проектов, поэтому в них есть
проектный офис
<ul>
<li>вырабатывает единые правила по управлению проектами и отвечает за их
реализацию</li>
<li>попадают инициативы от бизнеса, которые требуют изменений в
технологиях</li>
<li>оценивают, планируют, а затем бизнес принимает решение о
необходимости реализации: если проект нужен — его реализовываю</li>
</ul></li>
<li>для реализации стратегических изменений нужно много проектов, их
объединяют в программу проектов
<ul>
<li>отдельно программы не приведут к глобальному результату, только в
комплексе
<ul>
<li>есть стандарты PRINCE2 и PmBook</li>
</ul></li>
</ul></li>
<li>простой роадмап программы проектов для компании N <img
src="images/img_93.png" alt="img_93.png" /></li>
</ul>
<h4 id="продуктовый-подхода">Продуктовый подхода</h4>
<ul>
<li><p>Продукт — это результат деятельности компании, который
предназначен для удовлетворения потребностей пользователей или
рынка.</p>
<ul>
<li>Он может быть материальным или нематериальным и имеет свой жизненный
цикл.</li>
</ul></li>
<li><p>Продуктовый подход</p>
<ul>
<li>рассчитан на улучшение продукта в течение всего жизненного
цикла.</li>
<li>подход сосредоточен на бюджете и выполнении проекта в установленные
сроки — с фиксированными целями и результатами.</li>
<li>важна адаптивность и постоянное развитие, в проектном — завершение
конкретной задачи.</li>
</ul></li>
<li><p>пример</p>
<ul>
<li>Разработку медиаплатформы в компании N выделили в отдельное
управление в прямом подчинении CEO, чтобы добиться автономности
<ul>
<li>Управление развития медиаплатформы:
<ul>
<li>Отдел продуктового развития и сопровождения.
<ul>
<li>отвечает за развитие продукта, добавление функций, проектирование
интерфейса, определение эффективности и стратегии развития.</li>
<li>По сути, менеджеры этого отдела создают задачи на развитие
продукта.</li>
</ul></li>
<li>Отдел технологического развития и сопровождения платформы.
<ul>
<li>несколько групп разработки со своими техлидами
<ul>
<li>Группа системной аналитики.</li>
<li>Группа frontend-разработки.</li>
<li>Группа backend-разработки.</li>
<li>Группа тестирования.</li>
<li>Группа администрирования.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>вместо проектной модели изменений в продуктах используют
Agile-подходы к разработке</p>
<ul>
<li>команда продукта постоянно проверяет гипотезы и разрабатывает новые
функции — а бюджет выделяется не по проектам, а постепенно</li>
<li>разница между проектным и продуктовым подходами <img
src="images/img_94.png" alt="img_94.png" /></li>
</ul></li>
<li><p>продукт - удовлетворяет Потребности</p></li>
<li><p>проект - удовлетворяет проблему конкретную</p></li>
<li><p>продукт менеджер (PM, Product Manager)</p>
<ul>
<li>Это специалист, который отвечает за стратегию, планирование и
развитие продукта в компании
<ul>
<li>Основные функции PM:
<ul>
<li>Определение видения продукта.</li>
<li>Анализ рынка и пользователей.</li>
<li>Разработка стратегии.</li>
<li>Работа с командами развития продукта — маркетингом, разработкой,
поддержкой и другими.</li>
<li>Определение приоритетов работы над продуктом.</li>
<li>Анализ результатов и обратной связи.</li>
<li>Управление бюджетом продукта — не всегда.</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Customer Development, — процесс выявления потребностей с помощью
интервью у потенциальных пользователей приложения</p></li>
<li><p>Customer Journey Map, CJM - карта клиентского пути</p>
<ul>
<li>продукт будет полезен. Теперь нужно выявить, как им пользоваться на
концептуальном уровне и как организовать привлечение пользователей</li>
</ul></li>
<li><p>Lean-модель, оформленную в Lean Canvas - Чтобы оценить
целесообразность создания продукта</p></li>
<li><p>MVP — Minimal Valuable Product - полезно подготовить первую
версию продукта — запустить её и проверить гипотезу о потребности на
рынке</p></li>
</ul>
<h4 id="метрики-бизнеса-и-продуктов-1">Метрики бизнеса и продуктов</h4>
<ul>
<li>инвестиционные метрики - Для определения целесообразности на уровне
всего бизнеса и его стратегии</li>
<li>бизнес-метрики - Для определения целесообразности конкретных
продуктов или проектов</li>
<li>продуктовые метрики - они помогают выявить приоритеты в развитии
продукта и оценить его текущее состояние</li>
</ul>
<h4 id="инвестиционные-метрики-1">Инвестиционные метрики</h4>
<ul>
<li>Это метрики, отражающие объём вложений в бизнес и эффективность
использования средств.
<ul>
<li>С ними работают акционеры, финансовые менеджеры или IT-директора —
топ-менеджмент компании</li>
</ul></li>
<li>CAPEX, или Capital Expenditure - то затраты предприятия на
приобретение крупных активов на срок больше года и их модернизацию —
капитальные инвестиции</li>
<li>OPEX, или Operational Expenditure. - Это операционные расходы —
затраты на обеспечение текущей деятельности, а не инвестиции в
будущее</li>
</ul>
<h4 id="бизнес-метрики">Бизнес-метрики</h4>
<ul>
<li>Это метрики, которые могут быть важны для роста бизнеса и его
продуктов.
<ul>
<li>С ними работают руководители бизнес-направлений, проектные и
продуктовые менеджеры.</li>
</ul></li>
<li>Выручка — Revenue. Поток денег, который получает компания ещё до
налогообложения и издержек.</li>
<li>Прибыль — Profit. Деньги, которые остаются из выручки после всех
издержек. Их можно инвестировать в бизнес или выплачивать акционерам.
<ul>
<li>Прибыль делится на чистую и валовую — Net Profit и Gross
Profit.</li>
</ul></li>
</ul>
<h4 id="метрики-продукта-1">Метрики продукта</h4>
<ul>
<li><p>Позволяют оценивать продукт в ходе его жизненного цикла, могут
косвенно или прямо влиять на метрики других категорий</p></li>
<li><p>Метрики активности пользователей — User Activity.</p>
<ul>
<li>Показывают, насколько активно пользователь работает в
приложении.</li>
<li>считают дневную, недельную и месячную активность — DAU, или Daily
Activity Users, WAU, или Weekly Activity Users, и MAU, или Mouthly
Activity Users</li>
</ul></li>
<li><p>Метрики выручки на пользователя.</p>
<ul>
<li>Позволяют выявить траты пользователей и впоследствии управлять
экономикой продукта</li>
<li>ARPU, или Average Revenue per User,</li>
</ul></li>
</ul>
<h2
id="управление-требованиями-и-определение-бизнес-процессов-1">Управление
требованиями и определение бизнес-процессов</h2>
<ul>
<li><blockquote>
<p>При реализации проектов в компании всегда есть люди, которые
заинтересованы в изменениях и могут повлиять на ход работы, — таких
людей называют стейкхолдерами.</p>
</blockquote></li>
<li><blockquote>
<p>Стейкхолдеры могут участвовать в бюджетировании, определять
требования и принимать результаты.</p>
</blockquote></li>
<li><p>Внутренние стейкхолдеры — это сотрудники компании,
заинтересованные в проекте</p></li>
<li><p>Внешние стейкхолдеры — государственные органы и другие участники
рынка, которые проявляют интерес к проекту</p></li>
<li><p>Процесс работы со стейкхолдерами</p>
<ul>
<li>Чтобы организовать управление стейкхолдерами, нужно:
<ul>
<li>Выявить стейкхолдеров и определить их требования.
<ul>
<li>Можно начать с заказчиков или руководителей смежных
подразделений.</li>
</ul></li>
<li>Определить степень вовлечённости стейкхолдеров в проект и их
влияние. <img src="images/img_95.png" alt="img_95.png" /></li>
</ul></li>
</ul></li>
<li><p>Матрица стейкхолдеров</p>
<ul>
<li><figure>
<img src="images/img_174.png" alt="img_174.png" />
<figcaption aria-hidden="true">img_174.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="как-описывать-требования-1">Как описывать требования</h3>
<ul>
<li><p>Функциональные требования описывают то, что система должна
делать, то есть конкретные функции.</p>
<ul>
<li>пример, платформа должна отправлять уведомления пользователям о
статусе их подписки — сообщения об оформлении, условиях и
отключении.</li>
</ul></li>
<li><p>Нефункциональные требования описывают то, как система будет
реализовывать функции при работе.</p>
<ul>
<li>Их ещё называют атрибутами качества.</li>
<li>Это могут быть требования, которые влияют на производительность,
надёжность, удобство использования системы.
<ul>
<li>пример, платформа должна обрабатывать не менее 500 запросов в
секунду при пиковых нагрузках.</li>
</ul></li>
</ul></li>
<li><p>Модель описания требований FURPS+</p>
<ul>
<li>Функциональные и нефункциональные требования удобно описывать по
модели FURPS+</li>
<li><figure>
<img src="images/img_96.png" alt="img_96.png" />
<figcaption aria-hidden="true">img_96.png</figcaption>
</figure></li>
</ul></li>
<li><p>Функциональные (Functionality, F) — то, что система должна
выполнять на релизе.</p></li>
<li><p>Удобство использования (Usability, U) — правила, по которым
система взаимодействует с пользователем.</p>
<ul>
<li>Это могут быть UX/UI-дизайн, правила работы интерфейса для людей с
ограниченными возможностями</li>
</ul></li>
<li><p>Надёжность (Reliability, R) — всё, что относится к
работоспособности системы: время простоя в случае сбоя, режим работы,
график обслуживания.</p>
<ul>
<li>Обычно невозможно сделать систему устойчивой в любой ситуации,
поэтому сразу важно заложить ограничения.</li>
</ul></li>
<li><p>Производительность (Performance, P) — всё, что относится к
быстродействию и потреблению ресурсов:</p>
<ul>
<li>время отклика, масштабирование системы, число одновременных
пользователей.</li>
</ul></li>
<li><p>Поддерживаемость (Supportability, S) — возможность и правила
тестирования, параметры расширения и доработки системы.</p></li>
<li><p>Ограничения (остальное со знаком +) — это дополнительные
ограничения, которые мы накладываем на систему:</p>
<ul>
<li>языки программирования, правила проектирования, применение
определённых баз данных.</li>
<li>Эту группу можно отнести к архитектурно значимым требованиям</li>
</ul></li>
<li><p>На раннем этапе можно ограничиться категориями F, R и P+</p></li>
</ul>
<h4 id="архитектурно-значимые-требования-1">Архитектурно значимые
требования</h4>
<ul>
<li><p>Архитектурно значимые требования</p></li>
<li><p>это требования, которые оказывают влияние на архитектуру
системы.</p></li>
<li><p>Это могут быть требования как к программному обеспечению, так и к
оборудованию</p></li>
<li><p>Чаще всего в эту группу попадают нефункциональные
требования.</p></li>
<li><p>модели FURPS+ за архитектурно значимые требования отвечает
последний раздел +</p>
<ul>
<li>ограничения (Restrictions).</li>
<li>Обычно выделяют четыре группы ограничений:
<ul>
<li>Ограничения проектирования: средства разработки, технологии.</li>
<li>Ограничения реализации: стандарты разработки кода или требования к
архитектуре.</li>
<li>Требования к интерфейсам: форматы взаимодействия компонентов,
протоколы или способы взаимодействия, например, синхронные или
асинхронные.</li>
<li>Физические ограничения: они накладываются на аппаратные средства и
окружение системы, например, температура, влажность, условия
эксплуатации оборудования.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="пример-описания-требований-по-furps-1">Пример описания
требований по FURPS+</h4>
<ul>
<li>Рассмотрим модель FURPS+ для стриминг-платформы компании N.
<ul>
<li>Оргструктура платформы:</li>
<li>Управление развития:</li>
<li>Отдел продуктового развития и сопровождения.</li>
<li>Отдел технологического развития и сопровождения платформы.</li>
<li>Отдел маркетинга и цифровых продаж.</li>
<li>Отдел закупок.</li>
<li>Отдел технологического подбора.</li>
</ul></li>
<li>пример перечень требований по модели FURPS+:</li>
<li><figure>
<img src="images/img_97.png" alt="img_97.png" />
<figcaption aria-hidden="true">img_97.png</figcaption>
</figure></li>
<li><figure>
<img src="images/img_98.png" alt="img_98.png" />
<figcaption aria-hidden="true">img_98.png</figcaption>
</figure></li>
</ul>
<h4 id="пользовательские-сценарии-1">Пользовательские сценарии</h4>
<ul>
<li><p>Кроме требований, важно определить, с помощью каких действий
пользователя они будут реализованы и к каким результатам в системе или
смежных системах приведут</p></li>
<li><p>Use Cases, или пользовательские сценарии, описывают, какие
действия совершает пользователь и как система на них реагирует.</p>
<ul>
<li>Иначе говоря, это варианты использования.</li>
<li>Например, пользователь вводит номер телефона в форму авторизации —
это очень простой Use Case, состоящий из одного шага.</li>
</ul></li>
<li><p>В Agile-подходах к разработке часто используется инструмент User
Story</p>
<ul>
<li>формируется список задач, внутри которых рассматриваются отдельные
пользовательские сценарии</li>
</ul></li>
<li><p>Сценарии можно описывать от общего к частному, то есть
определять, какие есть Use Cases, как они связаны, и потом
детализировать описание каждого из них <img src="images/img_99.png"
alt="img_99.png" /></p></li>
<li><p>Каждый сценарий можно детализировать: <img
src="images/img_100.png" alt="img_100.png" /></p></li>
<li><p>можно добавить описание</p>
<ul>
<li><figure>
<img src="images/img_101.png" alt="img_101.png" />
<figcaption aria-hidden="true">img_101.png</figcaption>
</figure></li>
</ul></li>
<li><p>если мы получили функциональные требования <img
src="images/img_102.png" alt="img_102.png" /></p></li>
</ul>
<h4 id="потоки-вариантов-использования-1">Потоки вариантов
использования</h4>
<ul>
<li>Последовательность выполнения пользовательского сценария называют
потоком варианта использования (Use Case Flow)
<ul>
<li>основный поток (Basic Flow) - Основная последовательность, которая
приводит к целевому результату</li>
<li>альтернативный поток (Alternative Flow) - различные ветвления</li>
<li><figure>
<img src="images/img_103.png" alt="img_103.png" />
<figcaption aria-hidden="true">img_103.png</figcaption>
</figure>
<ul>
<li>пример, открыл фильм, но нет подписки, отрабатывает альтернативный
подход</li>
</ul></li>
</ul></li>
</ul>
<h3 id="описание-бизнес-процессов-1">Описание бизнес-процессов</h3>
<ul>
<li><p>Для описания процессов может использоваться нотация EPC. <img
src="images/img_115.png" alt="img_115.png" /></p></li>
<li><p>Для удобного описания таких взаимодействий существует нотация
BPMN</p>
<ul>
<li>она позволяет детально описывать процессы со всеми
взаимодействиями,</li>
<li>потому что они выделяются на отдельные «дорожки» (swimline).</li>
<li><figure>
<img src="images/img_105.png" alt="img_105.png" />
<figcaption aria-hidden="true">img_105.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h2
id="проектирование-архитектуры-и-управление-изменениями-1">Проектирование
архитектуры и управление изменениями</h2>
<ul>
<li>Принятые решения полезно оформить в некоторый документ
<ul>
<li>(например, в формате Architecture design record или Architecture
vision),
<ul>
<li>который служит для обсуждения процессов разработки с другими
участниками</li>
<li>На него ссылаются в спорных ситуациях,</li>
<li>он помогает оставаться в фокусе изначальной идеи при дальнейшем
развитии продукта,</li>
<li>и по нему легко отслеживать задачи.</li>
</ul></li>
</ul></li>
<li>Под архитектурой решения (solution architecture)
<ul>
<li>понимается результат планирования структуры и взаимодействия
компонентов программного обеспечения для достижения целей и соответствия
требованиям.</li>
<li>Это решение можно оформить в концептуальный документ с описанием,
схемами, допущениями и ограничениями, чтобы далее определить конкретный
план изменений.</li>
<li>Такой концепт часто называют архитектурным видением (architecture
vision).</li>
</ul></li>
</ul>
<h3
id="architecture-design-record-и-architecture-decision-log-1">Architecture
Design Record и Architecture Decision Log</h3>
<ul>
<li>Architecture decision record (ADR) — это явное описание принятых и
непринятых в ходе разработки ПО решений,
<ul>
<li>которые затрагивают архитектуру, выбранные технологии и отвечают
определённым функциональным или нефункциональным требованиям</li>
</ul></li>
<li>Каждая запись ADR фиксируется в журнале Architecture decision log
(ADL).
<ul>
<li>Ведение ADL позволяет отслеживать значимые архитектурные изменения
внутри проекта или продукта, их историю и накапливать знания для всех
участников</li>
</ul></li>
<li>ADR можно вести в системе контроля версий вроде git.
<ul>
<li>Можно использовать собственный репозиторий, а для работы со схемами
в формате текста — инструменты вроде C4-PlantUML.
<ul>
<li>PlantUML позволяет вести UML документацию как код.</li>
<li>А C4 расширяет этот инструмент нотацией C4.</li>
<li>Кроме того, есть специальный язык разметки ADR — MADR (Markdown
Architectural Decision Records)</li>
</ul></li>
</ul></li>
</ul>
<h4 id="формат-и-шаблоны-adr-1">Формат и шаблоны ADR</h4>
<ul>
<li>ADR может содержать достаточно простые решения
<ul>
<li>например, использовать только REST-формат взаимодействия</li>
<li>например, описание архитектуры работы с платёжной системой в
процессе оформления заказа.</li>
<li>могут быть включены схемы, таблицы и другое.</li>
</ul></li>
<li>состав ADR, каждая команда может определить самостоятельно, но есть
минимально необходимые элементы:
<ul>
<li>Контекст — то, при каких условиях принимается решение;</li>
<li>Решение — в чём суть принятого решения;</li>
<li>Последствия — к чему приведёт решение.</li>
</ul></li>
<li>ADR стоит вести в составе реестра, важно, чтобы в каждом был номер,
дата и автор.
<ul>
<li>Одним из популярных шаблонов является Y-statement. Он состоит из
следующих элементов:
<ul>
<li>Контекст (context) — на что решение влияет и в каких условиях
принято. Это могут требования или условия работы конкретного
компонента.</li>
<li>Причина (facing) — проблема, которую нужно решить, или определённые
нефункциональные требования.</li>
<li>Принято (we decided for) — принятое решение, аргументация и
причины.</li>
<li>Отклонено (neglected) — альтернативы, которые рассмотрели, но не
стали выбирать.</li>
<li>Чтобы достичь (to achieve) — преимущества решения и ожидаемый
результат.</li>
<li>Нужно учесть (accepting that) — недостатки или то, как решение
повлияет на другие элементы. <img src="images/img_106.png"
alt="img_106.png" /></li>
</ul></li>
</ul></li>
<li>пример,
<ul>
<li>Контекст.
<ul>
<li>Для взаимодействия сервисов в проекте необходимо выбрать протокол,
формат передачи данных и правила описания контрактов API.</li>
</ul></li>
<li>Причина.
<ul>
<li>Если не договориться о протоколе, то процесс разработки может
замедлиться и могут возникнуть проблемы с тестированием. Всё это потому,
что будут постоянно возникать споры о том, как должно быть сделано API
сервиса.</li>
</ul></li>
<li>Принято.
<ul>
<li>Используем формат HTTP/REST второго уровня зрелости со спецификацией
по Open API и методы GET, POST, PUT и DELETE.</li>
</ul></li>
<li>Альтернативы (отклонено)
<ul>
<li>Рассмотрели вариант использования gRPC: модель имеет свои
преимущества, но так как у команды нет практики применения, а сроки
проекта сжатые, то её использовать не будем.</li>
</ul></li>
<li>Чтобы достичь
<ul>
<li>того, чтобы у каждого разработчика было понимание, как должно быть
разработано API. При тестировании и интеграции можно будет использовать
готовый интерфейс Open API.</li>
</ul></li>
<li>Нужно учесть
<ul>
<li>Нужно подготовить примеры описания API, которые мы считаем
эталонным, отдельно принять ADR по работе с кодами ответов.</li>
</ul></li>
</ul></li>
<li>еще пример, более специфичный
<ul>
<li>шаблон наиболее нагляден для описания архитектуры сложного решения
со схемами и различными требованиями.</li>
<li>Название задачи:
<ul>
<li>Номер и название задачи.</li>
</ul></li>
<li>Автор:
<ul>
<li>Кто принял решение.</li>
</ul></li>
<li>Дата:
<ul>
<li>Она будет полезна для последующих обсуждений.</li>
</ul></li>
<li>Функциональные
<ul>
<li>требования: По сути, это контекст принятия решения, соответствует
разделу «контекст» в Y-statement. Здесь можно привести описание FURPS+
требований или таблицы use cases.</li>
</ul></li>
<li>Нефункциональные
<ul>
<li>требования: Описание нефункциональных требований и архитектурно
значимых требований — соответствует разделу «причина» в
Y-statement.</li>
</ul></li>
<li>Решение:
<ul>
<li>Принятое решение, его описание, аргументация и последствия, а также
схемы взаимодействия компонентов (например, в формате C4). Cоответствует
разделам «принято», «чтобы достичь» в Y-statement.</li>
</ul></li>
<li>Альтернативы:
<ul>
<li>Описание наиболее важных альтернативных решений, которые не были
приняты, — соответствует разделу «отклонено» в Y-statement.</li>
</ul></li>
<li>Недостатки,
<ul>
<li>ограничения, риски: Описание недостатков, ограничений и рисков
выбранного решения — соответствует разделу «нужно учесть» в
Y-statement.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="создание-adr-на-примере-1">Создание ADR на примере</h4>
<ul>
<li>пример требований</li>
<li><figure>
<img src="images/img_107.png" alt="img_107.png" />
<figcaption aria-hidden="true">img_107.png</figcaption>
</figure></li>
<li><figure>
<img src="images/img_108.png" alt="img_108.png" />
<figcaption aria-hidden="true">img_108.png</figcaption>
</figure></li>
<li>структура IT-ландшафта компании N с дополнительной информацией о
технологиях:
<ul>
<li>Развёрнутые технологии, сервисы и приложения</li>
<li>Система производства контента. В ней работают продюсеры, которые
отвечают за производство контента. Разрабатывают систему несколько
программистов из IT-отдела. Клиент-серверная система, клиентское
приложение под Windows разработано на QT (C++) и сервер на Java Spring.
В качестве СУБД используется Oracle. В ней ведётся библиотека контента
компании.</li>
<li>CRM-система на платформе Bitrix. Системой пользуются менеджеры по
продажам, работающие с каналами. Поддержка осуществляется внутри
IT-отдела.</li>
<li>Сайт. Собственная разработка на PHP. Поддерживается разработчиками
из IT-отдела.</li>
<li>1С: Зарплата и управление персоналом. В системе работают HR-отдел и
бухгалтерия, поддерживается разработчиком внутри IT-отдела.</li>
<li>1С: Бухгалтерия. Используют бухгалтеры, поддерживается разработчиком
внутри IT-отдела.</li>
</ul></li>
<li>описание ADR
<ul>
<li>Название задачи: MP-ADR1 MVP Медиаплатформы N</li>
<li>Автор: —</li>
<li>Дата: 12.10.2024</li>
<li>Функциональные требования:
<ul>
<li><figure>
<img src="images/img_109.png" alt="img_109.png" />
<figcaption aria-hidden="true">img_109.png</figcaption>
</figure></li>
</ul></li>
<li>нефункциональные требования
<ul>
<li><figure>
<img src="images/img_110.png" alt="img_110.png" />
<figcaption aria-hidden="true">img_110.png</figcaption>
</figure></li>
</ul></li>
<li>построим схему взаимодействия компонентов решения, исходя из
определённых Use Cases и с учётом нефункциональных требований
<ul>
<li>Диаграмма C4 первого уровня уже позволяет определить, что
функциональные требования удовлетворяются
<ul>
<li><figure>
<img src="images/img_111.png" alt="img_111.png" />
<figcaption aria-hidden="true">img_111.png</figcaption>
</figure></li>
</ul></li>
<li>построить схему второго уровня
<ul>
<li>Детализируем контейнеры медиаплатформы, учитывая нефункциональные
требования
<ul>
<li><ol type="a">
<li>Требование +R1.</li>
</ol></li>
<li><ol start="2" type="a">
<li>Требование +R2</li>
</ol></li>
</ul></li>
<li>Детализируем контейнеры системы производства контента, учитывая
нефункциональные требования.
<ul>
<li><ol type="a">
<li>Требование +R4.</li>
</ol></li>
</ul></li>
<li><figure>
<img src="images/img_112.png" alt="img_112.png" />
<figcaption aria-hidden="true">img_112.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li>альтернативные решения
<ul>
<li>Альтернативы
<ul>
<li>Масштабировать базу данных системы производства контента и не
разрабатывать отдельный микросервис.</li>
</ul></li>
<li>Недостатки, ограничения, риски
<ul>
<li>Медиаплатформа имеет большую монолитную часть, в будущем это может
создать риски масштабирования функционала и усложнить разработку.</li>
<li>Большую часть платформы надо разрабатывать на целевом стеке Java —
могут быть проблемы с загрузкой команды, можно было бы больше функций
выделить в микросервисы на PHP.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="дизайн-мышление-1">Дизайн-мышление</h3>
<ul>
<li>Дизайн-мышление
<ul>
<li>это нелинейная методология создания решений, в основе которой лежит
необходимость осознать проблему клиента и предложить, возможно
нестандартное, решение.</li>
<li>Так создаются удобные и адаптивные системы, эффективно решающие
задачи благодаря ориентации на реальный пользовательский опыт.</li>
</ul></li>
<li>подходы
<ul>
<li>эмпатия - встать на место клиента, определить источник проблемы</li>
<li>анализ и синтез - систематизация информации, убираем все лишнее</li>
<li>Генерация идей</li>
<li>Прототипирование - любый способы</li>
<li>Тестирование</li>
<li>Сторителлинг
<ul>
<li>обобщение информации об итоговом решении и сформировать итоговую
историю, чтобы точно убедиться, что проблема будет решена</li>
</ul></li>
</ul></li>
</ul>
<h3 id="планирование-реализации-1">Планирование реализации</h3>
<ul>
<li><p>архитектура определена!!</p></li>
<li><p>План работ и роадмап реализации</p>
<ul>
<li>интересует набор достаточно крупных задач в рамках системы, а также
задач, которые касаются взаимодействия разных систем</li>
<li>В различных Agile-подходах такие крупные задачи часто называют
<strong>эпиками</strong>,</li>
<li>которые уже делятся на задачи поменьше</li>
<li>задачи на основе архитектурного решения и диаграммы C4 второго
уровня
<ul>
<li><figure>
<img src="images/img_113.png" alt="img_113.png" />
<figcaption aria-hidden="true">img_113.png</figcaption>
</figure></li>
</ul></li>
<li>роадмап реализации на горизонте 6 месяцев
<ul>
<li><figure>
<img src="images/img_175.png" alt="img_175.png" />
<figcaption aria-hidden="true">img_175.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li><p>Управление изменениями</p>
<ul>
<li>то процесс планирования, внедрения и контроля изменений
проекта.</li>
<li>Для этого нужно минимизировать негативные последствия и достичь
поставленных целей.</li>
<li>Методов работы с изменениями:
<ul>
<li>Предиктивный — мы заранее держим в голове риск того, что случится
какое-то изменение, и имеем план на этот счёт
<ul>
<li>решили использовать платежную систему №1, но понимаем если она
отвалится будем использовать систему №2</li>
</ul></li>
<li>Реактивный — мгновенная реакция на случившееся изменение
<ul>
<li>снизить риски уже не получится</li>
<li>если платёжный шлюз не сможет принимать платежи, отправлять клиентам
счета на оплату по email вручную.</li>
</ul></li>
<li>Последовательный
<ul>
<li>это систематический подход к работе с изменениями, он состоит из
нескольких этапов и как раз заключается в построении модели
управления.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="введение-в-масштабирование-1">Введение в масштабирование</h2>
<ul>
<li>Вертикальное масштабирование - добавление ресурсов к одному
узлу</li>
<li>Горизонтальное масштабирование - добавление новых узлов в систему
<ul>
<li>что позволяет распределить нагрузку между ними</li>
<li>обеспечивает практически неограниченный рост и лучшую
отказоустойчивость</li>
</ul></li>
<li>Для реализации стратегию масштабирования необходимо понимать профиль
нагрузки
<ul>
<li>насколько, когда и как долго происходит недостаток ресурсов.
<ul>
<li>Статический
<ul>
<li>Каждую ночь в 00:00 количество активных пользователей составляет
менее 100, а загрузка ЦП на серверах приложений снижается на 90% на всех
узлах</li>
</ul></li>
<li>динамический, регулярный и предсказуемый
<ul>
<li>каждый ПН сотрудники входят в 1С</li>
</ul></li>
<li>Динамический, нерегулярный и предсказуемый
<ul>
<li>первый день месяца, и есть исторические данные о том, как
увеличивается трафик в таких ситуациях</li>
</ul></li>
<li>Динамический, нерегулярный и непредсказуемый
<ul>
<li>Крупномасштабное событие вызывает всплеск спроса на продукт.
Например, распродажа остатков.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="репликация-1">Репликация</h3>
<ul>
<li>Репликация — это процесс копирования и распространения данных между
различными базами данных</li>
<li>для обеспечения их согласованности и доступности.</li>
<li>создание и поддержание копий базы данных на нескольких серверах.
<ul>
<li><figure>
<img src="images/img_116.png" alt="img_116.png" />
<figcaption aria-hidden="true">img_116.png</figcaption>
</figure></li>
</ul></li>
<li>Шардирование - метод разделения на отдельные фрагменты (шарды), два
вида вертикальное и горизонтальное
<ul>
<li>данные можно разбить на шарды по регионам или типам данных и каждый
шард может иметь несколько реплик</li>
</ul></li>
<li>кеширование используется при запросах одних и тех же данных
<ul>
<li>данные о самых популярных товарах</li>
</ul></li>
<li>Географически распределённые ресурсы</li>
<li>Автоматическое масштабирование (англ. Auto-Scaling)
<ul>
<li>В облачных сервисах базы данных могут автоматически масштабироваться
в ответ на изменения нагрузки</li>
</ul></li>
<li>Использование специализированных баз данных для разных типов данных
<ul>
<li>реляционные базы данных для транзакционных данных</li>
<li>NoSQL для больших объёмов неструктурированных данных.</li>
</ul></li>
</ul>
<h4 id="репликация-master-slave-1">Репликация master-slave</h4>
<ul>
<li>В модели master-slave есть:
<ul>
<li>Главный, первичный узел (master), ответственный за обработку всех
операций записи и управление данными.</li>
<li>подчинённый, вторичный узел, или реплика, слейв (англ. slave)
<ul>
<li>узлов может быть несколько</li>
<li>пассивно реплицируют данные от главного узла и обслуживают запросы
на чтение (при паттерне read-replica)</li>
</ul></li>
<li>в master-slave в момент операции записи регистрируется изменения в
журнале транзакций
<ul>
<li>ведомые узлы извлекают эти журналы и применяют изменения
<ul>
<li>могут приостановить работу до получения обновления</li>
<li>одновременно вносить изменения</li>
</ul></li>
</ul></li>
<li>в случае потери ведущего, в зависимости от настроек становиться один
из ведомых</li>
</ul></li>
</ul>
<h4 id="паттерн-read-replica-1">Паттерн read-replica</h4>
<ul>
<li><p>в случае большой нагрузки чтение только с реплик, запись в
ведущий</p></li>
<li><p>проблемы</p>
<ul>
<li>задержка репликации
<ul>
<li>необходима последовательность чтение после записи</li>
<li>проверка совпадения реплики с основной БД</li>
</ul></li>
</ul></li>
</ul>
<h4 id="репликация-multi-master-1">Репликация multi-master</h4>
<ul>
<li>Multi-master, мульти — это тип репликации данных, при котором
несколько узлов выполняют роль главных
<ul>
<li>Данные синхронизируются между узлами, а запись может происходить на
любом из мастер-узлов</li>
<li>Система решает проблему конфликтов между одновременными
изменениями.</li>
</ul></li>
<li>преимущества
<ul>
<li>В случае сбоя одного главного узла другой главный узел может
обновить и вставить данные.</li>
<li>Главные узлы находятся в разных местах, поэтому вероятность сбоя
всех главных узлов крайне мала.</li>
<li>Обновления данных возможны на нескольких серверах.</li>
<li>Приложению не нужно направлять трафик только на один главный
узел.</li>
</ul></li>
<li>недостатки
<ul>
<li>Сложность настройки и поддержки.</li>
<li>Потенциальные задержки в данных.</li>
</ul></li>
<li>пример, в ЦОД поддержка горячей резервной копии всех сервисов в
другом ЦОД
<ul>
<li>при этом в самом ЦОД репликация master-slave</li>
<li><figure>
<img src="images/img_118.png" alt="img_118.png" />
<figcaption aria-hidden="true">img_118.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h4 id="преимущества-и-недостатки-репликации-1">Преимущества и
недостатки репликации</h4>
<ul>
<li>Преимущества
<ul>
<li>Высокая доступность данных (дублирование данных)</li>
<li>Высокая производительность системы</li>
<li>Отказоустойчивость (reliability)</li>
<li>Гибкость в распределении нагрузки</li>
</ul></li>
<li>Ограничения
<ul>
<li>Сложности с консистентностью данных (задержки)</li>
<li>Ресурсозатратность</li>
<li>Сложность управления (мониторинг, синхронизация)</li>
</ul></li>
</ul>
<h4 id="целесообразность-репликации-1">Целесообразность репликации</h4>
<ul>
<li>для оценки целесообразности репликации нужно проанализировать
требования:
<ul>
<li>доступность
<ul>
<li>высокая доступность данных и минимизация простое</li>
</ul></li>
<li>нагрузка на чтение
<ul>
<li>распределение запросов на чтение между несколькими серверами</li>
</ul></li>
<li>географическому распределению пользователей
<ul>
<li>направлять запросы на ближайшие реплики</li>
</ul></li>
<li>Критичность данных
<ul>
<li>если потеря данных недопустима, защита за счет дублирования данных
на нескольких серверах</li>
</ul></li>
</ul></li>
</ul>
<h3 id="репликация-на-mongodb-1">Репликация на MongoDb</h3>
<ul>
<li>MongoDB поддерживает два типа репликации
<ul>
<li>Replicaset
<ul>
<li>подобен multi-master, но затраты на поддержание на СУБД</li>
<li>каждый узел read/write</li>
</ul></li>
<li>master-slave
<ul>
<li>редко используемый</li>
</ul></li>
</ul></li>
<li>как работает репликация в MongoDB
<ul>
<li>запись и чтение с основного
<ul>
<li>его называют <strong>primary node</strong></li>
</ul></li>
<li>чтение с реплик
<ul>
<li><strong>secondary node</strong></li>
</ul></li>
</ul></li>
<li>2х факторная протокол фиксации
<ul>
<li>первичный сервер отправляет о Предстоящей записи всем вторичным
<ul>
<li>после подтверждения готовности выполняет операцию и рассылает
сообщение о Фиксации</li>
<li>если какой-нибудь вторичный отклоняет сообщение о Фиксации, операция
откатывается</li>
</ul></li>
<li>используется heartbeat для отслеживания состояния сервера</li>
</ul></li>
</ul>
<h4 id="настройка-репликации-mongodb-в-docker-1">Настройка репликации
MongoDB в Docker</h4>
<ul>
<li>используется Primary-Secondary</li>
<li>docker-compose.yaml</li>
</ul>
<pre><code>
version: &#39;3&#39;
services:
  mongodb1:
    image: mongo:latest # docker образ
    container_name: mongodb1
    restart: always
    ports:
      - &quot;27017:27017&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.10
    volumes:
      - mongodb1-data:/data/db
    command:
      [
        &quot;--replSet&quot;,
        &quot;rs0&quot;,
        &quot;--bind_ip_all&quot;,
        &quot;--port&quot;,
        &quot;27017&quot;
      ] #команда для создания реплики
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s

  mongodb2:
    image: mongo:latest
    container_name: mongodb2
    restart: always
    ports:
      - &quot;27018:27018&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.9
    volumes:
      - mongodb2-data:/data/db
    command:
      [
        &quot;--replSet&quot;,
        &quot;rs0&quot;,
        &quot;--bind_ip_all&quot;,
        &quot;--port&quot;,
        &quot;27018&quot;
      ]
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s

  mongodb3:
    image: mongo:latest
    container_name: mongodb3
    restart: always
    ports:
      - &quot;27019:27019&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.8
    volumes:
      - mongodb3-data:/data/db
    command:
      [
        &quot;--replSet&quot;,
        &quot;rs0&quot;,
        &quot;--bind_ip_all&quot;,
        &quot;--port&quot;,
        &quot;27019&quot;
      ]
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s

networks:
  app-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 173.17.0.0/16

volumes:
  mongodb1-data:
  mongodb2-data:
  mongodb3-data:

</code></pre>
<ul>
<li>запуск
<ul>
<li>docker-compose up -d</li>
</ul></li>
<li>подключиться к любому из контейнеров
<ul>
<li>docker exec -it mongodb1 mongosh</li>
</ul></li>
<li>создать набор реплик в командной оболочке mongosh</li>
</ul>
<pre><code>
rs.initiate({_id: &quot;rs0&quot;, members: [
{_id: 0, host: &quot;mongodb1:27017&quot;},
{_id: 1, host: &quot;mongodb2:27018&quot;},
{_id: 2, host: &quot;mongodb3:27019&quot;}
]}) 

</code></pre>
<h3 id="кеширование-1">Кеширование</h3>
<ul>
<li><figure>
<img src="images/img_119.png" alt="img_119.png" />
<figcaption aria-hidden="true">img_119.png</figcaption>
</figure></li>
<li>проблема при постоянном изменении информации, преимущество кеша
будет “съедено”
<ul>
<li>Кешом надо управлять</li>
</ul></li>
</ul>
<h3 id="redis-cluster-для-кеширования-данных-1">Redis Cluster для
кеширования данных</h3>
<ul>
<li><p>Redis позволяет реплицировать и шардировать данные - разбивать на
сегменты</p></li>
<li><p>Распределённый кеш</p>
<ul>
<li>это система, в которой данные хранятся на нескольких узлах
кластера</li>
<li>и в нескольких кластерах в разных центрах обработки данных по всему
миру.</li>
</ul></li>
<li><p>Система распределённого кеша объединяет оперативную память
нескольких сетевых компьютеров в единое хранилище</p>
<ul>
<li>данных в оперативной памяти, которое используется в качестве кеша
для быстрого доступа к данным.</li>
<li>Эти системы позволяют постепенно расширять и масштабировать систему,
добавляя новые компьютеры в кластер</li>
</ul></li>
</ul>
<h4 id="настройка-redis-cluster-1">Настройка Redis Cluster</h4>
<ul>
<li>docker-compose.yaml</li>
</ul>
<pre><code>
 redis_1:
    image: &quot;redis:latest&quot;
    container_name: redis_1
    ports:
      - &quot;6379&quot;
    volumes:
      - redis_1_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ]
    networks:
      app-network:
        ipv4_address: 173.17.0.2

  redis_2:
    image: &quot;redis:latest&quot;
    container_name: redis_2
    ports:
      - &quot;6379&quot;
    volumes:
      - redis_2_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ]
    networks:
      app-network:
        ipv4_address: 173.17.0.3

  redis_3:
    image: &quot;redis:latest&quot;
    container_name: redis_3
    ports:
      - &quot;6379&quot;
    volumes:
      - redis_3_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ]
    networks:
      app-network:
        ipv4_address: 173.17.0.4

  redis_4:
    image: &quot;redis:latest&quot;
    container_name: redis_4
    ports:
      - &quot;6379&quot;
    volumes:
      - redis_4_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ]
    networks:
      app-network:
        ipv4_address: 173.17.0.5

  redis_5:
    image: &quot;redis:latest&quot;
    container_name: redis_5
    ports:
      - &quot;6379&quot;
    volumes:
      - redis_5_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ]
    networks:
      app-network:
        ipv4_address: 173.17.0.6

  redis_6:
    image: &quot;redis:latest&quot;
    container_name: redis_6
    ports:
      - &quot;6379&quot;
    volumes:
      - redis_6_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ]
    networks:
      app-network:
        ipv4_address: 173.17.0.7

volumes:
  redis_1_data: {}
  redis_2_data: {}
  redis_3_data: {}
  redis_4_data: {}
  redis_5_data: {}
  redis_6_data: {}

</code></pre>
<ul>
<li>создать файл ./redis/redis.conf рядом с docker-compose.yaml</li>
</ul>
<pre><code>
port 6379
cluster-enabled yes #активация кластерного режима
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes

</code></pre>
<ul>
<li>запуск Redis
<ul>
<li>docker-compose up -d</li>
</ul></li>
<li>создание кластер Redis
<ul>
<li>docker exec -it redis_1 bash (или docker exec -it redis_1
redis-cli)</li>
<li>echo “yes” | redis-cli –cluster create 173.17.0.2:6379
173.17.0.3:6379 173.17.0.4:6379 173.17.0.5:6379 173.17.0.6:6379
173.17.0.7:6379 –cluster-replicas 1</li>
<li>получение информации о кластере
<ul>
<li>redis-cli cluster nodes</li>
</ul></li>
</ul></li>
<li>использование в nodejs</li>
</ul>
<pre><code>
&gt; mkdir nodejs-api
&gt; cd nodejs-api
&gt; npm init -y
&gt; npm install express mongoose redis
&gt; touch index.js

const express = require(&#39;express&#39;);
const redis = require(&#39;redis&#39;);
const app = express();
const PORT = 3000;

const client = redis.createClient();

// работа Redis - достаём данные, если они есть по ссылке /api/products
const cache = (req, res, next) =&gt; {
  const cacheKey = req.originalUrl;
  client.get(cacheKey, (err, data) =&gt; {
    if (err) throw err;
    if (data !== null) {
      res.json(JSON.parse(data));
    } else {
      next();
    }
  });
};

// сбрасываем кеш в случае обновления данных
const invalidateCache = (cacheKey) =&gt; {
  client.del(cacheKey, (err, response) =&gt; {
    if (err) throw err;
    console.log(`Cache key &quot;${cacheKey}&quot; invalidated`);
  });
};

app.get(&#39;/api/products&#39;, cache, (req, res) =&gt; {
  
  const products = //логика получения данных из MongoDB

  // Сохраняем данные по ключу /api/products на 1 минуту
  client.setex(req.originalUrl, 120, JSON.stringify(products));

  res.json(products);
});

// При обновлении данных - сбрасываем кеш
app.post(&#39;/api/products&#39;, (req, res) =&gt; {
  //обновляем данные в MongoDB
  
  invalidateCache(&#39;/api/products&#39;);

  res.json({ message: &#39;Product data updated successfully&#39; });
});

app.listen(PORT, () =&gt; {
  console.log(`Server is running on port ${PORT}`);
});


</code></pre>
<h4 id="механизм-работы-redis-1">Механизм работы Redis</h4>
<ul>
<li>кластер состоит из трёх сегментов
<ul>
<li>У каждого сегмента есть главный узел (master) - запись</li>
<li>узел-реплика (slave), который хранит копию данных</li>
<li>Сегмент кластера Redis может содержать до 500 реплик — так устроено
в AWS и зависит от провайдера.</li>
</ul></li>
</ul>
<p><img src="images/img_120.png" alt="img_120.png" /> - Клиенты
выполняют операции чтения и записи с узлами M1, M2, M3 и только чтения с
S1, S2, S3. - Между ведущими и подчинёнными узлами выполняется
репликация данных. - Для определения общего состояния кластера
используется протокол gossip.</p>
<h4 id="реализация-репликации-в-различных-бд-1">Реализация репликации в
различных БД</h4>
<ul>
<li><p>PostgreSQL использует потоковую или логическую репликации в
рамках механизмов master-slave и multi-master.</p></li>
<li><p>Потоковая репликация</p>
<ul>
<li>Процесс копирования данных с основного сервера PostgreSQL на
реплики.</li>
<li>При этом используется WAL (журнал предзаписи транзакций), который
позволяет восстановить данные в случае сбоя.</li>
<li>Потоковая может быть синхронной или асинхронной.</li>
<li>Для настройки потоковой репликации все серверы должны быть одной
версии, работать на одной операционной системе и архитектуре.</li>
</ul></li>
<li><p>Логическая репликация</p>
<ul>
<li>Возможность настройки логической репликации появилась в PostgreSQL
10.<br />
</li>
<li>Отличается от потоковой тем, что она оперирует записями в таблицах
PostgreSQL, а не физическим уровнем данных.<br />
</li>
<li>Этот вид репликации основан на механизме публикации/подписки: один
сервер публикует изменения,
<ul>
<li>а другой подписывается на них.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="шардирование-и-партиционирование-1">Шардирование и
партиционирование</h3>
<ul>
<li>Партиционирование, или секционирование, — метод разделения больших
объёмов данных на отдельные сегменты.
<ul>
<li>Иногда шардирование называют партиционированием в целом,</li>
<li>шардирование — это частный случай партиционирования</li>
</ul></li>
<li>Вертикальное партиционирование
<ul>
<li>метод разделения одной большой таблицы на несколько меньших, которые
физически хранятся отдельно.</li>
<li>позволяет повысить производительность и доступность данных,
поскольку операции выполняются над меньшим количеством данных.</li>
<li>пример, можно разделить таблицу с данными о покупателях и их
предпочтениях на две таблицы
<ul>
<li>и тогда при выполнении запросов будут загружаться только необходимые
столбцы.</li>
<li><figure>
<img src="images/img_121.png" alt="img_121.png" />
<figcaption aria-hidden="true">img_121.png</figcaption>
</figure></li>
</ul></li>
<li>пример полезного использования
<ul>
<li>В какой-то учётной системе с большим количеством данных есть таблица
«Х».
<ul>
<li>Она имеет 110 500 атрибутов, которые лежат в одной строке.</li>
<li>Как только разработчики замечают, что запросы стали выполняться в
разы медленнее, они начинают разделять эту таблицу на более мелкие.</li>
<li>Применяется вертикальное партиционирование.</li>
</ul></li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Вертикальное партиционирование делают в первую очередь при проблемах
с производительностью. Этот способ поможет оптимизировать запросы, но не
решит проблему с большим количеством данных.</p>
</blockquote></li>
<li><blockquote>
<p>Достаточно придумать, что «отрезать» от таблицы, и перенести это в
другую</p>
</blockquote></li>
<li>Горизонтальное партиционирование, шардирование, или сегментировани
<ul>
<li>распределение данных по нескольким базам, чаще всего на отдельных
физических серверах.
<ul>
<li>Шардирование предполагает разделение данных на группы по
определённым критериям</li>
<li>В результате разделения данных каждый сегмент (шард) включает одни и
те же столбцы, но разные строки информации.</li>
<li><figure>
<img src="images/img_122.png" alt="img_122.png" />
<figcaption aria-hidden="true">img_122.png</figcaption>
</figure></li>
</ul></li>
<li>пример полезного использования
<ul>
<li>Интернет-магазин, работающий по всей стране или даже в нескольких
странах, не может концентрировать все данные в одном месте.</li>
<li>Разработчики разносят данные по разным регионам. При этом остаётся
возможность запросить данные в одном месте, если это необходимо.</li>
<li>Это и есть горизонтальное партиционирование, или шардирование.</li>
</ul></li>
</ul></li>
<li>Преимущества Шардирования
<ul>
<li>Преодолеть технические ограничения
<ul>
<li>распределить данные по разным машинам</li>
</ul></li>
<li>Повысить надёжность
<ul>
<li>разные сервера, отказ одного из них не приведёт к полной остановке
работы.</li>
</ul></li>
<li>Ускорить доступ к данным с простыми запросами</li>
</ul></li>
<li>Ограничения Шардирования
<ul>
<li>Сложность реализации</li>
<li>Риск снижения эффективности разработки
<ul>
<li>необходимость управлять данными из нескольких сегментов вместо
единой точки входа эффективность может снизиться</li>
</ul></li>
<li>Неравномерность загрузки серверов</li>
<li>Снижение скорости обработки сложных запросов</li>
</ul></li>
</ul>
<h3 id="методы-шардирования-1">Методы шардирования</h3>
<ul>
<li>Хэшированное шардирование
<ul>
<li>разделение данных на шарды на основе хэш-функции
<ul>
<li>Хэш-функция принимает входные данные и возвращает хэш-значение,
которое определяет, в какой шард попадёт каждая запись данных.</li>
<li>Этот алгоритм нельзя запустить в обратную сторону и получить
исходное сообщение.</li>
<li>Применение алгоритма к одному и тому же значению всегда даёт
одинаковый результат.</li>
</ul></li>
<li>Особенности алгоритма:
<ul>
<li>высокая производительность;</li>
<li>отсутствие единой точки отказа;</li>
<li>равномерное распределение данных;</li>
<li>затруднённый поиск данных.</li>
</ul></li>
<li>пример, Магазин содержит базу данных пользователей.
<ul>
<li>Чтобы ослабить нагрузку на сервер, разработчики горизонтально делят
её по шардам, используя хэш-функцию для определения шарда.</li>
<li>В результате пользователи будут равномерно распределены по
серверам.</li>
</ul></li>
<li><blockquote>
<p>Применение алгоритма оптимально для приложений, в которых крайне
важно равномерно распределить данные.</p>
</blockquote></li>
</ul></li>
<li>Диапазонное шардирование
<ul>
<li>разделение данных на шарды на основе диапазона значений (chunk)
<ul>
<li>Значения разделяются не с помощью функции, а по ключу или другим
атрибутам
<ul>
<li>товары стоимостью до 50₽ идут в первый шард</li>
<li>от 50₽ до 100₽ — во второй, свыше 100₽ — в третий.</li>
</ul></li>
<li>Каждому фрагменту присваивается диапазон на основе значений ключа
сегментирования.</li>
<li>Ключи сегментов, чьи значения близки друг к другу, чаще всего
оказываются в одном диапазоне. Это упрощает выполнение целевых
операций.</li>
<li><figure>
<img src="images/img_123.png" alt="img_123.png" />
<figcaption aria-hidden="true">img_123.png</figcaption>
</figure></li>
</ul></li>
<li>Особенности алгоритма:
<ul>
<li>лёгкая реализуемость;</li>
<li>быстрый поиск информации по сравнению с хэшированием;</li>
<li>дисбаланс базы данных.</li>
</ul></li>
<li><blockquote>
<p>Подходит для данных временных рядов или последовательных данных,
таких как журналы, события с временными метками, цены на товары и т.
д.</p>
</blockquote></li>
</ul></li>
<li>Динамическое шардирование
<ul>
<li>автоматическое масштабирование хранилища в зависимости от текущей
производительности и объёма данных</li>
<li>очень гибкое, но требует сложной балансировки нагрузки, надёжного
мониторинга и тщательно продуманной архитектуры базы данных.</li>
<li>используют для определения местоположения записей внешний поисковый
сервис</li>
<li>Внешний поиск предоставляет полную информацию о том, в каком
сегменте находятся данные,
<ul>
<li>что позволяет перемещать пользователей по отдельности, а не большими
группами, из одного сегмента в другой.</li>
<li>Это помогает снизить нагрузку на перегруженные сегменты.</li>
<li>При этом поисковый сервис становится единственным местом
взаимодействия с системой и потенциальным источником сбоев.</li>
</ul></li>
</ul></li>
<li>Геошардинг
<ul>
<li>ранение в разных сегментах информации, относящейся к определённой
географической зоне</li>
</ul></li>
<li>таблица типов шардирования
<ul>
<li><figure>
<img src="images/img_124.png" alt="img_124.png" />
<figcaption aria-hidden="true">img_124.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="реализация-шардирования-1">Реализация шардирования</h3>
<ul>
<li>три способа реализации шардирования
<ul>
<li>средствами БД
<ul>
<li>MongoDB, Elasticsearch, ClickHouse и другие, могут автоматически
распределять данные между своими экземплярами.</li>
</ul></li>
<li>С использованием надстроек к базе данных
<ul>
<li>для PostgreSQL (Citus) есть риск потери данных</li>
</ul></li>
<li>С применением клиентских средств
<ul>
<li>экземпляры БД не знают о существовании друг друга, а шардированием
управляет ваш сервис.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="шардирование-в-redis-1">Шардирование в Redis</h4>
<ul>
<li>Redis использует шардирование по умолчанию для распределения данных,
специально ничего настраивать не придётся.
<ul>
<li>Всё пространство ключей в кластерах Redis разделено на 16384 слота
(называемых слотами хэша),
<ul>
<li>эти слоты назначены нескольким узлам Redis. Данный ключ
сопоставляется одному из этих слотов.</li>
</ul></li>
<li>Хэш-слот для ключа вычисляется как: HASH_SLOT = CRC16 (ключ) mod
16384</li>
</ul></li>
</ul>
<h4 id="шардирование-в-postgresql-практика-1">Шардирование в PostgreSQL:
практика</h4>
<ul>
<li>для шардирования используется сторонний инструмент Citus
<ul>
<li>sudo apt-get install postgresql-13-citus</li>
</ul></li>
<li>инициализировать Citus:
<ul>
<li>CREATE EXTENSION citus;</li>
</ul></li>
<li>Создать распределённую таблицу</li>
</ul>
<pre><code>
CREATE TABLE distributed_table (
 id SERIAL,
 data TEXT
);
SELECT create_distributed_table(&#39;distributed_table&#39;, &#39;id&#39;);

</code></pre>
<ul>
<li>Добавить рабочие узлы:</li>
</ul>
<pre><code>
SELECT citus_add_node(&#39;worker_node_address&#39;, 5432);

</code></pre>
<ul>
<li>Вставить данные в распределённую таблицу:</li>
</ul>
<pre><code>
INSERT INTO distributed_table (data) VALUES (&#39;example_data&#39;);

</code></pre>
<h4 id="шардирование-в-mongodb-1">Шардирование в MongoDB</h4>
<ul>
<li><p>поддерживает две стратегии сегментирования для распределения
данных по разделённым кластерам: диапазонному и хэшированному.</p></li>
<li><p>простой способ активировать шардирование — использовать
MongoAtlas или облачную инсталляцию</p></li>
<li><p>сложными вариантами будут использовать облако, а также настроить
шардирование в Docker или на ВМ.</p></li>
<li><p>Для запуска шардированного варианта MongoDB понадобится ещё два
сервиса — роутер и сервис конфигурации.</p></li>
<li><p>Для реализации high-avalability с шардированием
рекомендуется:</p>
<ul>
<li>Три инстанса роутера
<ul>
<li>Роутер определяет, на какой шард отправить запрос.</li>
</ul></li>
<li>Три инстанса с конфигурацией
<ul>
<li>Конфигурационный сервер хранит метаданные кластера, которые содержат
информацию о маппинге данных кластера на шарды.</li>
</ul></li>
<li>Три шарда и три реплики для каждого шарда
<ul>
<li>Шарды используются для хранения данных, каждый шард представляет
собой отдельную Replicaset.</li>
</ul></li>
<li><figure>
<img src="images/img_125.png" alt="img_125.png" />
<figcaption aria-hidden="true">img_125.png</figcaption>
</figure></li>
</ul></li>
<li><p>пример запуска MongoDB в режиме шардинга: 1 роутер, 1 сервер
конфигурации и 2 шарда</p></li>
<li><p>docker-compose.yaml</p></li>
</ul>
<pre><code>
version: &#39;3&#39;
services:

  //сервер конфигурации
  configSrv:
    image: mongo:latest # docker образ
    container_name: configSrv 
    restart: always
    ports:
      - &quot;27017:27017&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.10
    volumes:
      - config-data:/data/db
    command:
      [
        &quot;--configsvr&quot;,  //запуск в режиме конфигурации
        &quot;--replSet&quot;,
        &quot;config_server&quot;,
        &quot;--bind_ip_all&quot;,
        &quot;--port&quot;,
        &quot;27017&quot;
      ] 
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s

  //1-й шард 
  shard1:
    image: mongo:latest
    container_name: shard1
    restart: always
    ports:
      - &quot;27018:27018&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.9
    volumes:
      - shard1-data:/data/db
    command:
      [
        &quot;--shardsvr&quot;, //запуск в режиме шардинга
        &quot;--replSet&quot;,
        &quot;shard1&quot;, //название реплики
        &quot;--bind_ip_all&quot;,
        &quot;--port&quot;,
        &quot;27018&quot;
      ]
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s

  //2-й шард 
  shard2:
    image: mongo:latest
    container_name: shard2
    restart: always
    ports:
      - &quot;27019:27019&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.8
    volumes:
      - shard2-data:/data/db
    command:
      [
        &quot;--shardsvr&quot;, //запуск в режиме шардинга
        &quot;--replSet&quot;,
        &quot;shard2&quot;, //название реплик
        &quot;--bind_ip_all&quot;, // обратите внимание - она отличается от реплики 1-го шарда
        &quot;--port&quot;,
        &quot;27019&quot;
      ]
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s
  
  //роутер
  mongos_router:
    image: mongo:latest
    container_name: mongos_router
    restart: always
    ports:
      - &quot;27020:27020&quot;
    networks:
      app-network:
        ipv4_address: 173.17.0.7
    command:
      [
        &quot;mongos&quot;, //обычная mongo в режиме роутера
        **&quot;--configdb&quot;, 
        &quot;config_server/configSrv:27017&quot;,** //передача данных сервера конфигурации
        &quot;--bind_ip_all&quot;,
        &quot;--port&quot;,
        &quot;27020&quot;
      ]
    healthcheck:
      test: [ &quot;CMD&quot;, &quot;mongo&quot;, &quot;--eval&quot;, &quot;db.adminCommand(&#39;ping&#39;)&quot; ]
      interval: 5s
      start_period: 10s

networks:
  app-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 173.17.0.0/16

volumes:
  config-data:
  shard1-data:
  shard2-data:


</code></pre>
<ul>
<li>Фактически запустится четыре сервера MongoDB в различных режимах —
роутера, шардов, сервера конфигурации.
<ul>
<li>Запрос попадает сначала на роутер, где будет определён шард, на
котором хранится информация.</li>
</ul></li>
<li>запуск
<ul>
<li>docker-compose up -d</li>
</ul></li>
<li>инициализация сервера</li>
</ul>
<pre><code>
docker exec -it configSrv mongosh --port 27017

&gt; rs.initiate(
  {
    _id : &quot;config_server&quot;,
       configsvr: true,
    members: [
      { _id : 0, host : &quot;configSrv:27017&quot; }
    ]
  }
);
&gt; exit(); 

</code></pre>
<ul>
<li>инициализация шарды</li>
</ul>
<pre><code>
docker exec -it shard1 mongosh --port 27018

&gt; rs.initiate(
    {
      _id : &quot;shard1&quot;,
      members: [
        { _id : 0, host : &quot;shard1:27018&quot; },
       // { _id : 1, host : &quot;shard2:27019&quot; }
      ]
    }
);
&gt; exit();

docker exec -it shard2 mongosh --port 27019

&gt; rs.initiate(
    {
      _id : &quot;shard2&quot;,
      members: [
       // { _id : 0, host : &quot;shard1:27018&quot; },
        { _id : 1, host : &quot;shard2:27019&quot; }
      ]
    }
  );
&gt; exit();

</code></pre>
<ul>
<li>Инцициализируйте роутер и наполните его тестовыми данными:</li>
</ul>
<pre><code>
docker exec -it mongos_router mongosh --port 27020

&gt; sh.addShard( &quot;shard1/shard1:27018&quot;);
&gt; sh.addShard( &quot;shard2/shard2:27019&quot;);

&gt; sh.enableSharding(&quot;somedb&quot;);
&gt; sh.shardCollection(&quot;somedb.helloDoc&quot;, { &quot;name&quot; : &quot;hashed&quot; } )

&gt; use somedb;

&gt; for(var i = 0; i &lt; 1000; i++) db.helloDoc.insert({age:i, name:&quot;ly&quot;+i})

&gt; db.helloDoc.countDocuments() 
&gt; exit();

</code></pre>
<ul>
<li>Получится результат — 1000 документов.</li>
<li>Сделайте проверку на шардах:</li>
</ul>
<pre><code>
 docker exec -it shard1 mongosh --port 27018
 &gt; use somedb;
 &gt; db.helloDoc.countDocuments();
 &gt; exit();

</code></pre>
<ul>
<li>Получится результат — 492 документа.</li>
<li>Сделайте проверку на втором шарде:</li>
</ul>
<pre><code>
docker exec -it shard2 mongosh --port 27019
 &gt; use somedb;
 &gt; db.helloDoc.countDocuments();
 &gt; exit();

</code></pre>
<ul>
<li>Получится результат — 508 документов. Поздравляем! Документы
распределились.</li>
</ul>
<h2 id="горизонтальное-масштабирование-приложения-1">Горизонтальное
масштабирование приложения</h2>
<h3 id="способы-сохранения-состояний-приложения-1">Способы сохранения
состояний приложения</h3>
<ul>
<li>Stateful - с сохранением состояния
<ul>
<li>система сохраняет информацию о предыдущих состояниях или
взаимодействиях с клиентами</li>
<li>когда экземпляров приложения несколько, но пользователю нужно всегда
попадать на сервер, который владеет конкретным закреплённым за ним
состоянием
<ul>
<li>пример, у магазина в каждом экземпляре сервиса есть свой локальный
кеш или отдельный экземпляр кеша,
<ul>
<li>где сохраняется текущее состояние корзины. В фоне это состояние
сохраняется в общую базу данны</li>
<li>Если пользователь попадёт на другой экземпляр, то корзины в кеше не
будет</li>
</ul></li>
</ul></li>
</ul></li>
<li>Stateless - без сохранения состояния
<ul>
<li>архитектура приложения не сохраняет информацию о предыдущих
состояниях или сеансах где-то отдельно от остальных сервисов</li>
<li>такой подход можно горизонтально масштабировать</li>
</ul></li>
</ul>
<h3 id="балансировщик-нагрузки-1">Балансировщик нагрузки</h3>
<ul>
<li>можно было бы сделать много серверов на каждом экземпляр приложения
<ul>
<li>но как тогда пользователь попадет на экземпляр</li>
</ul></li>
<li>решение балансировщик нагрузки
<ul>
<li>инструмент для распределения запросов между серверами внутри
кластера.</li>
<li><figure>
<img src="images/img_126.png" alt="img_126.png" />
<figcaption aria-hidden="true">img_126.png</figcaption>
</figure></li>
<li>обеспечивает непрерывную работу приложения
<ul>
<li>если один из серверов выйдет их строя</li>
</ul></li>
<li>позволяет провести горизонтальное масштабирование
<ul>
<li>распределяет нагрузку между серверами</li>
</ul></li>
<li>повышает безопасность
<ul>
<li>анализ трафика, фильтр запросов</li>
</ul></li>
</ul></li>
</ul>
<h4 id="виды-балансировщиков-нагрузки-1">Виды балансировщиков
нагрузки</h4>
<ul>
<li>Балансировщики нагрузки по устройству
<ul>
<li>Программные
<ul>
<li>сервисы, которые обычно работают на отдельном сервере.</li>
<li>В зависимости от выбранного алгоритма они отправляют трафик на тот
или иной экземпляр приложения</li>
</ul></li>
<li>виртуальные
<ul>
<li>VMware, Hyper-V или KVM</li>
</ul></li>
<li>Аппаратные
<ul>
<li>непосредственно физические устройства, работающие на 4 и 7 уровнях
модели OSI, используются в ЦОД</li>
</ul></li>
</ul></li>
<li>Балансировщики нагрузки по функциям
<ul>
<li>На 4 (TCP, UDP - IP и порты), транспортном уровне, балансировщик
быстрее обрабатывает запросы,
<ul>
<li>поскольку не анализирует содержимое пакетов и имеет возможность
работать с адресами серверов</li>
</ul></li>
<li>На 7 (http), уровне приложений, балансировщик маршрутизирует контент
с учётом содержимого
<ul>
<li>и позволяет принимать сложные решения о маршрутизации, используя
данные, специфические для конкретного приложения</li>
<li>при этом они медленнее (Redis, Mongo, микросервисы)</li>
</ul></li>
<li>есть разные алгоритмы распределения
<ul>
<li>Round Robin (В базовом варианте) - В порядке очереди</li>
<li>Weighted Round Robin - аналог Round Robin, но с весами</li>
<li>IP Hash, или Sticky sessions (stateful-приложения) - использует хеш
IP-адреса клиента, чтобы распределить на какой сервер</li>
<li>Least Connection (Микросервисная архитектура) - На наименее
загруженный сервер</li>
<li>Least Response Time (Микросервисная архитектура) - На сервер с
наименьшим средним временем обработки ответа</li>
<li>LeastBandwidth (Микросервисная архитектура) - На сервер с наименьшим
трафиком</li>
</ul></li>
</ul></li>
</ul>
<h4 id="как-настроить-балансировщик-нагрузки-nginx-1">Как настроить
балансировщик нагрузки Nginx</h4>
<ul>
<li>Пример конфигурации для небольшого количества серверов</li>
</ul>
<pre><code>
   upstream application{
      least_conn; #алгоритм
      server 195.2.2.11; # ip-адреса серверов
      server 195.2.2.12;
      server 195.2.2.13;
   }

   server {
      listen 80; #порт nginx

      location / {
         # назначение трафика
          proxy_pass http://application;
      }
   }

</code></pre>
<ul>
<li>Паттерн API Gateway - единая точка входа для клиентских приложений
<ul>
<li>регламентирует коммуникации между клиентом и сервисами, убирая
прямую привязку сервисов к клиентам, абстрагирует сервисы от
клиентов.</li>
<li><figure>
<img src="images/img_127.png" alt="img_127.png" />
<figcaption aria-hidden="true">img_127.png</figcaption>
</figure></li>
</ul></li>
</ul>
<pre><code>
Простой пример. 
Представьте, что есть маленькая компания из 10 человек, в которой все свободно общаются друг с другом напрямую. 
Со временем компания растёт, человек в ней уже 300 и общаться всем напрямую долго, неудобно и неэффективно.
Чтобы всё упростить, создаются направления, команды, выделяются руководители и прописываются регламенты. 
Паттерн API Gateway — как раз такой руководитель, который централизованно передаёт задачи и информацию своим сотрудникам
и предоставляет результаты работы другим направлениям в компании.
При этом каждый отдельный сотрудник его команды напрямую не привязан к «сервису», то есть руководству компании и другим отделам.

</code></pre>
<ul>
<li>Внутрь API Gateway, этой единой точки входа, можно добавить разную
функциональность:
<ul>
<li>аутентификацию, походы в кеш, роутинг, логирование и другие нужные
функции и инструменты.</li>
</ul></li>
<li>Паттерн Service Discovery - паттерн, который облегчает коммуникацию
между приложениями,
<ul>
<li>даже если меняется количество их инстансов или сетевое
расположение</li>
<li>реестр, что-то вроде маленькой базы данных, в котором хранится
метаинформация о микросервисах, их экземплярах и сетевом
расположении.</li>
<li><figure>
<img src="images/img_128.png" alt="img_128.png" />
<figcaption aria-hidden="true">img_128.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h4 id="apisix-gateway-1">APISIX Gateway</h4>
<ul>
<li>PISIX Gateway, или API-шлюз, — инструмент с открытым исходным кодом
и встроенным Consul.
<ul>
<li>Consul — продукт от компании HashiCorp, который позволяет
регистрировать и отменять регистрацию IT-сервисов,
<ul>
<li>работающих в сети организации, а также хранить информацию о
них.</li>
</ul></li>
<li>Consul представляет собой хранилище данных типа «ключ —
значение».</li>
</ul></li>
<li><figure>
<img src="images/img_129.png" alt="img_129.png" />
<figcaption aria-hidden="true">img_129.png</figcaption>
</figure></li>
<li>Реализация функций реестра обнаружения сервисов включает в себя два
этапа:
<ul>
<li>Регистрация сервисов: сервисы «отмечаются» в реестре.</li>
<li>Обнаружение сервисов: клиентское приложение получает информацию о
маршрутах сервисов через реестр.</li>
</ul></li>
</ul>
<h4 id="практика-настройка-apisix-gateway-1">Практика: настройка APISIX
Gateway</h4>
<ul>
<li>понадобится docker и docker-compose</li>
</ul>
<pre><code>
#Возьмём официальный репозиторий APISIX
git clone https://github.com/apache/apisix-docker.git

#Перейти в папку example, нам не особо интересен дашборд сейчас
cd example

</code></pre>
<ul>
<li>Добавьте сервис в docker-compose.yml:</li>
</ul>
<pre><code>
  consul:
    image: consul:1.15.1
    container_name: consul
    restart: always
    networks:
      - apisix
    ports:
      - &#39;8500:8500&#39;
    command: &#39;agent -server -bootstrap-expect=1 -node=agent-one -client 0.0.0.0 -log-level info -data-dir=/consul/data -enable-script-checks&#39;

</code></pre>
<ul>
<li>Полный файл docker-compose.yml:</li>
</ul>
<pre><code>
version: &quot;3&quot;

services:
  #api gateway
  apisix:
    image: apache/apisix:3.9.0-debian
    restart: always
    volumes:
      - ./apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro
    depends_on:
      - etcd
    ##network_mode: host
    ports:
      - &quot;9180:9180/tcp&quot;
      - &quot;9080:9080/tcp&quot;
      - &quot;9091:9091/tcp&quot;
      - &quot;9443:9443/tcp&quot;
      - &quot;9092:9092/tcp&quot;
    networks:
      apisix:

  #база данных типа Key-value для APISIX
  etcd:
    image: quay.io/coreos/etcd:v3.5.13
    restart: always
    volumes:
      - etcd_data:/etcd-data
    environment:
      ETCD_DATA_DIR: &quot;/etcd-data&quot;
      ETCD_ENABLE_V2: &quot;true&quot;
      ETCD_LISTEN_CLIENT_URLS: &quot;http://0.0.0.0:2379&quot;
      ETCD_ADVERTISE_CLIENT_URLS: &quot;http://etcd:2379&quot;
      ETCD_NAME: &quot;etcd-node1&quot;
    ports:
      - &quot;2379:2379&quot;
    networks:
      - app-network


  #сервис для проверки
  web1:
    image: nginx:1.19.0-alpine
    restart: always
    volumes:
      - ./upstream/web1.conf:/etc/nginx/nginx.conf
    ports:
      - &quot;9081:80/tcp&quot;
    environment:
      - NGINX_PORT=80
    networks:
      apisix:
  
  # сервис для проверки
  web2:
    image: nginx:1.19.0-alpine
    restart: always
    volumes:
      - ./upstream/web2.conf:/etc/nginx/nginx.conf
    ports:
      - &quot;9082:80/tcp&quot;
    environment:
      - NGINX_PORT=80
    networks:
      apisix:

  consul:
    image: consul:1.15.1
    container_name: consul
    restart: always
    networks:
      - apisix
    ports:
      - &#39;8500:8500&#39;
    command: &#39;agent -server -bootstrap-expect=1 -node=agent-one -client 0.0.0.0 -log-level info -data-dir=/consul/data -enable-script-checks&#39;

networks:
  apisix:
    driver: bridge

volumes:
  etcd_data:
    driver: local

</code></pre>
<ul>
<li>Добавьте в apisix_conf/config.yaml для apisix данные consul:</li>
</ul>
<pre><code>
apisix:
  node_listen: 9080              # APISIX listening port
  enable_ipv6: false

  enable_control: true
  control:
    ip: &quot;0.0.0.0&quot;
    port: 9092

  enable_admin: true
  admin:
    listen:
      ip: &quot;0.0.0.0&quot;
      port: 9180

discovery:
  consul:
    servers:
      - &quot;http://consul:8500&quot;
    timeout:
      connect: 1000
      read: 1000
      wait: 60
    weight: 1
    default_service:
      protocol: &quot;http&quot;

deployment:
  admin:
    allow_admin:               # https://nginx.org/en/docs/http/ngx_http_access_module.html#allow
      - 0.0.0.0/0              # We need to restrict ip access rules for security. 0.0.0.0/0 is for test.

    admin_key:
      - name: &quot;admin&quot;
        key: edd1c9f034335f136f87ad84b625c8f1
        role: admin                 # admin: manage all configuration data

      - name: &quot;viewer&quot;
        key: 4054f7cf07e344346cd3f287985e76a2
        role: viewer

  etcd:
    host:                           # it&#39;s possible to define multiple etcd hosts addresses of the same etcd cluster.
      - &quot;http://etcd:2379&quot;          # multiple etcd address
    prefix: &quot;/apisix&quot;               # apisix configurations prefix
    timeout: 30                     # 30 seconds

plugin_attr:
  prometheus:
    export_addr:
      ip: &quot;0.0.0.0&quot;
      port: 9091

</code></pre>
<ul>
<li>Запустите:
<ul>
<li>docker-compose up -d</li>
</ul></li>
<li>Определите IP:
<ul>
<li>docker inspect -f=‘{{.Name}} - {{range
.NetworkSettings.Networks}}{{.IPAddress}}{{end}}’ $( docker ps -aq) |
grep web</li>
<li>В результате вы получите свои IP-адреса (например, 10.89.0.2 и
10.89.0.3).</li>
</ul></li>
<li>нужно вызвать Consul для регистрации сервисов.
<ul>
<li>В реальном приложении (например, на Spring Framework) в конфигурации
просто указывается адрес Consul и каждый экземпляр регистрируется сам:
<ul>
<li>В результате консоль выдаст: “truetrue%”</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
curl &quot;http://127.0.0.1:8500/v1/agent/service/register&quot; -X PUT \
  -H &quot;Content-Type: application/json&quot; \
  -d &#39;{
    &quot;ID&quot;: &quot;svc-a1&quot;,
    &quot;Name&quot;: &quot;svc-a&quot;,
    &quot;Tags&quot;: [&quot;sample_web_svc&quot;, &quot;v1&quot;],
    &quot;Address&quot;: &quot;&#39;10.89.0.2&#39;&quot;,
    &quot;Port&quot;: 80,
    &quot;Weights&quot;: {
      &quot;Passing&quot;: 10,
      &quot;Warning&quot;: 1
    }
  }&#39;

curl &quot;http://127.0.0.1:8500/v1/agent/service/register&quot; -X PUT \
  -H &quot;Content-Type: application/json&quot; \
  -d &#39;{
    &quot;ID&quot;: &quot;svc-a2&quot;,
    &quot;Name&quot;: &quot;svc-a&quot;,
    &quot;Tags&quot;: [&quot;sample_web_svc&quot;, &quot;v1&quot;],
    &quot;Address&quot;: &quot;&#39;10.89.0.3&#39;&quot;,
    &quot;Port&quot;: 80,
    &quot;Weights&quot;: {
      &quot;Passing&quot;: 10,
      &quot;Warning&quot;: 1
    }
  }&#39;

</code></pre>
<ul>
<li>Проверьте регистрацию непосредственно в Consul:
<ul>
<li>curl “http://127.0.0.1:8500/v1/catalog/service/svc-a” | jq</li>
</ul></li>
</ul>
<pre><code>
[
  {
    &quot;ID&quot;: &quot;1f42ff08-f451-5733-a62c-990011b0adf5&quot;,
    &quot;Node&quot;: &quot;agent-one&quot;,
    &quot;Address&quot;: &quot;10.89.0.5&quot;,
    &quot;Datacenter&quot;: &quot;dc1&quot;,
    &quot;TaggedAddresses&quot;: {
      &quot;lan&quot;: &quot;10.89.0.5&quot;,
      &quot;lan_ipv4&quot;: &quot;10.89.0.5&quot;,
      &quot;wan&quot;: &quot;10.89.0.5&quot;,
      &quot;wan_ipv4&quot;: &quot;10.89.0.5&quot;
    },
    &quot;NodeMeta&quot;: {
      &quot;consul-network-segment&quot;: &quot;&quot;
    },
    &quot;ServiceKind&quot;: &quot;&quot;,
    &quot;ServiceID&quot;: &quot;svc-a1&quot;,
    &quot;ServiceName&quot;: &quot;svc-a&quot;,
    &quot;ServiceTags&quot;: [
      &quot;sample_web_svc&quot;,
      &quot;v1&quot;
    ],
    &quot;ServiceAddress&quot;: &quot;10.89.0.2&quot;,
    &quot;ServiceTaggedAddresses&quot;: {
      &quot;lan_ipv4&quot;: {
        &quot;Address&quot;: &quot;10.89.0.2&quot;,
        &quot;Port&quot;: 80
      },
      &quot;wan_ipv4&quot;: {
        &quot;Address&quot;: &quot;10.89.0.2&quot;,
        &quot;Port&quot;: 80
      }
    },
    &quot;ServiceWeights&quot;: {
      &quot;Passing&quot;: 10,
      &quot;Warning&quot;: 1
    },
    &quot;ServiceMeta&quot;: {},
    &quot;ServicePort&quot;: 80,
    &quot;ServiceSocketPath&quot;: &quot;&quot;,
    &quot;ServiceEnableTagOverride&quot;: false,
    &quot;ServiceProxy&quot;: {
      &quot;Mode&quot;: &quot;&quot;,
      &quot;MeshGateway&quot;: {},
      &quot;Expose&quot;: {}
    },
    &quot;ServiceConnect&quot;: {},
    &quot;CreateIndex&quot;: 51,
    &quot;ModifyIndex&quot;: 51
  },
  {
    &quot;ID&quot;: &quot;1f42ff08-f451-5733-a62c-990011b0adf5&quot;,
    &quot;Node&quot;: &quot;agent-one&quot;,
    &quot;Address&quot;: &quot;10.89.0.5&quot;,
    &quot;Datacenter&quot;: &quot;dc1&quot;,
    &quot;TaggedAddresses&quot;: {
      &quot;lan&quot;: &quot;10.89.0.5&quot;,
      &quot;lan_ipv4&quot;: &quot;10.89.0.5&quot;,
      &quot;wan&quot;: &quot;10.89.0.5&quot;,
      &quot;wan_ipv4&quot;: &quot;10.89.0.5&quot;
    },
    &quot;NodeMeta&quot;: {
      &quot;consul-network-segment&quot;: &quot;&quot;
    },
    &quot;ServiceKind&quot;: &quot;&quot;,
    &quot;ServiceID&quot;: &quot;svc-a2&quot;,
    &quot;ServiceName&quot;: &quot;svc-a&quot;,
    &quot;ServiceTags&quot;: [
      &quot;sample_web_svc&quot;,
      &quot;v1&quot;
    ],
    &quot;ServiceAddress&quot;: &quot;10.89.0.3&quot;,
    &quot;ServiceTaggedAddresses&quot;: {
      &quot;lan_ipv4&quot;: {
        &quot;Address&quot;: &quot;10.89.0.3&quot;,
        &quot;Port&quot;: 80
      },
      &quot;wan_ipv4&quot;: {
        &quot;Address&quot;: &quot;10.89.0.3&quot;,
        &quot;Port&quot;: 80
      }
    },
    &quot;ServiceWeights&quot;: {
      &quot;Passing&quot;: 10,
      &quot;Warning&quot;: 1
    },
    &quot;ServiceMeta&quot;: {},
    &quot;ServicePort&quot;: 80,
    &quot;ServiceSocketPath&quot;: &quot;&quot;,
    &quot;ServiceEnableTagOverride&quot;: false,
    &quot;ServiceProxy&quot;: {
      &quot;Mode&quot;: &quot;&quot;,
      &quot;MeshGateway&quot;: {},
      &quot;Expose&quot;: {}
    },
    &quot;ServiceConnect&quot;: {},
    &quot;CreateIndex&quot;: 52,
    &quot;ModifyIndex&quot;: 52
  }
]

</code></pre>
<ul>
<li><p>Стандартный ключ для доступа к API APISIX —
edd1c9f034335f136f87ad84b625c8f1.</p></li>
<li><p>Проверьте наличие consul на apisix:</p></li>
</ul>
<pre><code>
curl http://127.0.0.1:9092/v1/discovery/consul/dump | jq

# результат
{
  &quot;services&quot;: {
    &quot;svc-a&quot;: [
      {
        &quot;weight&quot;: 1,
        &quot;port&quot;: 80,
        &quot;host&quot;: &quot;10.89.0.2&quot;
      },
      {
        &quot;weight&quot;: 1,
        &quot;port&quot;: 80,
        &quot;host&quot;: &quot;10.89.0.3&quot;
      }
    ]
  },
  &quot;config&quot;: {
    &quot;keepalive&quot;: true,
    &quot;weight&quot;: 1,
    &quot;dump&quot;: {
      &quot;expire&quot;: 2592000,
      &quot;load_on_init&quot;: true,
      &quot;path&quot;: &quot;logs/consul.dump&quot;
    },
    &quot;token&quot;: &quot;&quot;,
    &quot;timeout&quot;: {
      &quot;connect&quot;: 2000,
      &quot;wait&quot;: 60,
      &quot;read&quot;: 2000
    },
    &quot;fetch_interval&quot;: 3,
    &quot;sort_type&quot;: &quot;origin&quot;,
    &quot;servers&quot;: [
      &quot;http://consul:8500&quot;
    ]
  }
}

</code></pre>
<ul>
<li>Зарегистрируйте маршрут через consul:</li>
</ul>
<pre><code>
curl &quot;http://127.0.0.1:9180/apisix/admin/routes&quot; -H &#39;X-API-KEY: edd1c9f034335f136f87ad84b625c8f1&#39; -X PUT -d &#39;
{
  &quot;id&quot;: &quot;consul-web-route&quot;,
  &quot;uri&quot;: &quot;/consul/web/*&quot;,
  &quot;upstream&quot;: {
    &quot;service_name&quot;: &quot;svc-a&quot;,
    &quot;discovery_type&quot;: &quot;consul&quot;,
    &quot;type&quot;: &quot;roundrobin&quot;
  }
}&#39; | jq

#Получаем результат

{
  &quot;key&quot;: &quot;/apisix/routes/consul-web-route&quot;,
  &quot;value&quot;: {
    &quot;status&quot;: 1,
    &quot;uri&quot;: &quot;/consul/web/*&quot;,
    &quot;update_time&quot;: 1719606436,
    &quot;id&quot;: &quot;consul-web-route&quot;,
    &quot;priority&quot;: 0,
    &quot;upstream&quot;: {
      &quot;scheme&quot;: &quot;http&quot;,
      &quot;type&quot;: &quot;roundrobin&quot;,
      &quot;pass_host&quot;: &quot;pass&quot;,
      &quot;service_name&quot;: &quot;svc-a&quot;,
      &quot;hash_on&quot;: &quot;vars&quot;,
      &quot;discovery_type&quot;: &quot;consul&quot;
    },
    &quot;create_time&quot;: 1719606436
  }
}

</code></pre>
<ul>
<li>Можно ещё получить список маршрутов для того, чтобы удостовериться,
что всё работает:
<ul>
<li>curl http://127.0.0.1:9180/apisix/admin/routes -H ‘X-API-KEY:
edd1c9f034335f136f87ad84b625c8f1’ | jq</li>
<li>Вывод будет примерно таким (хотя id могут отличаться):</li>
</ul></li>
</ul>
<pre><code>
{
  &quot;list&quot;: [
    {
      &quot;key&quot;: &quot;/apisix/routes/consul-web-route&quot;,
      &quot;value&quot;: {
        &quot;upstream&quot;: {
          &quot;scheme&quot;: &quot;http&quot;,
          &quot;discovery_type&quot;: &quot;consul&quot;,
          &quot;pass_host&quot;: &quot;pass&quot;,
          &quot;service_name&quot;: &quot;svc-a&quot;,
          &quot;hash_on&quot;: &quot;vars&quot;,
          &quot;type&quot;: &quot;roundrobin&quot;
        },
        &quot;create_time&quot;: 1719606436,
        &quot;update_time&quot;: 1719606436,
        &quot;status&quot;: 1,
        &quot;priority&quot;: 0,
        &quot;uri&quot;: &quot;/consul/web/*&quot;,
        &quot;id&quot;: &quot;consul-web-route&quot;
      },
      &quot;modifiedIndex&quot;: 16,
      &quot;createdIndex&quot;: 16
    }
  ],
  &quot;total&quot;: 1
}

</code></pre>
<ul>
<li>Финальная проверка балансировки средствами APISIX и service
discovery средствами Consul:
<ul>
<li>curl “http://127.0.0.1:9080/consul/web/”
<ul>
<li>В результате вы увидите либо:
<ul>
<li>hello web2</li>
</ul></li>
<li>Либо спустя ещё пару вызовов:
<ul>
<li>hello web1</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="архитектура-без-ведущего-узла-1">Архитектура без ведущего
узла</h2>
<h3
id="архитектура-master-slave-vs-leaderless-архитектура-1">Архитектура
Master-Slave vs Leaderless-архитектура</h3>
<ul>
<li><p>master-slave в кластере всегда есть один главный узел.</p></li>
<li><p>В архитектуре без ведущего узла (или leaderless-архитектуре) -
нет единого ведущего узла</p>
<ul>
<li>Каждый узел кластера равноправен, поэтому любой может принять запрос
на запись или чтение</li>
<li>операция записи отправляется сразу на несколько реплик и считается
успешно выполненной,
<ul>
<li>когда определённое число узлов (например, большинство) подтвердит
запись</li>
</ul></li>
<li>при чтении клиент или координатор опрашивает несколько узлов и
возвращает клиенту самый свежий (актуальный) ответ</li>
</ul></li>
<li><blockquote>
<p>CAP-теорема утверждает, что распределённая система не может
одновременно гарантировать три свойства: согласованность данных
(Consistency), доступность (Availability) и устойчивость к разделению
сети (Partition Tolerance) — в любой момент времени можно обеспечить
только два из трёх.</p>
</blockquote></li>
<li><p>В треугольнике CAP для Apache Cassandra выбираем свойства
Availability + Partition Tolerance вместо строгой Consistency</p>
<ul>
<li><figure>
<img src="images/img_130.png" alt="img_130.png" />
<figcaption aria-hidden="true">img_130.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h4 id="репликация-без-ведущего-узла-в-apache-cassandra-1">Репликация
без ведущего узла в Apache Cassandra</h4>
<ul>
<li><p>Apache Cassandra ― база данных с репликацией без лидера. В
кластере Cassandra все узлы равноправны и могут выступать координаторами
запросов.</p></li>
<li><p>клиент записывает данные в Cassandra -&gt; запрос отправляется
сразу на несколько реплик</p>
<ul>
<li>Специальный узел-координатор (им может быть любой узел, принимающий
запрос) - собирает подтверждения от реплик
<ul>
<li>и решает удалось ли применить запись.</li>
</ul></li>
</ul></li>
<li><p>Сassandra позволяет сохранять запись не на все копии сразу</p>
<ul>
<li>пример, если из трёх реплик запись была успешно применена на двух
<ul>
<li>пока третья оставалась недоступной, узел-координатор сохранит для
неё подсказку (hint) и передаст обновление, когда узел вернётся в
строй</li>
</ul></li>
</ul></li>
</ul>
<h3 id="условия-согласованности-на-примере-cassandra-1">Условия
согласованности на примере Cassandra</h3>
<ul>
<li>разработчик может напрямую управлять согласованностью, используются
два настраиваемых параметра:
<ul>
<li>фактор репликации (N);</li>
<li>уровень согласованности (Consistency Level, или CL).</li>
</ul></li>
<li>Настраивая CL на запись и чтение, разработчики определяет, сколько
узлов должны подтвердить операцию.
<ul>
<li>меньше подтверждений, то система будет работать быстрее и легко
выдержит единичные сбои, но пользователь может получить устаревшие
данные.</li>
<li>если дожидаться подтверждений от большинства или даже всех узлов, то
при чтении пользователь гарантированно получит самую новую версию,
<ul>
<li>но при сбое нескольких узлов часть операций может выполниться с
задержкой или не выполниться вовсе.</li>
</ul></li>
</ul></li>
<li>Выбирая значения CL на запись (W) и CL на чтение (R), можно добиться
разных уровней согласованности:
<ul>
<li>Конфигурация строгого кворума, где W + R &gt; N - гарантирует
пересечение множеств узлов для любой записи и чтения хотя бы в одном
узле</li>
<li>Более слабые требования (например, W=1, R=1) - дают максимальную
скорость и доступность (для операции будет достаточно всего одной
реплики),
<ul>
<li>но не обеспечивают консистентности</li>
</ul></li>
</ul></li>
<li>баланс (W = 2, R = 1 при N = 3) сочетает высокую надёжность хранения
(кворум на запись) и приемлемый уровень eventual consistency,
<ul>
<li>когда небольшое временное несовпадение данных некритично для
пользовательского опыта и бизнес-метрик.</li>
<li><figure>
<img src="images/img_131.png" alt="img_131.png" />
<figcaption aria-hidden="true">img_131.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h4
id="механизмы-восстановления-согласованности-в-cassandra-1">Механизмы
восстановления согласованности в Cassandra</h4>
<ul>
<li>Cassandra гарантирует лишь итоговую согласованность (eventual
consistency) данных.
<ul>
<li>означает, что в конечном счёте все реплики станут одинаковыми.</li>
</ul></li>
<li>Hinted Handoff («Передача с подсказкой»)
<ul>
<li>узел-координатор пишет на реплики и обнаруживает, что какая-то из
них недоступна,</li>
<li>он не прерывает операцию (если набран кворум подтверждений),</li>
<li>а сохраняет хинт ― информацию о пропущенной записи.</li>
<li><figure>
<img src="images/img_132.png" alt="img_132.png" />
<figcaption aria-hidden="true">img_132.png</figcaption>
</figure></li>
<li>когда узел восстановиться координатор или другой узел передаст ему
из хинтов накопленные изменения и доведет до актуального</li>
<li>Если же узел долго не возвращается или хинт оказывается утерян, то
уже нельзя гарантировать доставку изменений.</li>
</ul></li>
<li>Read Repair (восстановление согласованности при чтении)
<ul>
<li>Если во время чтения данных обнаружится, что разные реплики
возвращают разные версии, то сработает механизм Read Repair
<ul>
<li>Его работа зависит от того, какой уровень согласованности был
выбран</li>
</ul></li>
<li>узел-координатор, получая данные от нескольких реплик, сравнивает их
между собой перед тем, как отдать результат клиенту.
<ul>
<li>Так определяется самая свежая версия.
<ul>
<li>Обычно это происходит по метке времени</li>
<li>такой подход называется Last Write Wins (LWW)</li>
</ul></li>
</ul></li>
<li>Если выясняется, что одна из реплик содержит устаревшую версию
данных, то координатор сразу же записывает на неё актуальное
значение</li>
<li>Механизм Read Repair особенно полезен для часто читаемых данных.
<ul>
<li>Они быстро становятся согласованными, так как любое чтение обнаружит
и устранит расхождения.</li>
<li>Однако если данные не читаются в течение долгого времени, то
механизм их не затронет.</li>
</ul></li>
</ul></li>
<li>Anti-Entropy Repair (процесс сравнения и синхронизации реплик)
<ul>
<li>полноценная сверка данных между репликами, которая выполняется
администратором вручную или по расписанию</li>
<li>В Cassandra механизм сравнения и синхронизации реплик реализован
через построение и сравнение Merkle Tree для данных каждого узла.</li>
<li>узлы обмениваются хеш-деревьями своих сегментов и выявляют
диапазоны, где хеши не совпадают, а значит, данные различаются
<ul>
<li>После этого их недостающие части стримятся с одной реплики на
другую, пока все реплики ну будут не синхронизированы.</li>
</ul></li>
<li>Полная сверка данных требует значительных ресурсов CPU, I/O и сети,
поэтому обычно её проводят периодически в фоновое время (например,
ночью)</li>
</ul></li>
<li>Оптимальный способ восстановления консистентности
<ul>
<li>Если узел был недоступен недолго (в течение минут или часов) и нужно
быстро восстановить актуальность данных
<ul>
<li>используйте Hinted Handoff.</li>
</ul></li>
<li>Если данные часто читаются и важна быстрая консистентность для
популярных ключей
<ul>
<li>полагайтесь на Read Repair, который «чинит» рассинхронизацию прямо
во время чтения.</li>
</ul></li>
<li>если же нужно гарантированно устранить все расхождения на редко
читаемых или долго недоступных разделах данных
<ul>
<li>запускайте Anti-Entropy Repair вручную или по расписанию</li>
</ul></li>
</ul></li>
</ul>
<h4 id="consistent-hashing-и-виртуальные-ноды-1">Consistent Hashing и
виртуальные ноды</h4>
<ul>
<li>При стандартном подходе hash-based sharding приходится
перераспределять данные между узлами
<ul>
<li>решение хеш ключа по модулю числа серверов приводит к следующей
проблеме.
<ul>
<li>если число серверов меняется, то почти все ключи «переезжают» на
новые узлы</li>
<li>Из-за этого клиенты обращаются за данными не туда, что провоцирует
массовые cache miss’ы,</li>
<li>перегрузку базы и падение производительности системы</li>
</ul></li>
<li>Consistent hashing решает эту проблему</li>
</ul></li>
</ul>
<h4 id="принцип-работы-consistent-hashing-1">Принцип работы consistent
hashing</h4>
<ul>
<li>все возможные значения хеша находятся на кольце от 0 до
2<sup></sup>160 − 1.
<ul>
<li>У каждого узла (например, сервер базы данных Cassandra) тоже есть
своё положение на этом кольце.</li>
<li>Чтобы узнать его, нужно вычислить хеш идентификатора узла.</li>
<li>Ключи данных также размещаются на кольце по хешу</li>
<li>Чтобы понять, на каком сервере хранится конкретный ключ, двигайтесь
по кольцу по часовой стрелке от позиции ключа до тех пор,
<ul>
<li>пока не встретится первый узел. Именно этот сервер и будет хранить
ключ.<br />
</li>
</ul></li>
<li>Если добавляется новый сервер, то будут перемещены только те ключи,
которые находятся между новым сервером и предыдущим против часовой
стрелки</li>
<li>А при удалении узла ключи просто «перетекают» на следующий сервер по
часовой стрелке.
<ul>
<li>Бо́льшая часть ключей не изменит своего расположения.</li>
</ul></li>
</ul></li>
<li>в базовой схеме consistent hashing есть проблемы:
<ul>
<li>Неравномерные диапазоны. Некоторые серверы могут получить слишком
большой диапазон ключей.</li>
<li>Перегрузка узлов. При случайном размещении серверов на кольце одни
узлы могут оказаться перегружены, тогда как другие будут пустовать.</li>
</ul></li>
<li><figure>
<img src="images/img_133.png" alt="img_133.png" />
<figcaption aria-hidden="true">img_133.png</figcaption>
</figure></li>
<li>в Cassandra используются виртуальные ноды (vnodes).
<ul>
<li>Один физический сервер представлен сразу несколькими виртуальными
точками на кольце.</li>
<li>Чем больше таких виртуальных точек, тем равномернее будут
распределяться ключи по узлам.<br />
</li>
<li>При добавлении нового сервера он не отбирает большой кусок у одного
узла, а забирает понемногу у многих,
<ul>
<li>тем самым минимально влияя на перераспределение данных.</li>
</ul></li>
<li><figure>
<img src="images/img_134.png" alt="img_134.png" />
<figcaption aria-hidden="true">img_134.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h4 id="особенности-работы-с-cassandra-1">Особенности работы с
Cassandra</h4>
<ul>
<li>нет внешних ключей, нет JOIN</li>
<li>одна таблица под один запрос Select-driven model</li>
<li>WHERE не поддерживает OR</li>
<li>Все операции идемпотентны</li>
<li>не поддерживается транзакции ACID</li>
<li>при удалении ставиться поле tombstone, удаляется запись только через
некоторое время</li>
</ul>
<h2 id="шарды-и-реплики-в-геораспределённой-среде-1">Шарды и реплики в
геораспределённой среде</h2>
<h3 id="облако-и-гибридная-архитектура-1">Облако и гибридная
архитектура</h3>
<ul>
<li>модели
<ul>
<li>IaaS, PaaS, Saas</li>
<li><figure>
<img src="images/img_135.png" alt="img_135.png" />
<figcaption aria-hidden="true">img_135.png</figcaption>
</figure></li>
</ul></li>
</ul>
<figure>
<img src="images/img_136.png" alt="img_136.png" />
<figcaption aria-hidden="true">img_136.png</figcaption>
</figure>
<h3
id="создание-шардированного-кластера-mongodb-в-yandex-cloud">Создание
шардированного кластера MongoDB в Yandex Cloud</h3>
<ul>
<li>инструкция смотри Шардирование и репликация/Шарды и реплики в
геораспределённой среде</li>
<li>бла-бла-бла вот получился результат</li>
<li><figure>
<img src="images/img_137.png" alt="img_137.png" />
<figcaption aria-hidden="true">img_137.png</figcaption>
</figure></li>
</ul>
<h2 id="распределённое-кеширование-1">Распределённое кеширование</h2>
<ul>
<li>Как и другие элементы инфраструктуры, кеширование можно перенести в
облако.</li>
<li>Высокая доступность данных — ключевое преимущество распределённого
облачного кеширования.
<ul>
<li>Это то, на что в первую очередь необходимо ориентироваться при
принятии решения о внедрении этого способа масштабирования.</li>
</ul></li>
<li>сложности
<ul>
<li>Зависимость от сети</li>
<li>Сложность настройки и управления</li>
<li>Меньшая безопасность данных</li>
<li>Риск потери данных</li>
<li>Сложности интеграции</li>
</ul></li>
<li>четыре типа хранилищ:
<ul>
<li>HDD
<ul>
<li>Обладают большим объёмом, но низкой скоростью обмена данными.
Стоимость — низкая.</li>
</ul></li>
<li>SSD
<ul>
<li>Обладают меньшим объёмом, но высокой скоростью обмена данными.
Стоимость — выше, чем у HDD, но не слишком высокая.</li>
</ul></li>
<li>RAM, оперативная память
<ul>
<li>Оптимальное соотношение цены и объёма обработки данных.</li>
</ul></li>
<li>CPU Cashe и CPU Registers
<ul>
<li>Самые дорогие и быстрые. Объём низкий</li>
</ul></li>
</ul></li>
</ul>
<h3 id="как-настроить-распределённое-кеширование-в-yandex-cloud-1">Как
настроить распределённое кеширование в Yandex Cloud</h3>
<ul>
<li>инструкция смотри Шардирование и репликация/Распределенное
кеширование</li>
<li>сервис Managed Service For Redis
<ul>
<li>а Managed Service For Redis переименовали в Yandex Managed Service
for Valkey™.</li>
</ul></li>
<li><figure>
<img src="images/img_138.png" alt="img_138.png" />
<figcaption aria-hidden="true">img_138.png</figcaption>
</figure></li>
<li>бла-бла-бла вот получился результат</li>
</ul>
<h2 id="content-delivery-network-cdn-1">Content Delivery Network
(CDN)</h2>
<ul>
<li>В Yandex Cloud для увеличения этой скорости есть сервис доставки
контента — CDN (Content Delivery Network)
<ul>
<li>механизм работы которого основан на разделении данных по системе
доменных имён (DNS).</li>
</ul></li>
</ul>
<h3 id="методы-разделения-данных-на-основе-dns-1">Методы разделения
данных на основе DNS</h3>
<ul>
<li>GeoDNS (solitary traffic directors, global traffic directors)
<ul>
<li>это метод географических доменных имён, который использует алгоритм
определения геокоординат по IP-адресу пользователя.
<ul>
<li>Клиент отправляет запрос, DNS-сервер определяет местоположение
пользователя по IP-адресу и находит ближайшую точку присутствия.</li>
</ul></li>
<li>Точка присутствия (пограничный узел, Point of presence, PoP)
<ul>
<li>это базовый компонент CDN. Здесь находятся копии или кешированные
версии контента, полученного от основного источника.
<ul>
<li>Их количество и географическое расположение влияет на эффективность
использования CDN.</li>
</ul></li>
</ul></li>
<li>GeoDNS позволяет контролировать, кто именно получает доступ к вашему
ресурсу в зависимости от географического положения.</li>
<li>Это позволяет ограничивать доступ из определённых стран, обеспечивая
соблюдение региональных законов</li>
</ul></li>
<li>Anycast
<ul>
<li>это метод сетевой адресации и маршрутизации, при котором один
IP-адрес присваивается нескольким серверам в сети.
<ul>
<li>Серверы при этом находятся в разных точках присутствия.</li>
<li><figure>
<img src="images/img_139.png" alt="img_139.png" />
<figcaption aria-hidden="true">img_139.png</figcaption>
</figure></li>
</ul></li>
<li>Найти такой сервер можно с помощью инструмента nslookup.</li>
<li>Anycast DNS можно представить как единый IP-адрес с несколькими
точками присутствия</li>
</ul></li>
</ul>
<h3 id="механизм-работы-cdn-1">Механизм работы CDN</h3>
<ul>
<li>Content Delivery Network, или CDN,
<ul>
<li>это распределённые узлы хранения и доставки информации.</li>
<li>Сервис представляет собой систему, которая в ответ на запросы от
клиента запрашивает, получает и кеширует данные от источника и отдаёт их
клиенту</li>
<li>без CDN, запросы от пользователей направляются сразу на первичный
сервер</li>
</ul></li>
<li>логика работы
<ul>
<li>Когда пользователь заходит на сайт, запрос направляется к ближайшему
CDN-серверу.
<ul>
<li>Если запрашиваемая информация кеширована на нём, данные сразу
отдаются пользователю.
<ul>
<li>Если данные запрашиваются впервые или они устарели, CDN-сервер
сначала загружает их с сервера-источника, а затем отдаёт клиент</li>
</ul></li>
</ul></li>
</ul></li>
<li>Архитектура CDN
<ul>
<li><figure>
<img src="images/img_140.png" alt="img_140.png" />
<figcaption aria-hidden="true">img_140.png</figcaption>
</figure></li>
<li>CDN, или пограничные серверы, хранят копии контента, который
предоставляют пользователям по запросу.</li>
</ul></li>
<li>в качестве основного сервера ля размещения данных можно использовать
один из трёх вариантов:
<ul>
<li>Бакет из Yandex Object Storage, том числе настроенный как хостинг
статического сайта.
<ul>
<li>Object Storage — это S3-подобное объектное хранилище</li>
</ul></li>
<li>L7-балансировщик нагрузки из Yandex Application Load Balance</li>
<li>Собственный сервер или другой ресурс, доступный по доменному
имени.</li>
</ul></li>
<li>преимущества CDN:
<ul>
<li>Улучшает SEO</li>
<li>Позволяет избежать дополнительных расходов на инфраструктур</li>
<li>Повышает доступность сайта за счёт резервирования серверов друг
другом</li>
</ul></li>
<li>Ограничения CDN:
<ul>
<li>Проблемы с динамическим контентом</li>
<li>Задержки при обновлении контента</li>
<li>Блокировка по IP-адресам</li>
<li>Зависимость от провайдера</li>
</ul></li>
</ul>
<h3 id="как-настроить-cdn-в-облаке-yandex-cloud-1">Как настроить CDN в
облаке Yandex Cloud</h3>
<ul>
<li>инструкция смотри Шардирование и репликация/Content Delivery Network
(CDN)</li>
<li>CDN в облаке получится настроить только при наличии доменного
имени</li>
<li>В контексте объектного хранилища файлы и каталоги называются
объектами</li>
<li>Эти объекты располагаются в корзинах-бакетах</li>
</ul>
<h2 id="как-настроить">Как настроить</h2>
<ul>
<li>Используем Yandex Cloud
<ul>
<li>создаем в облаке Бакет для хранения объектов
<ul>
<li>5 гигов, имя, чтение публичной, список объектов ограниченный, чтение
настроек ограниченное, класс стандартное</li>
</ul></li>
<li>после создания заходим в бакет - настройки - веб-сайт
<ul>
<li>хостинг - вводим главная страница - index.html</li>
</ul></li>
<li>загружаем в Объекты статику - от HTML до JS
<ul>
<li>при успешной загрузке можно проверить шлепнув по ссылке
<ul>
<li>например,
https://mobile-world-by-volkov.website.yandexcloud.net</li>
</ul></li>
</ul></li>
<li>далее настраиваем доступ CDN для замкадышей (то есть для себя)
<ul>
<li>в консоле Yandex Cloud
<ul>
<li>выбираем приз или Cloud CDN
<ul>
<li>создать ресурс</li>
</ul></li>
<li>выбираем Тип источника Бакет - в списке нужный</li>
<li>домен ставим свой домен (от Бакета), например
mobile-world-by-volkov.website.yandexcloud.net</li>
<li>далее можно добавить кеширование например задать Время жизни кеша -
от нескольких секунд до 4 дней</li>
<li>так же можно добавить HTTP заголовки (даже кастомные)</li>
</ul></li>
</ul></li>
</ul></li>
<li>бла-бла-бла вот получился результат
<ul>
<li><figure>
<img src="images/img_141.png" alt="img_141.png" />
<figcaption aria-hidden="true">img_141.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h2 id="оценка-угроз-системам-компании-1">Оценка угроз системам
компании</h2>
<h3 id="виды-угроз-1">Виды угроз</h3>
<ul>
<li>Угрозы по месту
<ul>
<li>внутренние - заложенные уязвимости в программных и аппаратных
компонентах</li>
<li>внешние - атаки, взлом, фишинг, социальная инженерия</li>
</ul></li>
<li>Угрозы по видимости
<ul>
<li>активные - явное внедрение вредоносного кода, повреждение данных,
изменение конфигурации (вирус)</li>
<li>пассивные - мониторинг трафика (тяжело отследить информационный
след)</li>
</ul></li>
<li>Угрозы по доступу
<ul>
<li>С несанкционированным доступом - обход штатных средств
аутентификации</li>
<li>С утечкой или нарушением целостности данных - данные
компрометируются или пропадают (Сотрудник компании случайно удаляет
важные данные,)</li>
</ul></li>
<li>Угрозы по цели
<ul>
<li>Угрозы данным
<ul>
<li>возникают в результате несанкционированного доступа</li>
<li>Целью является кража данных, нарушение их целостности, включая
удаление.</li>
</ul></li>
<li>Угрозы компонентам, информационным сервисам
<ul>
<li>попытки внедрения вредоносного ПО или изменения программных
компонентов системы</li>
</ul></li>
<li>Угрозы аппаратному обеспечению
<ul>
<li>физическое повреждение оборудования, кража или неправомерный доступ
к аппаратным компонентам.</li>
</ul></li>
<li>Угрозы обеспечивающей инфраструктуре
<ul>
<li>атаки на сетевую инфраструктуру, серверы, кластеры оркестрации
сервисов (Kubernetes), базы данных</li>
</ul></li>
</ul></li>
<li>Угрозы по объективности
<ul>
<li>Объективные - угрозы связаны реальными и конкретными факторами,
<ul>
<li>они не зависят от действий пользователя или случайных событий,</li>
<li>их можно предсказать или учесть заранее:
<ul>
<li>активируемые угрозы — вредоносное ПО и бэкдоры, программные
«закладки» и закладки аппаратуры;</li>
<li>особенности объекта — его расположение, наличие контролируемой зоны,
каналов обмена информацией
<ul>
<li>(например, выход ЦОДа из строя при размещении инфраструктуры в
облаке).</li>
</ul></li>
</ul></li>
</ul></li>
<li>Субъективные - угрозы, связанные с человеческим фактором,
<ul>
<li>неправильной эксплуатацией или ошибками в процессе работы с
системой:
<ul>
<li>ошибки при установке ПО и в процессе эксплуатации</li>
<li>повреждение данных или ненадлежащая работа с ними</li>
</ul></li>
</ul></li>
<li>Случайные - не зависят от человеческого фактора
<ul>
<li>и могут быть вызваны случайными сбоями или неисправностями в работе
системы или инфраструктуры:
<ul>
<li>неисправность, повреждения сетевых коммуникаций или систем
киберзащиты.</li>
<li><figure>
<img src="images/img_142.png" alt="img_142.png" />
<figcaption aria-hidden="true">img_142.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="векторы-угроз-1">Векторы угроз</h3>
<ul>
<li>Создается список наиболее популярных шаблонов атак и базы данных на
основе анализа глобальных инцидентов безопасности.</li>
<li>В них содержатся сведения о том, какие угрозы существуют,
<ul>
<li>какие тактики и техники использует злоумышленник и как можно
защититься:
<ul>
<li>ATT&amp;CK (MITRE) — фреймворк для описания тактик и техник
атакующих на разных стадиях кибератак.</li>
<li>OWASP Top Ten — список десяти наиболее распространённых уязвимостей
в веб-приложениях.</li>
<li>CAPEC — база данных с описанием типичных шаблонов атак, таких как
DDoS и инъекции кода.</li>
<li>STIX — стандарт обмена информацией об угрозах для координации между
организациями.</li>
<li>CWE (Common Weakness Enumeration) — список известных уязвимостей в
программном обеспечении.</li>
<li>NVD (National Vulnerability Database) — национальная база
уязвимостей с классификацией и описаниями.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="примеры-реализации-угроз-данным-1">Примеры реализации угроз
данным</h3>
<ul>
<li><figure>
<img src="images/img_143.png" alt="img_143.png" />
<figcaption aria-hidden="true">img_143.png</figcaption>
</figure></li>
<li>SQL-инъекции - украсть пользовательские данные или вовсе их
уничтожить.</li>
<li>XSS-уязвимости, или XSS (Cross-Site Scripting), — ошибка валидации
пользовательских данных,
<ul>
<li>которая позволяет передать JavaScript-код на исполнение в браузер
пользователя</li>
</ul></li>
<li>DDoS-атаки (Distributed Denial of Service — распределённый отказ в
обслуживании</li>
<li>Ботнет — сеть заражённых компьютеров, используемых для выполнения
вредоносных действий без ведома их владельцев.</li>
<li>Advanced Persistent Threat, или APT, — продолжительная
подготовленная целенаправленная кибератака.
<ul>
<li>В отличие от DDoS, APT — комплексная киберугроза, которая сочетает
различные способы атак на корпоративную инфраструктуру.</li>
</ul></li>
<li>Эксплойты - уязвимости в ПО и аппаратной части, которые могут
использовать для взлома.</li>
<li>Перехват паролей — процесс получения доступа к чужому аккаунту</li>
<li>Вирусы — вредоносные программы,</li>
</ul>
<h3 id="оценка-угроз-1">Оценка угроз</h3>
<ul>
<li>Выявление ресурсов и компонентов информационной системы
<ul>
<li>нужно определить активы IT-ландшафта — информационные ресурсы и
компоненты информационной системы
<ul>
<li>данные, оборудование, сотрудники или даже бизнес-процессы</li>
</ul></li>
<li>типы объектов воздействия:
<ul>
<li>сервер;</li>
<li>прикладное ПО (все сервисы/микросервисы);</li>
<li>сетевое оборудование;</li>
<li>средства защиты информации;</li>
<li>средства хранения данных (базы данных, брокеры, кеши и так
далее);</li>
<li>обеспечивающие системы (коробочные компоненты, готовые
программно-аппаратные модели и прочее).</li>
</ul></li>
</ul></li>
<li>Соотнесение объектов воздействия с вероятными векторами угроз
<ul>
<li>выявить вероятные реализации угроз, то есть векторы угроз</li>
<li>MindMap поможет визуализировать возможные уязвимости и сформировать
план мер по обеспечению безопасности системы.</li>
<li><figure>
<img src="images/img_144.png" alt="img_144.png" />
<figcaption aria-hidden="true">img_144.png</figcaption>
</figure></li>
</ul></li>
<li>Оценка вероятности угрозы
<ul>
<li>возможно ли фактически реализовать данную угрозу</li>
<li>определить сценарий, который может реализовать злоумышленник</li>
</ul></li>
<li>Анализ влияния угрозы и принятие решения
<ul>
<li>готовится документ, в котором отражены
<ul>
<li>категория угрозы, источники и условия её возникновения;</li>
<li>факторы в текущей архитектуре, которые приводят к возможности
реализации угрозы;</li>
<li>варианты изменений в архитектуре, которые позволят устранить или
избежать выявленной угрозы.
<ul>
<li>ADR — Architecture Decision Record</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<pre><code>
ADR ID: ADR.24.10.001

Title: Обеспечение безопасности данных для онлайн-сервисов PropDevelopment

Date: 15.10.2024

Status: Принято к реализации

Контекст

Компания PropDevelopment готовится к комплексному аудиту информационной безопасности. В ходе анализа были выявлены угрозы, такие как отсутствие контроля внутренних потоков данных между системами, незащищённые API для партнеров, а также риски, связанные с интенсивным накоплением и обработкой данных.
Компания стремится разработать единый план безопасности, учитывающий конфиденциальность, целостность и доступность данных.

Решение

- Внедрить централизованный API Gateway для контроля доступа к внутренним и внешним API, мониторинга и аудита передаваемых данных.
- Разработать и внедрить единую политику безопасности для всех партнерских API, ограничив доступ к определённым категориям данных.
- Классифицировать данные и внедрить ролевую модель доступа для ограничения прав пользователей и систем на основе категории данных.

Обоснование
- API Gateway обеспечит централизованный контроль и мониторинг доступа, предотвращая несанкционированный доступ к данным.
- Политики безопасности для партнеров ограничат и регламентируют их доступ к данным и таким образом повысят защиту от внешних угроз.
- Классификация данных и ролевая модель доступа помогут минимизировать риски утечки данных, соблюдая принцип минимальных привилегий.

Последствия
- Потребуется разработка и настройка API Gateway.
- Необходим анализ текущих договоров и интеграций для внедрения политики безопасности API партнеров.
- Классификация данных и внедрение ролевого доступа потребуют пересмотра процессов обработки данных.

Статус
Принято к реализации. 
Планируется поэтапная реализация с последующим мониторингом и проверкой эффективности мер.

</code></pre>
<ul>
<li>приоритет выявленных угроз
<ul>
<li>финансовые потери</li>
<li>репутационные риски</li>
</ul></li>
</ul>
<h2 id="как-управлять-рисками-1">Как управлять рисками</h2>
<ul>
<li><figure>
<img src="images/img_145.png" alt="img_145.png" />
<figcaption aria-hidden="true">img_145.png</figcaption>
</figure></li>
<li><figure>
<img src="images/img_146.png" alt="img_146.png" />
<figcaption aria-hidden="true">img_146.png</figcaption>
</figure></li>
<li>Вероятность угрозы — это частота или вероятность, с которой
злоумышленник может попытаться совершить атаку</li>
<li>Величина уязвимости — это вероятность того, что при попытке
эксплуатировать уязвимость атака будет успешной.</li>
<li><figure>
<img src="images/img_147.png" alt="img_147.png" />
<figcaption aria-hidden="true">img_147.png</figcaption>
</figure></li>
</ul>
<h3 id="типы-рисков-1">Типы рисков</h3>
<ul>
<li>Прямые риски — это риски, которые приводят к негативным
последствиям, прямому ущербу для работы информационных систем и
компании.</li>
<li>Косвенные риски — также приводят к негативным последствиям, но ущерб
от них косвенный.
<ul>
<li>Например, недополученная прибыль, потеря деловой репутации,
дополнительные расходы.</li>
</ul></li>
<li>Как анализировать риски
<ul>
<li><figure>
<img src="images/img_148.png" alt="img_148.png" />
<figcaption aria-hidden="true">img_148.png</figcaption>
</figure></li>
<li>Первый этап анализа — это идентификация активов ландшафта
<ul>
<li>Выявление активов — это также первый шаг для оценки угроз.</li>
</ul></li>
<li>На пятом этапе анализа нужно оценить вероятности реализации
угроз</li>
</ul></li>
<li>Подходы к анализу рисков
<ul>
<li><figure>
<img src="images/img_149.png" alt="img_149.png" />
<figcaption aria-hidden="true">img_149.png</figcaption>
</figure></li>
</ul></li>
<li>Качественный анализ рисков
<ul>
<li>компания привлекает нескольких экспертов для оценки рисков.</li>
<li>Основные методы качественного анализа — это:
<ul>
<li>использование шкалы оценок или матрицы рисков
<ul>
<li>вероятность риска и его величину - числовые (1-5) или
низкий-средний-высокий, незначительный-значительный-критический».</li>
</ul></li>
<li>анализ сценариев, которые моделируют разные угрозы и их
последствия.</li>
</ul></li>
<li>Когда использовать
<ul>
<li>недостаточно данных для проведения количественного анализа</li>
<li>необходимо быстро оценить риски и принять решение немедленно</li>
</ul></li>
<li>качественный анализ малоэффективен
<ul>
<li>Если у вас крупная организация с обширной инфраструктурой и
множеством разнообразных активов.</li>
<li>требуется финансовое обоснование, чтобы определить объём инвестиций
в меры безопасности.</li>
<li>мало или, наоборот, слишком много экспертов, чьё мнение важно
учесть.</li>
</ul></li>
<li>шаблон оценки
<ul>
<li><figure>
<img src="images/img_150.png" alt="img_150.png" />
<figcaption aria-hidden="true">img_150.png</figcaption>
</figure></li>
<li>использовать разные шкалы оценки, а не одну для всех</li>
</ul></li>
</ul></li>
<li>Количественный анализ
<ul>
<li><p>основывается на статистических данных и математических
методах.</p></li>
<li><figure>
<img src="images/img_151.png" alt="img_151.png" />
<figcaption aria-hidden="true">img_151.png</figcaption>
</figure></li>
<li><p>Начнём с количественных показателей рисков.</p>
<ul>
<li>Основных показателей четыре:
<ul>
<li>ALE, или Annual Loss Expectancy, — ожидаемые годовые потери, то есть
«стоимость» всех инцидентов за год.</li>
<li>SLE, или Single Loss Expectancy, — ожидаемые разовые потери, то есть
«стоимость» одного инцидента.</li>
<li>EF, или Exposure Factor, — фактор открытости перед угрозой, то есть
какой процент активов пострадает при успешной реализации угрозы.</li>
<li>ARO, или Annualized Rate of Occurrence, — среднее количество
инцидентов в год в соответствии со статистическими данными.</li>
</ul></li>
<li>формула
<ul>
<li><figure>
<img src="images/img_152.png" alt="img_152.png" />
<figcaption aria-hidden="true">img_152.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li><p>пример</p>
<pre><code>Посмотрим, как формула работает для реальной ситуации. 
  - Допустим, у организации есть сервер, на котором хранятся критически важные данные. 
  - В случае его взлома или поломки организация понесёт убытки. 
  - Нужно определить ожидаемые годовые потери (ALE). 

При этом вы знаете:
- SLE — каждый раз, когда сервер выходит из строя, убыток компании составляет 100 000 рублей.
- ARO — по статистике, выход из строя сервера происходит в среднем три раза в год.

Подставили эти данные в формулу: ALE = SLE × ARO= 100 000 * 3 = 300 000. 
Ожидаемые годовые убытки компании составят 300 000 рублей.</code></pre></li>
<li><p>Статистические методы (анализ)</p>
<ul>
<li>есть достаточный объём исторических данных об инцидентах,</li>
<li>популярные методы
<ul>
<li>Анализ тенденций, или Trend Analysis.</li>
<li>Регрессионный анализ.</li>
<li>Анализ временных рядов.</li>
<li>Метод Монте-Карло применяют, чтобы смоделировать множество возможных
исходов угроз.
<ul>
<li>способ оценки рисков с использованием случайных значений для
моделирования различных сценариев.</li>
<li>Применяя этот метод, можно многократно проводить расчёты, чтобы
определить возможные исходы и их вероятности</li>
<li>в ситуациях, где много неопределённости.</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Комбинированный анализ</p>
<ul>
<li>На практике качественный и количественный анализ часто используют
вместе.
<ul>
<li>Тогда качественный анализ применяют для первичной идентификации и
классификации рисков.</li>
<li>А для наиболее критичных угроз проводят количественный анализ</li>
</ul></li>
<li>две популярные модели:
<ul>
<li>OCTAVE — Operationally Critical Threat, Asset, and Vulnerability
Evaluation.
<ul>
<li>Оперативно-критическая оценка угроз, активов и уязвимости - Эта
модель преимущественно использует качественный анализ</li>
</ul></li>
<li>FAIR — Factor Analysis of Information Risk. Это факторный анализ
информационного риска
<ul>
<li>на количественном анализе</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="как-разработать-проект-архитектуры-безопасности-1">Как
разработать проект архитектуры безопасности</h2>
<ul>
<li>Архитектура информационной безопасности
<ul>
<li>это комплекс мер и решений, который определяет стратегию, технологии
и процессы для защиты информационных активов организации.</li>
<li>В архитектуру ИБ входят такие элементы:
<ul>
<li>механизмы контроля доступа,</li>
<li>системы мониторинга и управления угрозами,</li>
<li>меры по защите данных,</li>
<li>меры для соблюдения нормативных требований.</li>
</ul></li>
</ul></li>
<li>Архитектуру ИБ начинают разрабатывать после того, как провели анализ
угроз, уязвимостей и рисков
<ul>
<li><figure>
<img src="images/img_153.png" alt="img_153.png" />
<figcaption aria-hidden="true">img_153.png</figcaption>
</figure></li>
<li>крупных компаниях архитектуру безопасности проектирует служба
ИБ</li>
<li>задачу могут взять на себя системные архитекторы или
IT-менеджеры.</li>
<li>можно привлечь специализированные консалтинговые компании</li>
</ul></li>
<li>В разработке проекта всего четыре шага.
<ul>
<li><figure>
<img src="images/img_154.png" alt="img_154.png" />
<figcaption aria-hidden="true">img_154.png</figcaption>
</figure></li>
<li>Анализ и приоритизация угроз
<ul>
<li>Основа стратегии — это анализ и оценка рисков</li>
<li>Анализ и приоритизацию рисков проводят с помощью разных подходов —
количественного, качественного или комбинированного</li>
</ul></li>
<li>Определение пороговых значений рисков
<ul>
<li>границы, которые показывают, какой уровень риска компания готова
принять без существенного ущерба для своей деятельности.</li>
</ul></li>
<li>Формирование списка необходимых мер (roadmap)
<ul>
<li>Roadmap состоит из списка согласованных и приоритизированных
технических и организационных мер безопасности. Для каждого шага
дорожной карты указывают:
<ul>
<li>сроки реализации,</li>
<li>ответственных лиц,</li>
<li>необходимые ресурсы,</li>
<li>контрольные точки для оценки прогресса,</li>
<li>критерии успешного выполнения.</li>
</ul></li>
<li><figure>
<img src="images/img_155.png" alt="img_155.png" />
<figcaption aria-hidden="true">img_155.png</figcaption>
</figure></li>
<li>внедрение SOC
<ul>
<li>SOC, или Security Operations Center, — это централизованное
подразделение, которое занимается вопросами безопасности на
организационном и техническом уровне.</li>
<li>SOC-аналитики в работе используют особый класс ПО, который
называется SIEM (Security Information and Event Management).
<ul>
<li>Эти программы позволяют собирать и анализировать информацию о
событиях безопасности.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Мониторинг изменений
<ul>
<li>Фактически последний этап жизненного цикла стратегии — это
постоянная адаптация под изменения</li>
<li>Внедрить систему мониторинга безопасности (SIEM)</li>
<li>Использовать сканеры уязвимостей</li>
<li>Мониторить сетевую активность</li>
<li>Контролировать изменения конфигураций</li>
<li>Создать систему оповещений</li>
<li>Регулярно проводить анализ и формировать отчётность</li>
</ul></li>
</ul></li>
</ul>
<h2
id="законодательный-уровень-информационной-безопасности-1">Законодательный
уровень информационной безопасности</h2>
<ul>
<li>Законодательный уровень информационной безопасности
<ul>
<li>это совокупность правовых норм, которые определяют, какие данные в
информационных системах и как должны быть защищены.</li>
</ul></li>
<li>Конституция РФ
<ul>
<li>Статья 23 гарантирует право на личную и семейную тайну, тайну
переписки и иных видов сообщений.
<ul>
<li>Эта статья уже ограничивает доступ к персональной информации и
определяет правила обмена конфиденциальными данными.</li>
</ul></li>
<li>Статья 29 предоставляет право свободно искать, получать, передавать,
производить и распространять информацию любым законным способом</li>
</ul></li>
<li>Федеральный закон 149-ФЗ «Об информации, информационных технологиях
и о защите информации»
<ul>
<li>Определяет такие понятия, как «информация», «обладатель информации»,
«распространение информации»,
<ul>
<li>«информационная система» и многие другие.</li>
</ul></li>
<li>Вводит ключевые принципы информационной безопасности: актуальность,
доступность, целостность и конфиденциальность данных.</li>
</ul></li>
<li>Федеральный закон 152-ФЗ «О персональных данных»
<ul>
<li>Определяет основные понятия и принципы обработки персональных
данных.</li>
<li>Устанавливает обязанности оператора персональных данных и права
субъекта данных.</li>
</ul></li>
</ul>
<h3 id="работа-с-персональными-данными-1">Работа с персональными
данными</h3>
<ul>
<li>Чтобы данные оставались полезными, проверяется их корректность и
актуальность
<ul>
<li>Автоматизированная проверка данных</li>
<li>Периодическое обновление данных</li>
<li>Возможность самостоятельного обновления</li>
<li>Алгоритмы анализа и контроля</li>
</ul></li>
<li>Механизм обезличивания
<ul>
<li>Основная цель обезличивания — удалить или скрыть идентифицирующую
информацию,
<ul>
<li>чтобы конкретный человек не мог быть идентифицирован на основе
обрабатываемых данных.</li>
</ul></li>
<li>Шифрование</li>
<li>Токенизация
<ul>
<li>персональные данные меняются на уникальные токены, которые
связываются с исходными данными только в защищённой среде.</li>
</ul></li>
<li>Псевдонимизация</li>
<li>Удаление идентифицирующей информации</li>
</ul></li>
<li>Трансграничная передача персональных данных
<ul>
<li>защита персональных данных при их передаче за пределы Российской
Федерации.</li>
<li>Чтобы понять, адекватный ли уровень защиты у страны с точки зрения
152-ФЗ, нужно предпринять несколько шагов:
<ul>
<li>Проверка перечня стран с адекватным уровнем защиты</li>
<li>Оценка локального законодательства страны назначения</li>
<li>Запрос информации у иностранного получателя данных</li>
<li>Заключение договора с иностранным получателем</li>
<li>Документирование результатов</li>
</ul></li>
</ul></li>
<li>Процесс встраивания законодательных норм в архитектуры
информационной безопасности стартапа должен выглядеть так:
<ul>
<li>Классификация данных
<ul>
<li>фотографии, метаданные, рост, размер</li>
</ul></li>
<li>Получение согласия на обработку персональных данных</li>
<li>Хранение и шифрование данных</li>
<li>Обезличивание данных
<ul>
<li>обезличивания фотографий — они хранятся без прямой привязки к другой
идентифицирующей информаци</li>
</ul></li>
<li>Журналирование и контроль доступа</li>
<li>Предоставление пользователям контроля над своими данными</li>
<li>Обеспечить безопасность интеграций</li>
<li>Микросервисы для соответствия изменениям в законодательстве</li>
<li>Пройти сертификацию системы в ФСТЭК и ФСБ персональных данных</li>
</ul></li>
<li>Информирование об утечках данных
<ul>
<li>При обнаружении потенциальной утечки персональных данных система
автоматически запускает процесс информирования Роскомнадзора
<ul>
<li>и затронутых пользователей</li>
</ul></li>
</ul></li>
</ul>
<h2 id="классификация-данных-1">Классификация данных</h2>
<ul>
<li>Закон и отраслевые стандарты информационной безопасности обязывают
проводить классификацию данных.
<ul>
<li>Они устанавливают требования для обеспечения защиты данных
<ul>
<li>пример, азу классифицировали как «внутреннюю», а не
«конфиденциальную» — и её защита была недостаточной.</li>
</ul></li>
</ul></li>
<li>ISO/IEC 27001 и 27002 Международный стандарт
<ul>
<li>Публичные данные
<ul>
<li>не подлежит ограничению</li>
</ul></li>
<li>внутренние данные
<ul>
<li>информация для внутреннего использования в организации.</li>
</ul></li>
<li>конфиденциальные данные</li>
<li>имеет высокую ценность и ограничена в распространении, персональные,
финансовые</li>
<li>секретные данные
<ul>
<li>платежные данные, гос-тайна</li>
</ul></li>
</ul></li>
<li>NIST SP 800-53 и NIST SP 800-60 (стандарт США)
<ul>
<li>доступность данных
<ul>
<li>Низкое воздействие
<ul>
<li>утечка или компрометация не приведёт к потерям</li>
</ul></li>
<li>Умеренное воздействие
<ul>
<li>компрометация данных может вызвать заметные финансовые или
репутационные потери</li>
<li>личные данные без конфиденциальной инфо</li>
</ul></li>
<li>высокое воздействие
<ul>
<li>утечка данных может привести к серьёзным финансовым потерям</li>
</ul></li>
</ul></li>
</ul></li>
<li>152-ФЗ «О персональных данных»
<ul>
<li>устанавливает требования к классификации и обработке персональных
данных</li>
<li>Общедоступные персональные данные
<ul>
<li>данные, предоставленные субъектом для всеобщего доступа.</li>
</ul></li>
<li>Персональные данные
<ul>
<li>информация, относящаяся к конкретному человеку, которая требует
защиты.</li>
</ul></li>
<li>Специальные категории персональных данных
<ul>
<li>данные о расовой, национальной принадлежности, состоянии здоровья и
прочие.
<ul>
<li>Их обработка строго регулируется законом.</li>
</ul></li>
</ul></li>
</ul></li>
<li>инструменты для классификации данных
<ul>
<li>Varonis Data Security Platform
<ul>
<li>выполняет автоматизированный анализ и классификацию данных, которую
можно скорректировать вручную.</li>
</ul></li>
<li>IBM Guardium Data Protection
<ul>
<li>автоматически классифицирует данные на основе заданных политик
безопасности</li>
</ul></li>
</ul></li>
</ul>
<h3 id="классификация-данных-при-проектировании-систем-1">классификация
данных при проектировании систем</h3>
<ul>
<li>Сегментируйте сеть для изоляции важного
<ul>
<li>критически важные данные в изолированных сегментах сети</li>
</ul></li>
<li>Шифруйте данные для защиты конфиденциальности
<ul>
<li>AES — Advanced Encryption Standard. Применяется для симметричного
шифрования данных</li>
<li>RSA. Используется для безопасного обмена ключами и создания цифровых
подписей.
<ul>
<li>рекомендуется использовать ключи длиной не менее 2048 бит или
перейти на ECDH — Elliptic Curve Diffie-Hellman</li>
</ul></li>
<li>TLS — Transport Layer Security. Обеспечивает защищённые каналы связи
между клиентами и серверами для предотвращения перехвата данных</li>
</ul></li>
<li>Ограничьте привилегии для контроля доступа</li>
<li>Внедрите управление метаданными для отслеживания данных</li>
<li>Внедрите контроль доступа и видимости данных на основе
классификации</li>
</ul>
<h3 id="вызовы-и-решения-в-управлении-разными-классами-данных-1">Вызовы
и решения в управлении разными классами данных</h3>
<ul>
<li><p>Разделение данных и предотвращение утечек</p></li>
<li><p>Обеспечение совместимости и соответствия
законодательству</p></li>
<li><p>Мониторинг и адаптивная безопасность</p></li>
<li><p>Security Information and Event Management (SIEM)</p>
<ul>
<li>система управления событиями безопасности.</li>
<li>Она обеспечивает сбор, обработку, анализ и корреляцию данных,
поступающих с устройств и приложений,</li>
<li>для выявления угроз и реагирования на них в реальном времени.
<ul>
<li>SIEM-системы автоматически присваивают новый уровень классификации
данных.</li>
<li><figure>
<img src="images/img_156.png" alt="img_156.png" />
<figcaption aria-hidden="true">img_156.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul>
<h2 id="составление-проверочного-листа-1">Составление проверочного
листа</h2>
<ul>
<li>Процесс аудита информационной безопасности
<ul>
<li>Определение целей и объёма аудита
<ul>
<li>какие активы, системы и процессы необходимо проверить, исходя из
бизнес-целей и нормативных требований</li>
<li>составляется чек-лист с ключевыми областями для проверки
<ul>
<li>управлением доступом, защитой данных, безопасностью сетевой и
серверной инфраструктуры, реагированием на инциденты</li>
</ul></li>
</ul></li>
<li>Сбор данных и анализ текущего состояния
<ul>
<li>Проверяется соответствие требованиям безопасности, наличие
уязвимостей и «болевых точек» в системе.</li>
</ul></li>
<li>Ранжирование выявленных угроз и рисков
<ul>
<li>на основе собранных данных оцениваются риски.</li>
<li>расставляют приоритеты для выделения ключевых проблем</li>
</ul></li>
<li>Формирование плана улучшений
<ul>
<li>создаётся план действий по устранению уязвимостей с приоритетом</li>
</ul></li>
<li>Исполнение плана и мониторинг изменений</li>
<li>Заключение и аудит на постоянной основе
<ul>
<li>финальная проверка оценки эффективности</li>
</ul></li>
</ul></li>
</ul>
<h3 id="ключевые-разделы-it-инфраструктуры-чек-листа-1">Ключевые разделы
IT-инфраструктуры чек-листа</h3>
<ul>
<li>Чек-лист должен быть гибким
<ul>
<li>Разделите проверочный лист на отдельные модули в соответствии с
ключевыми областями безопасности
<ul>
<li>управление доступом, защита данных, сетевое оборудование</li>
</ul></li>
<li>Создавайте базовые шаблоны для разных типов инфраструктуры
(локальные сети, облака, гибридные среды)</li>
<li>Изучите возможность автоматизации с помощью GRC-систем</li>
</ul></li>
<li>GRC-системы (Governance, Risk Management, and Compliance) —
инструменты,
<ul>
<li>которые объединяют управление деятельностью компании, рисками и
соответствием требованиям.</li>
</ul></li>
<li>Управление доступом
<ul>
<li>проверка того, кто и на каких условиях может получить доступ к
важным ресурсам.
<ul>
<li>современные методы аутентификации, такие как многофакторная
аутентификация (MFA).</li>
<li>принцип минимальных привилегий</li>
<li>регулярные аудиты учётных записей с повышенными привилегиями и
выполняется</li>
<li>журналирование всех операций доступа к системам и данным</li>
</ul></li>
</ul></li>
<li>Безопасность данных
<ul>
<li>фокусируется на методах защиты данных, их классификации и
шифровании.
<ul>
<li>Существуют ли политики классификации данных и соответствуют ли
закона (ФЗ-152).</li>
<li>Как ведётся учёт персональных данных</li>
<li>Шифрование данных как при передаче по сети, БД, файловой
системы</li>
<li>сертифицированные алгоритмы шифрования AES-256 или TLS 1.3.</li>
<li>механизмы управления ключами — ротация, хранение в защищённых
модулях HSM.</li>
<li>Проводится ли регулярное резервное копирование</li>
<li>Контролирование доступа к резервным копиям</li>
<li>регулярное тестирование восстановления данных из резервных
копий.</li>
</ul></li>
</ul></li>
<li>Защита инфраструктуры
<ul>
<li>безопасность сетевой инфраструктуры, серверов, рабочих станций и,
при наличии, облачных ресурсов
<ul>
<li>Корректность настройки межсетевых экранов для фильтрации входящего и
исходящего трафика и реализована ли сегментация сети на логические
зоны</li>
<li>Использование системы обнаружения и предотвращения вторжений
(IDS/IPS) для выявления аномалий в сетевом трафике</li>
<li>Наличие на серверах и рабочих станциях антивирусных программ и
системы EDR (Endpoint Detection and Response).</li>
<li>Обновляется ли программное обеспечение своевременно</li>
<li>Осуществляется ли отключение всех неиспользуемых служб и портов</li>
</ul></li>
</ul></li>
<li>Управление инцидентами
<ul>
<li>оценка способности организации быстро выявлять инциденты
безопасности и реагировать на них
<ul>
<li>Настроена ли система мониторинга событий безопасности (SIEM)</li>
<li>автоматические оповещения об инцидента</li>
<li>детальный план реагирования на инциденты</li>
<li>регулярные учения по симуляции инцидентов</li>
<li>статистика по всем зарегистрированным инцидентам</li>
<li>Обновляются ли политики и процедуры на основе результатов
аудито</li>
</ul></li>
</ul></li>
<li>Локальная инфраструктура
<ul>
<li>Как контролируется физический доступ к серверным помещениям</li>
<li>Процессы безопасного удаления данных перед утилизацией
оборудования</li>
<li>Убедиться, что ведётся инвентаризация оборудования и контролируется
его состояние с активах компании</li>
</ul></li>
<li>Облачная инфраструктура
<ul>
<li>политики управления доступом к облачным ресурсам</li>
<li>автоматизированные инструменты безопасности от провайдера облачных
услуг</li>
<li>многофакторная аутентификация для доступа к облачным сервисам и
административным консолям.</li>
<li>Используются ли теги и политики для идентификации и управления
ресурсами в облаке.</li>
<li>Включена ли сегментация доступа к различным компонентам облачной
инфраструктуры.</li>
<li>Используются ли специальные инструменты для сканирования
конфигураций на соответствие рекомендациям безопасности.</li>
</ul></li>
<li>Мобильные устройства и удалённый доступ
<ul>
<li>доступ к корпоративным ресурсам с мобильных устройств
<ul>
<li>Используется ли система управления мобильными устройствами (MDM,
Mobile Device Management)</li>
<li>процедуры для контроля доступа к данным и для удалённого стирания
информации в случае утери устройства</li>
<li>VPN и шифрование для защиты данных при удалённом</li>
<li>мониторинг активности удалённых пользователей</li>
</ul></li>
</ul></li>
<li>шаблон чек-листа
<ul>
<li><figure>
<img src="images/img_157.png" alt="img_157.png" />
<figcaption aria-hidden="true">img_157.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h2 id="проектирование-слоя-безопасности-1">Проектирование слоя
безопасности</h2>
<h2
id="идентификация-и-аутентификация-управление-доступом-1">Идентификация
и аутентификация, управление доступом</h2>
<ul>
<li><figure>
<img src="images/img_158.png" alt="img_158.png" />
<figcaption aria-hidden="true">img_158.png</figcaption>
</figure></li>
</ul>
<h3 id="идентификация-1">Идентификация</h3>
<ul>
<li><p>процесс определения пользователя, в ходе которого система узнаёт,
кто пытается получить доступ к ресурсу</p></li>
<li><p>типовые угрозы и способы защиты:</p>
<ul>
<li><p>Подмена идентификатора (ID Spoofing)</p>
<pre><code> URL вида https://example.com/user/1234/profile позволяет злоумышленнику подставить другой ID, 
 например https://example.com/user/5678/profile, и получить доступ к чужому профилю</code></pre>
<ul>
<li>как защититься
<ul>
<li>Проверять права доступа к ресурсам, связанным с каждым
идентификатором.</li>
<li>Использовать безопасные токены вместо идентификаторов, передаваемых
через URL.</li>
<li>маскировать идентификаторы</li>
</ul></li>
</ul></li>
<li><p>Сбор информации (Information Harvesting)</p>
<ul>
<li>Как защититься:
<ul>
<li>Использовать единые и обобщённые сообщения об ошибках, чтобы не
раскрывать информацию о существовании учётной записи.</li>
<li>Ограничить публичный доступ к информации о структуре
идентификаторов</li>
</ul></li>
</ul></li>
<li><p>Атака на перехват идентификационных данных (Session
Hijacking)</p>
<ul>
<li>Как защититься:
<ul>
<li>применять флаги безопасности для куки (HttpOnly, Secure).</li>
<li>Использовать защищённые каналы передачи данных (HTTPS).</li>
</ul></li>
</ul></li>
<li><p>Подбор идентификатора (Identifier Guessing</p>
<ul>
<li>пользователь может быть зарегистрированным, и попытаться получить
данные другого пользователя подобрав идентификатор
<ul>
<li>обязательно проверка авторизации, не только аутентификацию</li>
<li>Вместо последовательных чисел система может использовать UUID</li>
<li>система должна проверять, имеет ли текущий пользователь право
доступа к запрашиваемому ресурсу.</li>
</ul></li>
</ul></li>
<li><p>Человек посередине» (Man-in-the-Middle, MITM)</p>
<ul>
<li>незащищенный Wi-Fi</li>
<li>Использовать только зашифрованные соединения (HTTPS, VPN).</li>
</ul></li>
</ul></li>
</ul>
<h3 id="аутентификация-1">Аутентификация</h3>
<ul>
<li>Аутентификация — это процесс подтверждения личности пользователя или
системы перед предоставлением доступа к ресурсу.
<ul>
<li>После идентификации система запрашивает подтверждение с помощью
пароля, одноразового кода, биометрии или других факторов.</li>
</ul></li>
<li>Факторы аутентификации
<ul>
<li>Что-то, что вы знаете (knowledge) - парольная аутентификация</li>
<li>Что-то, что у вас есть (possession). Одноразовые пароли (OTP)</li>
<li>Что-то, что вы представляете собой (inherence). Это биометрическая
аутентификация</li>
</ul></li>
<li>Трёхфакторная аутентификация (3FA) предполагает использование всех
трёх категорий факторов
<ul>
<li>аутентификации для проверки личности пользователя: knowledge,
possession и inherence.</li>
<li>два разных пароля и секретный вопрос — всё это относится к типу
«что-то, что вы знаете».</li>
<li><figure>
<img src="images/img_159.png" alt="img_159.png" />
<figcaption aria-hidden="true">img_159.png</figcaption>
</figure></li>
</ul></li>
<li>Протоколы аутентификации
<ul>
<li>OAuth 2.0
<ul>
<li>Один из наиболее часто используемых протоколов аутентификации и
авторизации.</li>
</ul></li>
<li>OpenID Connect (OIDC)
<ul>
<li>Эта надстройка над OAuth 2.0 позволяет осуществлять аутентификацию
пользователе</li>
</ul></li>
<li>SAML (Security Assertion Markup Language)
<ul>
<li>Протокол, применяемый для организации SSO между разными доменами и
приложениями</li>
</ul></li>
<li>Kerberos
<ul>
<li>Протокол аутентификации, основанный на использовании симметричных
криптографических ключей и билетной системы</li>
</ul></li>
</ul></li>
<li>Инструкция по внедрению многофакторной аутентификации
<ul>
<li>Оцените, есть ли потребность в MFA
<ul>
<li>Анализ рисков: проведите оценку уязвимостей для выявления систем и
данных, требующих дополнительной защиты</li>
<li>Определение пользователей: определите группы пользователей, которые
должны использовать MFA</li>
</ul></li>
<li>Выберите методы MFA
<ul>
<li>Комбинация факторов</li>
<li>Аппаратные токены</li>
</ul></li>
<li>Проектирование архитектуры MFA
<ul>
<li>Интеграция с существующими системами</li>
</ul></li>
<li>Реализация MFA</li>
<li>Обучение и информирование пользователей</li>
<li>Мониторинг и поддержка</li>
<li>Документация и соблюдение требований
<ul>
<li>Документирование процессов</li>
<li>Соблюдение стандартов (152 ФЗ)</li>
</ul></li>
</ul></li>
</ul>
<h3 id="авторизация-и-управление-доступом-1">Авторизация и управление
доступом</h3>
<ul>
<li><figure>
<img src="images/img_160.png" alt="img_160.png" />
<figcaption aria-hidden="true">img_160.png</figcaption>
</figure></li>
<li>В зависимости от гибкости системы и требований безопасности
<ul>
<li>доступ может предоставляться на основе роли пользователя —
role-based access control (RBAC)</li>
<li>на основе атрибутов пользователя, объекта и среды — attribute-based
access control (ABAC)
<ul>
<li>ABAC отлично подходит для крупных систем со множеством ресурсов и
сложными требованиями к управлению доступом</li>
</ul></li>
<li>в зависимости от контекста пользователя — contextual access.</li>
</ul></li>
<li>принципы для повышения безопасности своих систем и процессов
<ul>
<li>Принцип наименьших привилегий (Least Privilege)
<ul>
<li>пользователи и системы должны иметь доступ только к тем ресурсам и
функциям, которые необходимы для выполнения их задач, и не больше.</li>
</ul></li>
<li>Принцип разделения обязанностей (Separation of Duties)
<ul>
<li>задачи распределяются между разными сотрудниками, чтобы ни один
человек не контролировал весь процесс целиком</li>
</ul></li>
<li>Принцип доверия с осторожностью (Zero Trust).
<ul>
<li>Согласно этому принципу никто не считается безопасным по
умолчанию</li>
</ul></li>
<li>Принцип открытой безопасности (Security in the Open).
<ul>
<li>Разработчики должны учитывать потенциальные уязвимости в своём коде,
применять безопасные методы кодирования, тестировать ПО и сотрудничать с
экспертами по безопасности</li>
</ul></li>
</ul></li>
<li>Принцип наименьших привилегий (Least Privilege Access, LPA)
<ul>
<li><figure>
<img src="images/img_161.png" alt="img_161.png" />
<figcaption aria-hidden="true">img_161.png</figcaption>
</figure></li>
<li>Администраторы, Менеджеры, Операторы, гость</li>
<li>реализация
<ul>
<li>Определить роли и разрешения
<ul>
<li>анализ потребностей пользователей и задач</li>
</ul></li>
<li>Применить атрибутивное управление доступом (ABAC)</li>
<li>Провести регулярный аудит и пересмотр ролей</li>
<li>Внедрить временные роли
<ul>
<li>для специфических задач</li>
<li>модель доступа Just-In-Time (JIT), когда привилегии выдаются только
на короткий период времени
<ul>
<li>и автоматически отзываются по истечении срока.
<ul>
<li>администратор или разработчик инициирует запрос на доступ к
тестируемому ПО и система автоматически выдаёт
<ul>
<li>временные привилегии на срок, необходимый для выполнения конкретной
задачи, например на 24 часа.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>Настроить контекстное управление доступом</li>
</ul></li>
</ul></li>
</ul>
<h4 id="типичные-проблемы-управления-доступом-1">Типичные проблемы
управления доступом</h4>
<ul>
<li>Централизованное управление доступом и его недостатки
<ul>
<li>все компоненты системы (веб-приложения, мобильные приложения, базы
данных и API) используют один и тот же сервис для аутентификации и
авторизации пользователей</li>
<li>этот сервис становиться единой точкой отказа
<ul>
<li>Разделить обязанности
<ul>
<li>для веб-приложений используйте OAuth 2.0 и OpenID Connect,</li>
<li>а для внутренних систем — отдельный модуль аутентификации (например,
на базе Kerberos или SAML).</li>
</ul></li>
<li>Изолировать сервисы</li>
</ul></li>
</ul></li>
<li>Избыточные привилегии пользователей
<ul>
<li>Применять принцип наименьших привилегий (Least Privilege
Access)</li>
<li>Предусмотреть выдачу временных привилегий</li>
<li>Проводить периодические аудиты</li>
</ul></li>
<li>Сложности в управлении контекстным доступом
<ul>
<li>Использовать гибкие политики
<ul>
<li>При проектировании архитектуры используйте системы управления
доступом, которые поддерживают атрибутивное управление доступом (ABAC).
<ul>
<li>Это позволит создавать гибкие и динамичные политики на основе
различных атрибутов и контекстов
<ul>
<li>(например, времени суток, IP-адреса, устройства или
геолокации).</li>
</ul></li>
</ul></li>
</ul></li>
<li>Внедрить мониторинг и машинное обучение</li>
<li>Использовать простые правила
<ul>
<li>постепенно усложняйте</li>
</ul></li>
</ul></li>
<li>Проблемы интеграции
<ul>
<li>Интеграция современных протоколов (OAuth 2.0, OpenID Connect, SAML)
с уже существующими системами может быть сложной задачей</li>
<li>Тщательно проектировать схемы работы
<ul>
<li>Используйте OpenID Connect для веб-приложений и OAuth 2.0 для
доступа к API.</li>
</ul></li>
<li>Безопасно хранить и передавать токены</li>
<li>Создать многоуровневую авторизацию</li>
</ul></li>
<li>Проблемы с масштабируемостью
<ul>
<li>Организовать децентрализацию и кеширование</li>
<li>Использовать масштабируемые протоколы
<ul>
<li>Используйте протоколы, оптимизированные для распределённых систем,
такие как OAuth 2.0 и OpenID Connect</li>
</ul></li>
</ul></li>
</ul>
<h2 id="протоколирование-аудит-1">Протоколирование, аудит</h2>
<ul>
<li>проектирования системы протоколирования и аудита.
<ul>
<li>Полнота данных
<ul>
<li>Избыточность логов</li>
<li>Пропуск критических событий</li>
</ul></li>
<li>Сегментация данных
<ul>
<li>логи должны быть разделены на категории
<ul>
<li>действия пользователя, изменения статуса заявки, взаимодействие с
поддержкой.</li>
<li>Аутентификация и авторизация, Финансовые операции, Взаимодействие с
поддержкой</li>
</ul></li>
<li>Сложность сегментации, Избыточная детализация</li>
</ul></li>
<li>Централизация и автоматизация анализа
<ul>
<li>Ложные срабатывания</li>
<li>Обработка больших данных</li>
</ul></li>
<li>Безопасность
<ul>
<li>Открытые данные в логах</li>
<li>Защита логов</li>
</ul></li>
</ul></li>
</ul>
<h3 id="принципы-построения-подсистемы-аудита-1">Принципы построения
подсистемы аудита</h3>
<ul>
<li>Аудируемость
<ul>
<li>это способность системы или процесса подвергаться аудиту.</li>
<li>означает, что система спроектирована так, чтобы фиксировать все
необходимые данные и события,
<ul>
<li>что позволяет потом провести анализ и оценку её состояния.</li>
</ul></li>
</ul></li>
<li>Аудит
<ul>
<li>это процесс анализа и проверки данных и событий в системе для
определения их соответствия требованиям безопасности, стандартам и
политике организации.</li>
</ul></li>
<li>Логирование
<ul>
<li>это процесс записи информации о событиях и действиях, происходящих в
системе</li>
</ul></li>
<li>Когда нужен аудит
<ul>
<li>После инцидентов безопасности</li>
<li>Для регулярных проверок соответствия</li>
<li>При изменениях в инфраструктуре</li>
<li>Перед внедрением новых функций</li>
<li>Для периодической оценки эффективности мер безопасности</li>
</ul></li>
</ul>
<h3 id="основные-принципы-аудита-1">Основные принципы аудита</h3>
<ul>
<li><p>Полнота данных</p></li>
<li><p>Сегментация данных</p></li>
<li><p>Централизация и анализ</p></li>
<li><p>Безопасность</p></li>
<li><p>Масштабируемость</p></li>
<li><p>Автоматизация анализа</p></li>
<li><p>рекомендации</p>
<ul>
<li>Минимизация чувствительных данных в логах
<ul>
<li>нет паролей, платежей</li>
</ul></li>
<li>Сохранение логов
<ul>
<li>хранений по закону 5 лет</li>
</ul></li>
<li>Интеграция с системой управления инцидентами</li>
</ul></li>
<li><blockquote>
<p>Эффективное логирование заключается в сборе правильных данных, а не
всех данных.</p>
</blockquote></li>
</ul>
<h3 id="определение-состава-процессов-подлежащих-аудиту-1">Определение
состава процессов, подлежащих аудиту</h3>
<ul>
<li>Аутентификация и управление доступом, протоколируйте
<ul>
<li>Попытки входа</li>
<li>Изменение учетных записей</li>
<li>Смена паролей</li>
<li>Запросы на авторизацию</li>
</ul></li>
<li>Доступ к данным и ресурсам, Протоколируйте
<ul>
<li>Операции с данными
<ul>
<li>чтение, изменение и удаление критически важных данных (персональные
или финансовые).</li>
</ul></li>
<li>Доступ к конфиденциальным ресурсам
<ul>
<li>попытки доступа к системным ресурсам, с указанием пользователя,
времени и типа действия.</li>
</ul></li>
<li>Изменение конфигурации системы</li>
</ul></li>
<li>Административные действия, Протоколируйте
<ul>
<li>Изменение политик безопасности</li>
<li>Доступ к системным журналам</li>
<li>Управление привилегиями</li>
</ul></li>
<li>События безопасности и инциденты, протоколируйте
<ul>
<li>Попытки сканирования уязвимостей
<ul>
<li>все попытки сканирования сети, портов и приложений.</li>
</ul></li>
<li>Перегрузка системы</li>
<li>Обнаружение вредоносной активности
<ul>
<li>Интегрируйте с системой мониторинга антивирусов</li>
</ul></li>
</ul></li>
<li>Бизнес-транзакции и операции
<ul>
<li>Финансовые операции:</li>
<li>Изменение данных клиентов</li>
</ul></li>
</ul>
<h3 id="проектирование-структуры-данных-для-аудита-1">Проектирование
структуры данных для аудита</h3>
<ul>
<li>Как из плохих логов сделать хорошие
<ul>
<li>Структурируйте данные
<ul>
<li>единый формат JSON</li>
<li>каждая запись содержит ключевые поля, например: timestamp, event_id,
event_type, user_id, result.</li>
</ul></li>
<li>Добавьте информативность
<ul>
<li>IP-адрес, местоположение и детали действия.</li>
</ul></li>
<li>Классифицируйте события
<ul>
<li>Разделите логи на категории (например, аутентификация, доступ к
данным, ошибки).</li>
<li>фильтрация по категориям</li>
</ul></li>
<li>Учитывайте специфические требования
<ul>
<li>особенности логирования в зависимости от типа приложения</li>
<li>требования вроде ФЗ-152.</li>
</ul></li>
<li>Автоматизируйте анализ
<ul>
<li>системы мониторинга для автоматического анализа логов (например, ELK
Stack или Splunk).</li>
</ul></li>
<li>Установите политику хранения и ротации
<ul>
<li>Определите политику хранения логов (например, на 1 год для
аутентификации, 5 лет для транзакций).</li>
<li>Настройте автоматическую ротацию и архивирование логов для
предотвращения переполнения диска.</li>
</ul></li>
<li>Проведите обучение и подготовьте документацию</li>
<li>Проверяйте логи периодически</li>
</ul></li>
</ul>
<h3 id="записи-в-логах-1">Записи в логах</h3>
<ul>
<li>Ключевые элементы структуры данных для аудита
<ul>
<li><figure>
<img src="images/img_162.png" alt="img_162.png" />
<figcaption aria-hidden="true">img_162.png</figcaption>
</figure></li>
</ul></li>
<li>пример схемы JSON Schema</li>
</ul>
<pre><code>
{
  &quot;$schema&quot;: &quot;https://json-schema.org/draft/2020-12/schema&quot;,
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;timestamp&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;format&quot;: &quot;date-time&quot;
    },
    &quot;event_id&quot;: {
      &quot;type&quot;: &quot;string&quot;
    },
    &quot;user_id&quot;: {
      &quot;type&quot;: &quot;string&quot;
    },
    &quot;event_type&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;enum&quot;: [&quot;registration&quot;, &quot;login&quot;, &quot;data_access&quot;, &quot;payment&quot;, &quot;admin_action&quot;]
    },
    &quot;result&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;enum&quot;: [&quot;success&quot;, &quot;failed&quot;, &quot;rejection&quot;]
    },
    &quot;details&quot;: {
      &quot;type&quot;: &quot;object&quot;,
      &quot;additionalProperties&quot;: true
    }
  },
  &quot;required&quot;: [&quot;timestamp&quot;, &quot;event_id&quot;, &quot;user_id&quot;, &quot;event_type&quot;, &quot;result&quot;, &quot;details&quot;]
}

// Микросервис 1: сервис управления пользователями
package main

import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;time&quot;
)

type LogEntry struct {
    Timestamp string `json:&quot;timestamp&quot;`
    EventID   string `json:&quot;event_id&quot;`
    UserID    string `json:&quot;user_id&quot;`
    EventType string `json:&quot;event_type&quot;`
    Result    string `json:&quot;result&quot;`
    Details   struct {
        IPAddress string `json:&quot;ip_address&quot;`
        Location  string `json:&quot;location&quot;`
        Device    string `json:&quot;device&quot;`
        OS        string `json:&quot;os&quot;`
    } `json:&quot;details&quot;`
}

// logUserRegistration пример кода для записи лога
func logUserRegistration(userID string, result string) {
    entry := LogEntry{
        Timestamp: time.Now().Format(time.RFC3339),
        EventID:   &quot;evt_001&quot;,
        UserID:    userID,
        EventType: &quot;registration&quot;,
        Result:    result,
        Details: struct {
            IPAddress string `json:&quot;ip_address&quot;`
            Location  string `json:&quot;location&quot;`
            Device    string `json:&quot;device&quot;`
            OS        string `json:&quot;os&quot;`
        }{
            IPAddress: &quot;127.0.0.1&quot;,
            Location:  &quot;Moscow, Russia&quot;,
            Device:    &quot;Some-Phone&quot;,
            OS:        &quot;iOS XX&quot;,
        },
    }

    logJSON, err := json.Marshal(entry)
    if err != nil {
        log.Printf(&quot;Error marshaling log entry: %v&quot;, err)
        return
    }
    log.Println(string(logJSON))
}

func main() {
    logUserRegistration(&quot;user123&quot;, &quot;success&quot;)
}


// сервис обработки платежей
package main

import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;time&quot;
)

type PaymentLogEntry struct {
    Timestamp     string `json:&quot;timestamp&quot;`
    EventID       string `json:&quot;event_id&quot;`
    TransactionID string `json:&quot;transaction_id&quot;`
    UserID        string `json:&quot;user_id&quot;`
    EventType     string `json:&quot;event_type&quot;`
    Result        string `json:&quot;result&quot;`
    Details       struct {
        Amount        int    `json:&quot;amount&quot;`
        Currency      string `json:&quot;currency&quot;`
        Reason        string `json:&quot;reason&quot;`
        PaymentMethod string `json:&quot;payment_method&quot;`
    } `json:&quot;details&quot;`
}

type PaymentFailureDTO struct {
    TransactionID string
    UserID        string
    Reason        string
    Amount        int
    Currency      string
    PaymentMethod string
    EventID       string
}

func logPaymentFailure(dto PaymentFailureDTO) {
    entry := PaymentLogEntry{
        Timestamp:     time.Now().Format(time.RFC3339),
        EventID:       dto.EventID,
        TransactionID: dto.TransactionID,
        UserID:        dto.UserID,
        EventType:     &quot;payment&quot;,
        Result:        &quot;failed&quot;,
    }
    entry.Details.Amount = dto.Amount
    entry.Details.Currency = dto.Currency
    entry.Details.Reason = dto.Reason
    entry.Details.PaymentMethod = dto.PaymentMethod

    logJSON, err := json.Marshal(entry)
    if err != nil {
        log.Printf(&quot;Error marshaling JSON: %v&quot;, err)
        return
    }

    log.Println(string(logJSON))
}

func main() {
    dto := PaymentFailureDTO{
        TransactionID: &quot;trans_12345&quot;,
        UserID:        &quot;user_67890&quot;,
        Reason:        &quot;Insufficient funds&quot;,
        Amount:        5000,
        Currency:      &quot;RUB&quot;,
        PaymentMethod: &quot;credit_card&quot;,
        EventID:       &quot;evt_002&quot;,
    }

    logPaymentFailure(dto)
}

</code></pre>
<ul>
<li>в промышленной эксплуатации лог-сообщения обычно не валидируют по
схемам в целях оптимизации быстродействия и экономии ресурсов.</li>
</ul>
<h2 id="как-контролировать-целостность-данных-1">Как контролировать
целостность данных</h2>
<ul>
<li><p>в распределённых системах сложно обеспечить целостность
данных</p></li>
<li><p>Контроль целостности опирается на требования ACID — Atomicity
(атомарность), Consistency (согласованность), Isolation (изоляция),
Durability (устойчивость).</p></li>
<li><figure>
<img src="images/img_163.png" alt="img_163.png" />
<figcaption aria-hidden="true">img_163.png</figcaption>
</figure></li>
</ul>
<h3 id="двухфазный-коммит-1">Двухфазный коммит</h3>
<ul>
<li><p>Протокол двухфазного коммита (2PC) используют, когда транзакция
затрагивает несколько узлов или сервисов. Протокол гарантирует, что либо
все изменения будут зафиксированы одновременно, либо все изменения
откатятся.</p></li>
<li><p>двухфазный коммит позволяет реализовать в распределённых системах
два первых принципа ACID:</p>
<ul>
<li>атомарность — транзакция либо успешна, либо откатывается.</li>
<li>согласованность — данные остаются в корректном состоянии.</li>
</ul></li>
<li><p>Фаза 1. Подготовка — Prepare Phase</p>
<ul>
<li>запрос на все узлы (сервисы), которые участвуют в транзакции
<ul>
<li>Готовы ли вы зафиксировать транзакцию?</li>
</ul></li>
</ul></li>
<li><p>Фаза 2. Фиксация или откат — Commit or Abort Phase</p>
<ul>
<li>координатор отправляет команду commit и все участники фиксируют свои
изменения, завершая транзакцию.</li>
<li>Если хотя бы один из узлов не готов, координатор отправляет команду
abort и все изменения откатываются, возвращая данные в исходное
состояние.</li>
</ul></li>
<li><blockquote>
<p>такой подход может создать проблемы с производительностью.</p>
</blockquote></li>
<li><p>Минусы двухфазного коммита</p>
<ul>
<li>Во время выполнения двухфазного коммита ресурсы остаются
заблокированными</li>
<li>участники связаны между собой и каждый из них должен
взаимодействовать с координатором</li>
<li>Если координатор или участник «зависнет» или выйдет из строя,
процесс коммита тоже может зависнуть.
<ul>
<li>Это приведёт к блокировке всей транзакции.</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>двухфазный коммит крайне редко используют в микросервисной
архитектуре. антипаттерн</p>
</blockquote></li>
</ul>
<h3 id="eventual-consistency-1">Eventual Consistency</h3>
<ul>
<li>важно понять и принять, что не все данные должны быть немедленно
согласованы между всеми узлами хранения.
<ul>
<li>Достаточно, чтобы это произошло со временем.</li>
</ul></li>
<li>Eventual Consistency, или согласованность в конечном итоге,
<ul>
<li>это модель согласованности, при которой гарантируется,
<ul>
<li>что, если новых обновлений данных не происходит, все копии данных на
узлах системы со временем придут к одному и тому же состоянию.</li>
<li><figure>
<img src="images/img_164.png" alt="img_164.png" />
<figcaption aria-hidden="true">img_164.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul>
<h3 id="компенсационные-транзакции-в-микросервисах-1">Компенсационные
транзакции в микросервисах</h3>
<ul>
<li>В распределённых системах управление транзакциями обычно реализуют с
помощью паттерна Saga.
<ul>
<li>Он позволяет компенсировать отсутствие двухфазного коммита.</li>
</ul></li>
<li>Саги помогают реализовать принципы атомарности и согласованности
ACID
<ul>
<li>Атомарность. В традиционной модели ACID система должна дождаться
выполнения всех шагов транзакции.
<ul>
<li>А компенсирующие транзакции в микросервисной архитектуре в случае
ошибки откатывают действия на любом этапе.</li>
</ul></li>
<li>Согласованность. В результате применения компенсирующих операций
данные остаются в корректном и согласованном состоянии.</li>
</ul></li>
</ul>
<h4
id="приёмы-которые-компенсируют-отсутствие-транзакций-в-распределённых-системах-1">Приёмы,
которые компенсируют отсутствие транзакций в распределённых
системах</h4>
<ul>
<li>Event Sourcing
<ul>
<li>это подход к управлению данными, в котором изменения, происходящие в
бизнес-домене, сохраняются как события в журнале.</li>
<li>При этом новая запись всегда самая последняя, а уже записанные
события изменению не подлежат. То есть хранится не текущее
состояние,</li>
<li>а вся история изменений, на основании которых можно это состояние
при необходимости собрать.</li>
</ul></li>
<li>CQRS
<ul>
<li>разделение операций чтения и записи</li>
</ul></li>
</ul>
<h2 id="угрозы-целостности-данных-и-меры-защиты-1">Угрозы целостности
данных и меры защиты</h2>
<ul>
<li>Принцип нулевой потери данных
<ul>
<li>предполагает, что данные ни при каких обстоятельствах не должны
теряться или повреждаться.
<ul>
<li>репликация данных,</li>
<li>Event Sourcing,</li>
<li>журнал транзакций.</li>
</ul></li>
</ul></li>
<li>Мониторинг и уведомления в реальном времени
<ul>
<li>Контроль целостности — это задача не только хранения и обработки
данных, но и постоянного мониторинга.
<ul>
<li>Настроить интеграцию с SIEM. Используйте системы управления
информацией и событиями безопасности для анализа журналов и обнаружения
аномалий.
<ul>
<li>Они помогают выявлять потенциальные угрозы целостности
<ul>
<li>например, неожиданное изменение данных или отклонения в работе
сервисов</li>
</ul></li>
</ul></li>
<li>Настройте уведомления о нарушениях.</li>
</ul></li>
</ul></li>
<li>Функции SIEM
<ul>
<li>Сбор и корреляция событий.</li>
<li>Обнаружение инцидентов</li>
<li>Оповещения</li>
<li>Автоматическая реакция на атаку</li>
<li>Аудит и отчётность</li>
</ul></li>
<li>Архитектура SIEM, Чтобы интегрировать SIEM в распределённую систему,
нужно учитывать пять ключевых элементов:
<ul>
<li>Источники данных.
<ul>
<li>Это приложения, базы данных, серверы и сетевые устройства, которые
генерируют логи и события.</li>
</ul></li>
<li>Сбор и агрегация логов
<ul>
<li>собирают с помощью агентов или лог-коллекторов, таких как Filebeat,
Fluentd или Logstash.</li>
</ul></li>
<li>SIEM.
<ul>
<li>Это центральный компонент системы, в котором происходит анализ всех
собранных данны</li>
</ul></li>
<li>Панели мониторинга (Dashboards)</li>
<li>Хранилище данных
<ul>
<li><figure>
<img src="images/img_165.png" alt="img_165.png" />
<figcaption aria-hidden="true">img_165.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li>Как популярные БД обеспечивают целостность данных
<ul>
<li><figure>
<img src="images/img_166.png" alt="img_166.png" />
<figcaption aria-hidden="true">img_166.png</figcaption>
</figure></li>
</ul></li>
<li>Контроль целостности при использовании облачных сервисов
<ul>
<li>два важных инструмента для контроля целостности:
<ul>
<li>Подпись данных</li>
<li>Шифрование данных.</li>
</ul></li>
</ul></li>
<li>Управление целостностью с использованием блокчейн-технологий
<ul>
<li>Непрерывный лог изменений. Блокчейн позволяет хранить неизменяемую
последовательность транзакций.</li>
<li>Децентрализация. Использование блокчейна исключает необходимость в
центральном координаторе</li>
</ul></li>
</ul>
<h2 id="средства-защиты-доступа-к-данным-1">Средства защиты доступа к
данным</h2>
<h3
id="проектирование-защиты-от-несанкционированного-доступа-1">Проектирование
защиты от несанкционированного доступа</h3>
<ul>
<li>Основные принципы защиты данных
<ul>
<li>Классификация данных по степени секретности и важности</li>
<li>Внедрение мер сетевой безопасности, использование брандмауэров и
маршрутизаторов</li>
<li>соблюдение политик безопасности</li>
</ul></li>
<li>Шифрование
<ul>
<li>Шифрование на уровне приложения</li>
<li>Транспортное шифрование</li>
</ul></li>
<li>Мониторинг и аудит
<ul>
<li>Журналирование доступа</li>
<li>Мониторинг аномалий</li>
</ul></li>
</ul>
<h3 id="методы-защиты-данных-1">Методы защиты данных</h3>
<ul>
<li>Хранение и защита ключей
<ul>
<li>Аппаратные модули безопасности (HSM, Hardware Security Module)</li>
<li>HSM - Это физическое устройство, предназначенное для безопасного
хранения, управления и использования криптографических ключей.</li>
<li>критически важные ключи могут храниться в HSM, а менее
чувствительные данные — управляться через KMS.</li>
</ul></li>
<li>Ротация и управление ключами шифрования
<ul>
<li>Ключи шифрования
<ul>
<li>это уникальные криптографические параметры, которые используются для
защиты данных посредством их шифрования и последующей расшифровки.</li>
</ul></li>
<li>Ротация ключей шифрования заключается в регулярном изменении ключей,
которые используются для шифрования данных.</li>
<li>Реализовать ротацию ключей можно в стратегиях переключения и
миграции
<ul>
<li>Переключение (Rolling Rotation)
<ul>
<li>постепенная ротация, при которой новые данные шифруются с
использованием нового ключа,</li>
</ul></li>
<li>Миграция (Key Migration)
<ul>
<li>Все данные, зашифрованные старым ключом, немедленно
перешифровываются новым ключом</li>
</ul></li>
</ul></li>
</ul></li>
<li>Гомоморфное шифрование
<ul>
<li>метод, позволяющий выполнять вычисления над зашифрованными данными
без их предварительной расшифровки</li>
</ul></li>
<li>Токенизация
<ul>
<li>это процесс замены важных данных (например, номеров кредитных карт,
идентификационных номеров) на случайные значения или токены.</li>
<li>Токены могут храниться в хранилище, но при этом сопоставление
оригинальных данных и токенов осуществляется отдельно.</li>
<li>Безопасность: токены, в отличие от шифрованных данных, не содержат
информацию, которую можно расшифровать, что делает их более
безопасными.</li>
<li>Соответствие нормативным требованиям</li>
</ul></li>
<li>Дифференциальная приватность
<ul>
<li>это метод обработки данных, который позволяет собирать и
анализировать агрегированные данные
<ul>
<li>и при этом обеспечивает защиту конфиденциальной информации отдельных
пользователей.</li>
</ul></li>
</ul></li>
<li>Обнаружение и предотвращение утечек данных (DLP)
<ul>
<li>это набор инструментов и методик, которые используются для
обнаружения, контроля и предотвращения несанкционированного доступа,
<ul>
<li>утечки или передачи конфиденциальной информации за пределы
защищённой среды.</li>
</ul></li>
<li>DLP помогает организациям защищать данные при хранении, передаче или
обработке.</li>
<li>DLP-системы состоят из трёх компонентов
<ul>
<li>Мониторинг данных</li>
<li>Идентификация и классификация данных</li>
<li>Применение политик безопасности</li>
</ul></li>
</ul></li>
</ul>
<h2 id="как-настроить-rbac-в-kubernetes-1">Как настроить RBAC в
Kubernetes</h2>
<ul>
<li>RBAC Kubernetes используется четыре основных компонента
<ul>
<li>Role
<ul>
<li>набор разрешений, который определяет, какие действия можно выполнять
над ресурсами в определённом неймспейсе.</li>
</ul></li>
<li>ClusterRole
<ul>
<li>аналогичен Role, но применяется ко всему кластеру. Используется для
управления ресурсами,</li>
</ul></li>
<li>RoleBinding
<ul>
<li>связывает пользователя, группу или сервисный аккаунт с ролью (Role)
в конкретном неймспейсе и предоставляет разрешения, которые определены в
роли.</li>
</ul></li>
<li>ClusterRoleBinding
<ul>
<li>RoleBinding, но применяется ко всему кластеру. Связывает
пользователя, группу или сервисный аккаунт с кластерной ролью
(ClusterRole).</li>
</ul></li>
</ul></li>
</ul>
<h3 id="настройка-rbac-практика-1">Настройка RBAC: практика</h3>
<ul>
<li><p>доступ к работающему кластеру Kubernetes и инструменту командной
строки kubectl.</p></li>
<li><p>Этап 1. Подготовка окружения</p>
<ul>
<li>проверить доступ
<ul>
<li>kubectl get nodes</li>
<li>для визуального управления кластером и мониторинга ресурсов можно
использовать OpenLens</li>
</ul></li>
</ul></li>
<li><p>Этап 2. Создание Role</p>
<ul>
<li>При определении полномочий роли (role) Kubernetes оперирует глаголом
(verb) и выделяет две категории глаголов:
<ul>
<li>Для права на запись (write) — create, update, patch</li>
<li>Для права на чтение (read) — get, list, watch</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
// Создадим роль, которая разрешит выполнение только операций чтения над ресурсами pods в определённом неймспейсе (например, development):
# role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: development
  name: pod-reader
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;pods&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]

</code></pre>
<ul>
<li>применить эту роль в кластере:
<ul>
<li>kubectl apply -f role.yaml</li>
</ul></li>
<li>Теперь в неймспейсе development существует роль pod-reader,
<ul>
<li>ограничивающая действия пользователя или сервисного аккаунта
операциями чтения.</li>
</ul></li>
<li>Этап 3. Создание RoleBinding
<ul>
<li>В данном случае связываем роль pod-reader с пользователем
developer:</li>
</ul></li>
</ul>
<pre><code>
# rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: development
subjects:
- kind: User
  name: developer
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<ul>
<li>Применим RoleBinding:
<ul>
<li>kubectl apply -f rolebinding.yaml</li>
</ul></li>
<li>пример еще</li>
</ul>
<pre><code>
Пример привязки роли pod-reader к сервисному аккаунту home-operator в неймспейсе:

# rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: home-namespace
subjects:
- kind: ServiceAccount
  name: home-operator
  namespace: home-namespace
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<ul>
<li><p>Точное соответствие субъекта и роли</p>
<ul>
<li>Убедитесь, что каждый RoleBinding связывает только нужные роли с
конкретными сервисными аккаунтами или пользователями</li>
</ul></li>
<li><p>Ограничение действий в пределах одного неймспейса</p></li>
<li><p>Каждый RoleBinding должен быть нацелен на конкретный
неймспейс</p></li>
<li><p>Регулярный аудит привязок</p></li>
<li><p>Этап 4. Сетевые политики</p>
<ul>
<li>Настроим сетевую политику, которая позволит взаимодействовать подам
с метками app: front-end и role: back-end-api.</li>
</ul></li>
</ul>
<pre><code>
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
spec:
  podSelector:
    matchLabels:
      role: back-end-api
  policyTypes:
  - Ingress
  ingress:
  - from:
      - podSelector:
          matchLabels:
            app: front-end

</code></pre>
<ul>
<li><p>Теперь политика разрешает подам с меткой app: front-end
взаимодействовать с подами, у которых метка role: back-end-api</p></li>
<li><p>Этап 5. Создание ClusterRole</p>
<ul>
<li>ClusterRole позволяет управлять разрешениями на уровне всего
кластера — создадим роль, которая разрешает чтение всех подов во всех
неймспейсах</li>
</ul></li>
</ul>
<pre><code>
# clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-pod-reader
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;pods&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]

</code></pre>
<ul>
<li>применить
<ul>
<li>kubectl apply -f clusterrole.yaml</li>
</ul></li>
<li>Пример ClusterRole, которая предоставляет доступ только на чтение
для подов во всём кластере:</li>
</ul>
<pre><code>
# clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-pod-reader
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;pods&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]

</code></pre>
<ul>
<li>На что обратить внимание
<ul>
<li>Минимизация прав</li>
<li>Централизованный мониторинг</li>
</ul></li>
<li>Этап 6. Создание ClusterRoleBinding
<ul>
<li>используется ClusterRoleBinding, который связывает ClusterRole с
субъектами на уровне всего кластера</li>
<li>Свяжем ClusterRole с пользователем:</li>
</ul></li>
</ul>
<pre><code>
# clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-read-pods
subjects:
- kind: User
  name: developer
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: cluster-pod-reader
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<ul>
<li>Применим ClusterRoleBinding:
<ul>
<li>kubectl apply -f clusterrolebinding.yaml</li>
</ul></li>
<li>Теперь пользователь developer имеет права на просмотр подов во всех
неймспейсах кластера.</li>
<li>Пример манифеста ClusterRoleBinding для связи роли
cluster-pod-reader с сервисным аккаунтом infrastructure-operator:</li>
</ul>
<pre><code>
# clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-read-pods
subjects:
- kind: ServiceAccount
  name: infrastructure-operator
  namespace: kube-system
roleRef:
  kind: ClusterRole
  name: cluster-pod-reader
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<ul>
<li>На что обратить внимание
<ul>
<li>Точность привязок</li>
<li>Мониторинг использования</li>
</ul></li>
<li>Практические сценарии</li>
<li>Ограничение доступа к конфигурационным данным
<ul>
<li>Доступ необходимо разрешить только к секретам (secrets) одной группе
пользователей и в определённом неймспейсе.</li>
<li>Создадим Role и RoleBinding для этого сценария:</li>
</ul></li>
</ul>
<pre><code>
# secret-reader-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: secure-space
  name: secret-reader
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;secrets&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;]
  
  
# secret-reader-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-secrets
  namespace: secure-space
subjects:
- kind: User
  name: secure-operator
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: secret-reader
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<ul>
<li><p>Применим эти манифесты:</p>
<ul>
<li>kubectl apply -f secret-reader-role.yaml</li>
<li>kubectl apply -f secret-reader-binding.yaml</li>
</ul></li>
<li><p>Теперь secure-operator имеет доступ к секретам в неймспейсе
secure-space.</p></li>
<li><p>Ограничение доступа к конфиденциальным данным</p>
<ul>
<li>создадим Role и RoleBinding, которые предоставляют только
необходимые разрешения</li>
</ul></li>
</ul>
<pre><code>
# devops-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: development
  name: devops-role
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;pods&quot;]
  verbs: [&quot;create&quot;, &quot;delete&quot;, &quot;list&quot;]
  
# devops-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: devops-access
  namespace: development
subjects:
- kind: Group
  name: devops-group
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: devops-role
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<h2 id="как-работает-http-кеширование-1">Как работает
HTTP-кеширование</h2>
<ul>
<li><p>Долгое исполнение запроса называется высокой
латентностью</p></li>
<li><p>Кеш-промах (cache miss) - кеш есть, но еще пустой</p></li>
<li><p>для клиентского кеширования в браузере используется заголовки</p>
<ul>
<li>Cache-Control, Expires - на какой период будут кешироваться ресурсы
на стороне клиента</li>
<li>Cache-Control: private, max-age=0, no-cache, Cache-Control: private,
no-cache, must-revalidate</li>
<li><figure>
<img src="images/img_167.png" alt="img_167.png" />
<figcaption aria-hidden="true">img_167.png</figcaption>
</figure></li>
<li>no-cache - контент, требующий проверки актуальности
<ul>
<li>клиент должен уточнять запросом (If-None-Match с Etag либо
If-Modified-Since - время)</li>
</ul></li>
<li>Expires - более древняя версия в формате даты в строке
<ul>
<li>Expires: Wed, 25 Aug 2022 12:00:00 GMT</li>
<li>max-age - в секундах, проще синхронизация
<ul>
<li>если оба используются, приоритет max-age</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Не используется</p>
<ul>
<li>динамические, часто обновляемые данные</li>
<li>актуальные данные</li>
<li>редко запрашиваемые данные</li>
<li>секретная информация</li>
</ul></li>
<li><blockquote>
<p>Прибегать к кешированию просто ради внедрения модной технологии не
стоит.</p>
</blockquote></li>
</ul>
<h2 id="паттерны-кеширования-и-способы-инвалидации-кеша-1">Паттерны
кеширования и способы инвалидации кеша</h2>
<ul>
<li>паттерн Cache-Aside
<ul>
<li>Пользователь отправляет запрос на чтение данных. Приложение
проверяет кеш. Если данные найдены, происходит попадание в кеш.</li>
<li>Если данные не найдены, происходит кеш-промах и приложение
отправляет запрос к базе данных.</li>
<li>Пользователь получает ответ. Данные заносятся в кеш</li>
<li><figure>
<img src="images/img_168.png" alt="img_168.png" />
<figcaption aria-hidden="true">img_168.png</figcaption>
</figure></li>
<li>Плюсы
<ul>
<li>формат кещ-сервера может отличаться от БД, так как там результат
запроса (объединение данных, таблиц и т.д.))</li>
</ul></li>
<li>Минусы
<ul>
<li>скорость обновления - данные обновляются только при чтении</li>
<li>несогласованность с БД, используется параметр
<ul>
<li>TTL (Time to Live) — это предельный срок жизни данных в кэше.</li>
</ul></li>
</ul></li>
</ul></li>
<li>паттерн Read-Through
<ul>
<li>актуальные данные из базы данных сразу кладутся в кеш и только потом
возвращаются приложению.
<ul>
<li><figure>
<img src="images/img_169.png" alt="img_169.png" />
<figcaption aria-hidden="true">img_169.png</figcaption>
</figure></li>
</ul></li>
<li>к базе данных обращается именно кеш, а не приложение.</li>
<li>Плюсы
<ul>
<li>Меньшая сложность приложения и низкая вероятность ошибок</li>
</ul></li>
<li>Минусы
<ul>
<li>Кеш-промах при первом запросе - данных еще нет</li>
<li>Ограничения на выбор модели данных в кеше</li>
<li>Чувствительность к ошибкам</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
//псевдокод реализации
//выполняется кешем, если кеш пустой
cache.onmiss = (key) =&gt; {
  return db.get(key) //return data from the database
};

const data = cache.readThrough(key, data, ttl);

</code></pre>
<ul>
<li><blockquote>
<p>Cache-Aside, Read-Through оптимизируют только операции чтения и
подходят для приложений, где практически отсутствуют операции записи</p>
</blockquote></li>
<li>паттерн Refresh-Ahead
<ul>
<li>принудительное обновление часто используемых кешированных данных до
истечения срока их действия.
<ul>
<li><figure>
<img src="images/img_170.png" alt="img_170.png" />
<figcaption aria-hidden="true">img_170.png</figcaption>
</figure></li>
</ul></li>
<li>Плюсы
<ul>
<li>Низкая стоимость чтения данных из БД;</li>
<li>Согласованность записей кеша, к которым часто обращаются
пользователи;</li>
<li>Высокая чувствительность к задержкам.</li>
</ul></li>
<li>Минусы
<ul>
<li>Кеш должен работать без ошибок, поскольку в случае ошибки это будет
не сразу определено
<ul>
<li>и приведёт к неконсистентности данных и чтению из базы.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<pre><code>
//псевдокод реализации
setInterval(()=&gt; {
     let data = db.read(key);
     cache.set(key,data);
},10000); 

</code></pre>
<ul>
<li>паттерн Write-Through
<ul>
<li>любая операция записи всегда проходит и через кеш, и через базу
данных последовательно.</li>
<li>Механизм работы:
<ul>
<li>Приложение обновляет кеш.</li>
<li>Кеш немедленно обновляет базу данных.</li>
<li>База данных обновляется в соответствии с задачей.</li>
<li>Ответ об успешной операции возвращается клиенту.</li>
<li><figure>
<img src="images/img_171.png" alt="img_171.png" />
<figcaption aria-hidden="true">img_171.png</figcaption>
</figure></li>
</ul></li>
<li>Плюсы
<ul>
<li>Данные между кешем и базой данных всегда будут синхронизированы</li>
</ul></li>
<li>Минусы
<ul>
<li>синхронная запись в БД, долго ждать</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
// Псевдокод 
function updateData(id, data) {
  // выполняется после сохранения записи в кеше
  cache.writeThrough(id, data, cache.defaultTTL, (key, value) =&gt; {
    return db.save(key, value) // сохранение в базу
  });
}
// Сначала обновляем в бд
function updateDataAnotherWay(id, data) {
  // сначала в базе
  const record = db.findAndUpdate(id, data)
  // потом в кеше
  cache.set(customerId, record, cache.defaultTTL)
}

</code></pre>
<ul>
<li><blockquote>
<p>Обычно использует вместе Read-Through и Write-Through</p>
</blockquote></li>
<li>Паттерн Write-Behind
<ul>
<li>асинхронное обновление данных в БД</li>
<li>Механизм работы:
<ul>
<li>Приложение обновляет кеш.</li>
<li>Кеш возвращает клиенту ответ.</li>
<li>Кеш планирует асинхронную задачу на обновление базы данных.</li>
<li>База данных обновляется в соответствии с задачей.</li>
</ul></li>
</ul></li>
<li>плюсы и минусы всех подходов</li>
<li><figure>
<img src="images/img_172.png" alt="img_172.png" />
<figcaption aria-hidden="true">img_172.png</figcaption>
</figure></li>
</ul>
<pre><code>
//псевдокод реализации
function updateData(id, data) {
  await cache.set(id,data); //ждём обновления в кеше
  async db.save(id,data); //асинхронно обновляем бд
  return data;
}
 

</code></pre>
<h3 id="способы-инвалидации-кеша-1">Способы инвалидации кеша</h3>
<ul>
<li>очистка кеша
<ul>
<li>временная - по фиксированному времени жизни
<ul>
<li>прогноз погоды на 1 час</li>
</ul></li>
<li>на основе запросов -каждый раз при изменении данных
<ul>
<li>онлайн-магазин, изменение товаров при оплате</li>
</ul></li>
<li>программная - на основе условий или событий
<ul>
<li>очистка после добавления нового комментария</li>
</ul></li>
<li>по ключу - обновление некоторых данных
<ul>
<li>для определенных товаров в системе учета</li>
</ul></li>
</ul></li>
<li><figure>
<img src="images/img_173.png" alt="img_173.png" />
<figcaption aria-hidden="true">img_173.png</figcaption>
</figure></li>
</ul>
<h2 id="практика-настройка-кеширования-1">Практика: настройка
кеширования</h2>
<h3 id="реализация-cache-aside-1">Реализация Cache-Aside</h3>
<ul>
<li>при чтении запрос сначала в Кеш потом в БД</li>
<li>пример для примера возьмем тестовый API
<ul>
<li>используем nodejs, пакет npm
<ul>
<li>npm install node-cache –save</li>
<li>npm install node-fetch</li>
</ul></li>
</ul></li>
</ul>
<pre><code>
import express from &#39;express&#39;;
import fetch from &#39;node-fetch&#39;;
import NodeCache from &#39;node-cache&#39;;

// stdTTL is the default time-to-live for each cache entry
const cache = new NodeCache({ stdTTL: 300 });

// retrieve data
async function getCountries() {
 const response = await fetch(`https://restcountries.com/v3.1/all?fields=name,flags`);

 if (!response.ok) {
   throw new Error(response.statusText);
 }

 return await response.json();
}

const app = express(); 
app.get(&#39;/countries&#39;, async (req, res) =&gt; {
 try {
   // try to get the countries from cache
   let countries = cache.get(&#39;allCountries&#39;);

   // if data from cache is empty then get data from store
   if (countries == null) {
     countries = await getCountries();
     // time-to-live is set to 300 seconds. 
     cache.set(&#39;allCountries&#39;, countries, 300);
   }

   res.status(200).send(countries);
 } catch (err) {
   console.log(err);
   res.sendStatus(500);
 }
});

const port = 3000;
app.listen(port, () =&gt; {
console.log(`Server listening on http://localhost:${port}`);
});

</code></pre>
<ul>
<li>выполнить несколько запросов, первый будет долгий, следующий быстрее
(из кеша)
<ul>
<li>можно улучшить добавить Redis
<ul>
<li>создай в другой папке docker-compose.yaml:</li>
</ul>
<pre><code> services:
 redis:
   image: &#39;redis:alpine&#39;
   ports:
     - &#39;6379:6379&#39;
</code></pre>
<ul>
<li>docker-compose up -d</li>
<li>добавить npm install redis express node-fetch</li>
<li>обновить скрипт</li>
</ul>
<pre><code>import express from &#39;express&#39;;
 import fetch from &#39;node-fetch&#39;;
 import { createClient } from &#39;redis&#39;;

 const client = await createClient()
   .on(&#39;error&#39;, err =&gt; console.log(&#39;Redis Client Error&#39;, err))
   .connect();

 // извлечение данных
 async function getCountries() {

   const response = await fetch(`https://restcountries.com/v3.1/all?fields=name,flags`);

   if (!response.ok) {
     throw new Error(response.statusText);
   }

   return await response.json();
 }

 const app = express(); 
 app.get(&#39;/countries&#39;, async (req, res) =&gt; {
   try {
     // попробуем извлечь данные о странах из кеша
     let countries = null;
     try {
       // попробуем извлечь данные о странах из кеша
       countries = await client.get(&#39;countries&#39;);
     } catch (err) {
       console.log(err);
     }
     // если кеш пуст, извлекаем данные из хранилища
     if (countries == null) {
       countries = await getCountries();
       await client.set(&#39;countries&#39;, JSON.stringify(countries));
     }

     res.status(200).send(JSON.stringify(countries));
   } catch (err) {
     console.log(err);
     res.sendStatus(500);
   }
 });

 const port = 3000;
 app.listen(port, () =&gt; {
   console.log(`Server listening on http://localhost:${port}`);
 });</code></pre></li>
</ul></li>
</ul>
<h3 id="паттерн-refresh-ahead-1">Паттерн Refresh-Ahead</h3>
<ul>
<li>постоянно независимо от запросов извне, запрос в БД дял записи в
кеш</li>
</ul>
<pre><code>
 import express from &#39;express&#39;;
 import fetch from &#39;node-fetch&#39;;
 import { createClient } from &#39;redis&#39;;
 
 const client = await createClient()
   .on(&#39;error&#39;, err =&gt; console.log(&#39;Redis Client Error&#39;, err))
   .connect();
 
 // извлечение данных
 async function getCountries() {
   
   const response = await fetch(`https://restcountries.com/v3.1/all?fields=name,flags`);
 
   if (!response.ok) {
     throw new Error(response.statusText);
   }
 
   return await response.json();
 }
 
 const app = express(); 
 app.get(&#39;/countries&#39;, async (req, res) =&gt; {
   try {
     // попробуем извлечь данные о странах из кеша
     let countries = null;
     try {
       // попробуем извлечь данные о странах из кеша
       countries = await client.get(&#39;data&#39;);
     } catch (err) {
       console.log(err);
     }
     res.status(200).send(JSON.stringify(countries));
   } catch (err) {
     console.log(err);
     res.sendStatus(500);
   }
 });
 
 setInterval(async () =&gt; {
   console.log(&#39;Running a scheduled task&#39;);
   let countries = await getCountries();
   updateData(&#39;data&#39;, JSON.stringify(countries));
 }, 2000); //every 2 seconds
 
 // определение функции для обновления данных, 
 // определение приоритетности обновлений кеша 
 // и асинхронной отсрочки обновлений хранилища данных
 async function updateData(key, newData) {
   // инициируются обновления кеша
   await client.set(key, JSON.stringify(newData));
   console.log(&#39;cache updated&#39;);
 }
 
 const port = 3000;
 app.listen(port, () =&gt; {
   console.log(`Server listening on http://localhost:${port}`);
 });
 

</code></pre>
<h2 id="паттерны-backpressure-и-circuit-breaker-1">Паттерны Backpressure
и Circuit Breaker</h2>
<h3 id="метрики-нагрузки-1">Метрики нагрузки</h3>
<ul>
<li><p>Приложения с высокой нагрузкой называют высоконагруженными
(high-load) приложениями.</p></li>
<li><p>технические метриками:</p>
<ul>
<li>DAU (Daily Active Users) — количество пользователей в день. Также
часто используют метрику MAU — Monthly Active Users.</li>
<li>RPS (Requests Per Second) — количество запросов, которые сервер
приложения обрабатывает в секунду.</li>
<li>QPS (Queries Per Second) — количество запросов в секунду к базе
данных.</li>
</ul></li>
<li><blockquote>
<p>Пиковая нагрузка, как правило, превышает среднюю в два раза. При
поддержке высоконагруженных систем ориентироваться следует именно на
пиковую нагрузку.</p>
</blockquote></li>
</ul>
<h3 id="паттерны-снижения-нагрузки-1">Паттерны снижения нагрузки</h3>
<ul>
<li>суть не только сделать масштабирование, но сделать небольшое
ограничение на запросы, параллельно делать масштабирование</li>
</ul>
<h4 id="паттерн-backpressure-1">Паттерн Backpressure</h4>
<ul>
<li>Паттерн Backpressure — удобный способ ограничить давление или
противодействовать потоку данных</li>
<li>для выявление узких мест, механизмы обратного давления
<ul>
<li>важно проводить мониторинг и собирать показатели метрики</li>
<li><figure>
<img src="images/img_176.png" alt="img_176.png" />
<figcaption aria-hidden="true">img_176.png</figcaption>
</figure></li>
</ul></li>
<li>Принцип работы паттерна:
<ul>
<li>избыток запросов в очередь (Kafka)</li>
<li>канал обратной связи (feedback channel) - между потребителем и
производителем</li>
<li>механизм регулирования (flow control mechanism) - управление потоком
данных
<ul>
<li>производитель корректирует скорость или поведение</li>
</ul></li>
<li>механизм сигнализации (pressure signal mechanism) - потребитель
отправляет сигналы об обратном давлении производителю</li>
</ul></li>
<li>реализация Питон Python
<ul>
<li>используется очередь для буферизации</li>
<li>потоки для моделирования производителей и потребителей данных</li>
<li>в примере:
<ul>
<li>есть общий buffer (размер 5) для производителя и потребителя;</li>
<li>производитель генерирует случайное число и пытается поместить его в
буфер;</li>
<li>если буфер заполнен, производитель ожидает;</li>
<li>потребитель пытается использовать данные из буфера;</li>
<li>если буфер пуст, потребитель ожидает;</li>
</ul></li>
<li>потребитель «спит» случайное время, чтобы имитировать обратное
давление, то есть потребитель обрабатывает сообщения медленнее, чем их
производит производитель.</li>
</ul></li>
</ul>
<pre><code>
import queue
import threading
import time
import random

class Producer(threading.Thread):
    def __init__(self, buffer):
        super().__init__()
        self.buffer = buffer

    def run(self):
        while True:
            item = random.randint(1, 100)
            print(f&quot;Producing {item}&quot;)
            #ждем буфер
            while self.buffer.full():
                print(&quot;Buffer full, waiting...&quot;)
                time.sleep(1)
            
            self.buffer.put(item)
            time.sleep(random.random())  # Спим случайное время

class Consumer(threading.Thread):
    def __init__(self, buffer):
        super().__init__()
        self.buffer = buffer

    def run(self):
        while True:
            # Ждём, если буфер пустой
            while self.buffer.empty():
                print(&quot;Buffer empty, waiting for items...&quot;)
                time.sleep(1)
            
            item = self.buffer.get()
            print(f&quot;Consuming {item}&quot;)
            time.sleep(1 + random.random())  # спим для эмуляции backpressure

if __name__ == &quot;__main__&quot;:
    buffer = queue.Queue(maxsize=5) 

    producer = Producer(buffer)
    consumer = Consumer(buffer)

    producer.start()
    consumer.start()

    producer.join()
    consumer.join()  
    
    
  Consuming 35
Producing 53
Producing 66
Producing 90
Buffer full, waiting...
Consuming 93
Producing 25
Buffer full, waiting. 

</code></pre>
<h4 id="паттерн-circuit-breaker-1">Паттерн Circuit Breaker</h4>
<ul>
<li><p>функции:</p>
<ul>
<li>снижение использования ресурсов (CPU, Memory)</li>
<li>предотвращение ошибок в работе приложения.</li>
</ul></li>
<li><p>пример, если внешний API недоступен, то прекращаются запросы,
иначе будут бесконечные вызовы с ошибкой, что приведет к
зависанию</p></li>
<li><p>Circuit Breaker - автоматический выключатель</p>
<ul>
<li><figure>
<img src="images/img_177.png" alt="img_177.png" />
<figcaption aria-hidden="true">img_177.png</figcaption>
</figure></li>
<li><figure>
<img src="images/img_178.png" alt="img_178.png" />
<figcaption aria-hidden="true">img_178.png</figcaption>
</figure></li>
<li><figure>
<img src="images/img_179.png" alt="img_179.png" />
<figcaption aria-hidden="true">img_179.png</figcaption>
</figure></li>
<li>если сбои начинают учащаться — превышается порог, состояние
переключается на «открыто» и вызовы больше не проходят.
<ul>
<li>В этом случае можно возвращать заглушку.</li>
</ul></li>
</ul></li>
<li><blockquote>
<p>Не рекомендуется использовать Circuit Breaker для обработки обращений
к локальным частным ресурсам в приложении (например, к структуре данных
в памяти).</p>
</blockquote></li>
<li><p>Реализация паттерна Circuit Breaker</p></li>
</ul>
<pre><code>
import time

def circuit_breaker(fn, failure_count, time_threshold):
    failures = 0
    time_since_last_failure = 0
    is_closed = False **#начальное состояние, закрыт, вызовы идут**

    def wrapper(*args):
        nonlocal failures, time_since_last_failure, is_closed

        # if service is closed
        if is_closed:
            diff = time.time() * 1000 - time_since_last_failure

            # if the time since last failure has exceeded 
            # the time threshold
            # open the service
            if diff &gt; time_threshold:
                is_closed = False
            # else throw error
            else:
                print(&quot;Service unavailable&quot;)
                return

        # try running the function
        # if it passes reset the failure count
        try:
            result = fn(*args) **#вызываем удалённый сервис**
            failures = 0
            return result
        # if function throws error / fails
        # increase the failure count and 
        # time when it fails
        except Exception as error:
            failures += 1
            time_since_last_failure = time.time() * 1000
            if failures &gt;= failure_count:
                is_closed = True #открыт

            print(&quot;Error&quot;)

    return wrapper

def test_function():
    count = 0

    def inner():
        nonlocal count
        count += 1
        if count &lt; 4:
            raise Exception(&quot;failed&quot;)
        else:
            return &quot;hello&quot;

    return inner

t = test_function()
c = circuit_breaker(t, 3, 200)

c()  # &quot;Error&quot;
c()  # &quot;Error&quot;
c()  # &quot;Error&quot;

# service is closed for 200 MS
c()  # &quot;Service unavailable&quot; 
c()  # &quot;Service unavailable&quot;
c()  # &quot;Service unavailable&quot;
c()  # &quot;Service unavailable&quot;
c()  # &quot;Service unavailable&quot;

# service becomes available after 300ms
time.sleep(0.3)
print(c())  # &quot;hello&quot;

</code></pre>
<h2 id="мониторинг-и-логирование-1">Мониторинг и логирование</h2>
<ul>
<li><blockquote>
<p>Вместо того, чтобы ждать пока проблемы подымут пользователи, а в
худшем представители бизнеса, настрой мониторинг и действуй</p>
</blockquote></li>
</ul>
<h3 id="observability-1">Observability</h3>
<ul>
<li><p>это свойство системы, подразумевает, что вы можете получать
информацию о внутренних процессах</p></li>
<li><p>ключевые источники информации:</p>
<ul>
<li>мониторинг - сбор бизнесовых и инфраструктурных метрик
(metrics)</li>
<li>логирование - сбор логов (logs)</li>
<li>трейсинг - сбор трейсов внутренних вызовов</li>
</ul></li>
<li><p>преимущества</p>
<ul>
<li>Улучшение видимости и повышение безопасности системы - полное
представление о работе системы</li>
<li>Более быстрое решение проблем и повышение надёжности системы -
выявление и устранение проблем</li>
<li>Повышение быстродействия системы и распределение ресурсов -
выявление узких мест</li>
<li>Ускорение рабочего процесса и DevOps</li>
<li>Ценные бизнес-инсайты - по собранным данным можно принять
стратегические решения более обоснованно</li>
<li>Повышение удовлетворённости пользователей</li>
</ul></li>
</ul>
<h3 id="мониторинг-1">Мониторинг</h3>
<ul>
<li>виды мониторинга (лишь некоторые):
<ul>
<li>производительность</li>
<li>безопасность</li>
<li>сетевые</li>
<li>базы данных</li>
</ul></li>
<li>метрика - есть агрегированные или одиночные данные о том, как себя
чувствуют сервисы
<ul>
<li>обычно выражается одним числом, отслеживаемое в динамике</li>
<li>типы
<ul>
<li>показатели системного уровня - потребление ресурсов процессора,
диска, памяти
<ul>
<li>счетчики, задержки, индикаторы</li>
</ul></li>
<li>метрики производительности - время отклика, количество ошибок</li>
<li>бизнес-метрики - набор метрик для конкретной организации
<ul>
<li>кол-0во уникальных пользователей, возращаемость пользователей</li>
</ul></li>
</ul></li>
</ul></li>
<li>каждый показатель отслеживает только одну переменную
<ul>
<li>ее хранение и отправка должны стоить дешево</li>
</ul></li>
<li>набор показателей определяет команда DevOps, SRE-инженер и
продакт-менеджер
<ul>
<li>например, для MVP - будет что-то простое</li>
<li>для легаси разветвленная панель</li>
<li><ul>
<li>релиз - для обнаружния проблем и отката назад</li>
</ul></li>
</ul></li>
</ul>
<h4 id="этапы-мониторинга-1">Этапы мониторинга</h4>
<ul>
<li>процесс мониторинга может выглядеть по разному
<ul>
<li>в основе 4 этапов</li>
<li><figure>
<img src="images/img_180.png" alt="img_180.png" />
<figcaption aria-hidden="true">img_180.png</figcaption>
</figure></li>
<li>Этап 1. Определить, какие данные нужно собрать
<ul>
<li>подготовка, используй разные показатели</li>
</ul></li>
<li>Этап 2. Собрать данные
<ul>
<li>агенты, фреймворки, сторонне ПО - цель собрать данные в реальном
времени</li>
</ul></li>
<li>Этап 3. Отправить данные на хранение
<ul>
<li>модель push - сам отправляешь во внешнюю систему</li>
<li>модель pull - у вас кто-то забирает</li>
<li>например, хранилища influx, ClickHouse</li>
</ul></li>
<li>Этап 4. Проанализировать данные
<ul>
<li>скрипты, ИИ, ПО</li>
</ul></li>
<li>Этап 5. Сформировать отчет
<ul>
<li>есть результат анализа</li>
</ul></li>
</ul></li>
</ul>
<h4 id="основные-подходы-к-мониторингу-1">Основные подходы к
мониторингу</h4>
<ul>
<li>Методы
<ul>
<li>USE</li>
<li>Четыре золотых сигнала</li>
<li>RED</li>
</ul></li>
<li>USE
<ul>
<li>суть в том, чтобы для каждого ресурса проверять три ключевых
показателя
<ul>
<li>Utilization (утилизация) - среднее время, которое ресурс занят
работой в %</li>
<li>Saturation (насыщенность) - объем работы, которую ресурс не может
выполнить и откладывает, оценивается по длине очереди</li>
<li>Errors (ошибки) - количество ошибок</li>
</ul></li>
<li>Используется для серверов, инструментов (для Redis и подоюбного не
используется)</li>
<li>Например, для RAM (оперативная память) нужно отслеживать:</li>
</ul></li>
</ul>
<pre><code>
- Процент использования — эта метрика показывает утилизацию.
- Память SWAP — показывает насыщенность.
- Ошибки при работе RAM.

А вот пример метрик, которые помогут отслеживать производительность сервиса:
- Процент загрузки ресурсов сервера — для утилизации.
- Очередь или замедление работы из-за постепенного «переваривания запросов» — для насыщенности.
- Количество ошибок при обработке запросов.


</code></pre>
<ul>
<li>Четыре золотых сигнала от Google
<ul>
<li>Задержка - время, которое уходит на доставку запроса по сети от
отправителя к получателю</li>
<li>Трафик - показатель активности пользователей, обычно количество
HTTP-запросов в секунду</li>
<li>Ошибки - частота неудачных запросов (не только статус 500, но и 200
с некорректным контентом)</li>
<li>Насыщенность - насколько наполнена (!) система, то есть насколько ее
использует и переполнена ли она</li>
<li>Используется для API</li>
<li><figure>
<img src="images/img_181.png" alt="img_181.png" />
<figcaption aria-hidden="true">img_181.png</figcaption>
</figure></li>
</ul></li>
<li>RED
<ul>
<li>Requests Rate - Errors - Duration
<ul>
<li>в основном мониторинг endpoints, то есть HTTP-трафика</li>
<li>оценка производительности ввода-вывода</li>
</ul></li>
<li>Requests Rate
<ul>
<li>частота запросов, оценка пропускной способности</li>
</ul></li>
<li>Errors
<ul>
<li>количество неудачных запросов в секунду</li>
</ul></li>
<li>Duration
<ul>
<li>количество времени на выполнение одного запроса</li>
<li>обычно используют для этого трассировку
<ul>
<li>Jaeger - инструмент трассировки</li>
</ul></li>
</ul></li>
<li>Используется
<ul>
<li>веб-сервисы, запросы к БД, очереди</li>
<li>сервисы, управляемы запросами</li>
</ul></li>
<li>Не подходит для потоковых и пакетных обработок</li>
</ul></li>
</ul>
<h3 id="логирование-1">Логирование</h3>
<ul>
<li>это запись в хранилище, которая содержит информацию о состоянии в
корректный момент времени
<ul>
<li>фиксация состояния системы с течением времени</li>
<li>источник информации для мониторинга</li>
</ul></li>
<li>уровни
<ul>
<li>Fatal - отказ сервиса или оборудования</li>
<li>Error - ошибочные состояния (Пользователь заблокирован)</li>
<li>Warn - состояние близкое к нестандартному поведению систему
(неправильно введен пароль)</li>
<li>Info - штатное поведение (Данные загружены)</li>
<li>Debug - для отладки, чтобы не засорять логи лишней информацией</li>
<li>Trace - отладка в тестовом окружении</li>
</ul></li>
<li>хранить не более месяца</li>
</ul>
<h2
id="сбор-и-визуализация-метрик-с-помощью-prometheus-и-grafana-1">Сбор и
визуализация метрик с помощью Prometheus и Grafana</h2>
<ul>
<li>пример на RED-методе - как самый распространенный</li>
</ul>
<h3 id="prometheus-1">Prometheus</h3>
<ul>
<li><p>это система мониторинга и оповещения с открытым исходным кодом,
на Goland с языком PromQl</p></li>
<li><p>схематично</p>
<ul>
<li>HTTP-сервер для обработки API</li>
<li>Time-Series БД (TSDB), многомерная временных рядов</li>
<li>компонент который собирает метрики с агентов по модели pull</li>
<li>агенты-экспортеры которые стоят на сервисах</li>
<li><figure>
<img src="images/img_182.png" alt="img_182.png" />
<figcaption aria-hidden="true">img_182.png</figcaption>
</figure></li>
</ul></li>
<li><p>Prometheus работает только с агрегированными метриками, а не с
текстовыми сырыми</p></li>
<li><p>модель данных ключ-значение</p>
<ul>
<li>ключ какая метрика</li>
<li>значение число, которое отражает измеренную величину за определенный
период времени</li>
</ul></li>
</ul>
<pre><code>
#Формат метрик

metric_name{label1=&lt;label1&gt;, ..., labelN=&lt;labelN&gt;} metric_value
up{instance=&quot;localhost:8000&quot;, job=&quot;sample&quot;} 1 #sample поднялся

</code></pre>
<ul>
<li>к метрике добавляют метки
<ul>
<li>Основная метрика http_request_total
<ul>
<li>метки method=GET, status=200</li>
</ul></li>
</ul></li>
<li>основным инструментом визуализации является Grafana
<ul>
<li>при этом собственные средства менее удобные</li>
<li><figure>
<img src="images/img_183.png" alt="img_183.png" />
<figcaption aria-hidden="true">img_183.png</figcaption>
</figure></li>
</ul></li>
<li>показатели
<ul>
<li>счетчик</li>
<li>индикатор
<ul>
<li>текущее состояние</li>
</ul></li>
<li>гистограмма
<ul>
<li>группировка в сегменты</li>
</ul></li>
<li>сводка
<ul>
<li>похож на гистограмму, но показывает процент наблюдений для заданного
значения</li>
</ul></li>
</ul></li>
</ul>
<h4 id="развёртывание-prometheus-1">Развёртывание Prometheus</h4>
<ul>
<li>докер дял запуска</li>
</ul>
<pre><code>
version: &quot;3&quot;

services:
  prometheus:
    image: prom/prometheus
    ports:
      - target: 9090
        published: 9090
    volumes:
      - type: bind
        source: ./prometheus.yml
        target: /etc/prometheus/prometheus.yml 

</code></pre>
<ul>
<li>рядом файл конфигурации prometheus.yml</li>
</ul>
<pre><code>
global:
  scrape_interval: 15s
scrape_configs:
  - job_name: &quot;prometheus&quot;
    scrape_interval: 5s
    static_configs:
      - targets: [&quot;localhost:9090&quot;]

</code></pre>
<ul>
<li>запуск docker-compose up</li>
<li>веб http://localhost:9090/metrics</li>
<li>источник метрик
<ul>
<li>http://localhost:9090/targets?search=</li>
</ul></li>
<li>для добавления мониторинга добавить scrape в .yml</li>
</ul>
<pre><code>
global:
  scrape_interval: 15s
scrape_configs:
  - job_name: &quot;prometheus&quot;
    scrape_interval: 5s
    static_configs:
      - targets: [&quot;localhost:9090&quot;]
  - job_name: &quot;app&quot;
    scrape_interval: 10s
    static_configs:

</code></pre>
<ul>
<li>перезапустить докер</li>
<li>сервис появиться по http://localhost:9090/targets?search=</li>
</ul>
<h3 id="grafana-1">Grafana</h3>
<ul>
<li>инструмент с открытым исходным кодом, со своей собственной базой
данных timeseries
<ul>
<li>по факту интерфейс к популярным источникам
<ul>
<li>Prometheus</li>
<li>InfluxDb, Graphite, ElasticSearch</li>
</ul></li>
</ul></li>
<li>Основные элементы интерфейса Grafana
<ul>
<li>Панель — элемент отображения выбранных параметров</li>
<li>Дашборд — это набор отдельных панелей, размещённых в сетке с набором
переменных</li>
</ul></li>
</ul>
<h4 id="установка-grafana-1">Установка Grafana</h4>
<ul>
<li>docker-compose</li>
</ul>
<pre><code>
 grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - 3000:3000
    volumes:
      - grafana_data:/var/lib/grafana


</code></pre>
<ul>
<li>Откройте <a href="http://localhost:3000/">http://localhost:3000</a>
admin/admin.
<ul>
<li>Добавьте Prometheus: Connections→ Add new connection → «Prometheus»
в строке поиска.</li>
</ul></li>
<li>В настройках напишите ссылку на сервер с метриками
http://prometheus:9090. Сохраните (кнопка внизу).</li>
<li>Добавьте новый дашборд. И нажмите Create dashboard.</li>
<li>Добавьте метрики, нажав Add visualization. Первой предлагаем
визуализировать Requests.</li>
<li>В самом простом варианте ничего не меняйте, кроме заполнения запроса
снизу. Заполните название метрики http_request_duration_count и нажмите
Run queries. Нарисуется график, дальше исправьте Title в Panel Options и
нажмите Save.</li>
<li>Добавьте ещё одну визуализацию Errors.</li>
<li>Заполните название метрики http_request_duration_count и label = 500
(ошибочные запросы) и нажмите Run queries. Нарисуется график, дальше
исправьте Title в Panel Options и нажмите Save.
<ul>
<li>Проделайте то же и с Durations.</li>
</ul></li>
<li>Заполните название метрики http_request_duration_bucket, в функциях
агрегации выберите Avg by (средняя) по метке le (время меньше, чем из
наших синтетических метрик) и нажмите Run queries.
<ul>
<li>Нарисуется график, дальше исправьте Title в Panel Options и нажмите
Save. По итогу у вас получится вот такой вариант RED.</li>
</ul></li>
</ul>
<h2
id="elk.-создание-и-настройка-индексов-c-помощью-elasticsearch-1">ELK.
Создание и настройка индексов c помощью Elasticsearch</h2>
<ul>
<li>ELK — это аббревиатура от ElasticSearch, Logstash и Kibana.</li>
<li>Вместе с Beats они составляют набор инструментов для извлечения,
поиска, анализа и визуализации данных.</li>
<li>Их ещё называют «стек ELK» или «стек Elastic».
<ul>
<li><figure>
<img src="images/img_184.png" alt="img_184.png" />
<figcaption aria-hidden="true">img_184.png</figcaption>
</figure></li>
</ul></li>
<li>Filebeat передаёт данные в Logstach — конвейер данных.
<ul>
<li>Logstach передаёт данные в Elasticsearch — базу данных.
<ul>
<li>Elasticsearch обменивается данными с Kibana, инструментом для
визуализации.</li>
</ul></li>
</ul></li>
<li>Logstash — это серверный конвейер обработки данных.
<ul>
<li>Он собирает входные данные и отправляет их в Elasticsearch.</li>
<li>Программа собирает данные из разных источников. Чаще всего
используют Beats.</li>
</ul></li>
<li>Elasticsearch — это документоориентированная распределённая база
данных NoSQL.
<ul>
<li>OpenSearch - аналог то Amazon, популярен в РФ</li>
</ul></li>
<li>Kibana — это инструмент, который используют для визуализации
документов Elasticsearch. О
<ul>
<li><figure>
<img src="images/img_185.png" alt="img_185.png" />
<figcaption aria-hidden="true">img_185.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="как-работает-elasticsearch-1">Как работает Elasticsearch</h3>
<ul>
<li>сопоставления с реляционными
<ul>
<li>индекс вместо БД (сердце)</li>
<li>тип(Mapping) - вместо таблицы</li>
<li>поле в документе вместо колонки</li>
<li>документ вместо таблицы</li>
<li>пример</li>
</ul></li>
</ul>
<pre><code>
{
  &quot;_index&quot;: &quot;index-2024.06.06&quot;, 
  &quot;_type&quot;: &quot;_doc&quot;,
  &quot;_id&quot;: &quot;yvNZcWwBygdfsdsdss&quot;,
  &quot;_version&quot;: 1,
  &quot;_score&quot;: null,
  &quot;_source&quot;: {
        &quot;user_uuids&quot;: [
          &quot;dae7f01c-4c98-db35-a643-bfbb8fcf40f0&quot;,
          &quot;db6e3718-cf2f-4ae0-8681-529cb75be9a6&quot;
        ]
    }
}

</code></pre>
<ul>
<li>По умолчанию Elasticsearch индексирует все данные в каждом поле
<ul>
<li>каждое поле имеет специальную оптимизированную структуру данных</li>
</ul></li>
<li>типы полей
<ul>
<li>Текстовое - две настройки
<ul>
<li>полный текст - для аналитических задач (поиск в корпоративной
системе знаний)</li>
<li>по ключевым словам - найти совпадения по задачам в конкретных
очередях</li>
</ul></li>
<li>Числовое
<ul>
<li>integer, long, float, double</li>
</ul></li>
<li>Дата
<ul>
<li>поддержка запросов диапазонов дат, арифметики дат, агрегации
дат</li>
</ul></li>
<li>Геопозиция
<ul>
<li>точки, фигуры, границы</li>
</ul></li>
</ul></li>
<li>шардирование
<ul>
<li>по умолчанию 1 экземпляр шарды
<ul>
<li>index.number_of_shards: 1</li>
</ul></li>
<li>Рекомендуем держать размер сегментов в пределах 10–50 ГБ.
<ul>
<li>выше затруднит восстановление, нагрузка на ЦПУ и память</li>
</ul></li>
<li>текущий размер
<ul>
<li>GET
_cat/shards?v=true&amp;h=index,prirep,shard,store&amp;s=prirep,store&amp;bytes=gb</li>
</ul></li>
</ul></li>
</ul>
<h4 id="рекомендации-по-работе-с-индексами-1">Рекомендации по работе с
индексами</h4>
<ul>
<li><p>Удаляйте индексы, а не отдельные документы</p>
<ul>
<li>при удалении документа он помечается удаленным, но остается
физически, удаление будет при следубщем слиянии</li>
</ul></li>
<li><p>распределяйте шарды по нодам</p></li>
<li><p>явно настраивайте маппинг</p>
<ul>
<li>Используйте статическое сопоставление вместо динамического, чтобы
избежать создания ненужных полей.</li>
</ul></li>
<li><p>используйте политику управления индексами</p></li>
<li><p>ILM</p>
<ul>
<li>политика управления индексами — Index Lifecycle Management</li>
</ul></li>
<li><p>этапы жизненного цикла индекса ILM</p>
<ul>
<li>создание
<ul>
<li>устанавливается начальный набор параметров конфигурации
<ul>
<li>количество сегментов, реплик, и сопоставление</li>
</ul></li>
</ul></li>
<li>ролловер
<ul>
<li>при добавлении данных увеличивается размер индекса</li>
<li>при достижении максимального размера, запускается ролловер</li>
<li>создается новый индекс и индексация новых данных</li>
<li>можно выставить плитку для ролловеров</li>
</ul></li>
<li>хранение
<ul>
<li>срок хранения индексов, перемещение на дешевый уровень (SSD -&gt;
HDD)</li>
</ul></li>
<li>удаление
<ul>
<li>удаление истекших, либо переставших соответствовать критериям</li>
</ul></li>
</ul></li>
<li><p>рекомендации</p>
<ul>
<li>выберите анализаторы и токенизаторы
<ul>
<li>для предварительной обработки текстовых полей во время индексации и
поиска</li>
</ul></li>
<li>регулируйте интервал обновления индекса
<ul>
<li>при массовой загрузке лучше отключать обновление на время, потом
включить</li>
</ul></li>
</ul></li>
</ul>
<h4 id="практика-настройте-elasticsearch-logstash-и-kibana-1">Практика:
настройте Elasticsearch, Logstash и Kibana</h4>
<ul>
<li>Для логирования важны:
<ul>
<li>скорость поиска,</li>
<li>скорость индексации логов,</li>
<li>стабильность поискового движка.</li>
</ul></li>
<li>целевая архитектура
<ul>
<li><figure>
<img src="images/img_186.png" alt="img_186.png" />
<figcaption aria-hidden="true">img_186.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h2 id="трейсинг-1">Трейсинг</h2>
<ul>
<li>наблюдаемость архитектуры из 3-х ключевых
<ul>
<li>мониторинг</li>
<li>логирование</li>
<li>трейсинг</li>
<li><figure>
<img src="images/img_187.png" alt="img_187.png" />
<figcaption aria-hidden="true">img_187.png</figcaption>
</figure></li>
</ul></li>
<li>логирование все и вся дорого</li>
<li>трейсинг начинается с точки входа и запускается для запроса, имеет
уникальный идентификатор
<ul>
<li>передается от сервиса к сервису обрастая информацией</li>
<li>получается список вызовов в виде дерева</li>
</ul></li>
</ul>
<h3 id="opentelemetry-1">OpenTelemetry</h3>
<ul>
<li><p>OpenTelemetry (OTel) - платформа наблюдения, со сбором,
обработкой и экспортом телеметрических данных-сигналов</p>
<ul>
<li>по факту отраслевой стандарт</li>
</ul></li>
<li><p>в приложение (в код) в страивается sdk OTel и передает сигналы в
приемник по HTTP, gRPC</p></li>
<li><p>Коллектор обрабатывает, отфильтровывает, агрегирует телеметрию и
отправляет в хранилище и в визуал</p>
<ul>
<li><figure>
<img src="images/img_188.png" alt="img_188.png" />
<figcaption aria-hidden="true">img_188.png</figcaption>
</figure></li>
</ul></li>
<li><p>контекст операции</p>
<ul>
<li>статическая информация (resource)
<ul>
<li>название ноды, либо название окружения</li>
</ul></li>
<li>динамическая информация
<ul>
<li>идентификатор эндпоинта</li>
</ul></li>
</ul></li>
<li><p>основные атрибуты контекста</p>
<ul>
<li>идентификатор операции - trace_id</li>
<li>идентификатор подзапроса - span_id
<ul>
<li>каждый подзапрос со своим униклаьным идентификатором span_id</li>
<li><figure>
<img src="images/img_189.png" alt="img_189.png" />
<figcaption aria-hidden="true">img_189.png</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li><p>Jaeger</p>
<ul>
<li>популярный инструмент трейсинга и визуализации трассировок в
распределенных сисетмах</li>
</ul></li>
<li><p>Реализация трейсинга, пример</p>
<ul>
<li>три сервиса</li>
<li><figure>
<img src="images/img_190.png" alt="img_190.png" />
<figcaption aria-hidden="true">img_190.png</figcaption>
</figure></li>
</ul></li>
<li><p>Jaeger docker - поставляется с “all-in-one”</p>
<ul>
<li>All-in-one — это исполняемый файл, предназначенный для быстрого
локального тестирования, который запускает
<ul>
<li>Jaeger UI, коллектор, запрос и агент, используя компонент хранения в
оперативной памяти.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="применение-мониторинга-логов-кеша-1">Применение мониторинга,
логов, кеша</h2>
<ul>
<li>Анализ архитектурного ландшафта
<ul>
<li>анализа текущего состояния системы как целого:</li>
<li>как взаимодействуют компоненты,</li>
<li>где проходят основные бизнес-потоки, какие элементы являются
критичными.</li>
<li>На этом этапе важно не искать “плохой код”, а выявлять структурные
слабые места:
<ul>
<li>отсутствие ответственности за состояние,</li>
<li>перегруженные компоненты,</li>
<li>хрупкие связи,</li>
<li>неуправляемый рост нагрузки.</li>
</ul></li>
<li>Результат этапа — понимание, почему система деградирует при росте, а
не просто где она “тормозит”.</li>
</ul></li>
<li>Выявление проблем и приоритизация
<ul>
<li>формируется список проблем, каждая из которых оценивается:
<ul>
<li>по влиянию на бизнес,</li>
<li>по масштабу риска,</li>
<li>по системности (корень проблемы или симптом).</li>
</ul></li>
<li>На основе этого выстраивается приоритетный план изменений, где в
первую очередь решаются проблемы, влияющие на деньги и устойчивость, а
не косметические улучшения.</li>
</ul></li>
<li>План изменений и горизонт планирования
<ul>
<li>Архитектурные изменения планируются не точечно, а с горизонтом —
например, 6 месяцев.</li>
<li>Формируется целевое состояние системы:
<ul>
<li>какие компоненты появятся или будут выделены,</li>
<li>какие связи будут изменены,</li>
<li>какие проблемы перестанут существовать как класс.</li>
</ul></li>
</ul></li>
<li>Мониторинг как количественная основа управления
<ul>
<li>Мониторинг рассматривается как инструмент измерения состояния
системы во времени.</li>
<li>Он отвечает на вопросы:
<ul>
<li>сколько запросов,</li>
<li>сколько ошибок,</li>
<li>какая нагрузка,</li>
<li>где начинается насыщение ресурсов.</li>
</ul></li>
</ul></li>
<li>Логирование как фиксация локального поведения
<ul>
<li>Логирование фиксирует, что происходит внутри конкретного сервиса на
короткой дистанции времени.</li>
<li>Логи — это последовательная запись фактов:
<ul>
<li>INFO — штатное поведение,</li>
<li>WARN — признаки потенциальной деградации,</li>
<li>ERROR / FATAL — сбои и отказы.</li>
</ul></li>
<li>Логи позволяют быстро восстановить контекст ошибки без пересказов со
стороны пользователей.</li>
</ul></li>
<li>Трейсинг как сквозное представление бизнес-операции
<ul>
<li>Трейсинг поднимается уровнем выше логов и описывает одну
бизнес-операцию как единую сущность, проходящую через несколько
сервисов.</li>
<li>Он показывает:
<ul>
<li>где операция началась,</li>
<li>через какие системы прошла,</li>
<li>где замедлилась или остановилась.</li>
</ul></li>
</ul></li>
<li>Кеширование как инструмент производительности
<ul>
<li>Кеширование используется не как “модная технология”, а как
целенаправленный инструмент ускорения чтения.</li>
<li>Оно снижает нагрузку на базы данных и уменьшает латентность для
часто запрашиваемых и тяжёлых операций,
<ul>
<li>при этом требует аккуратной стратегии инвалидации для сохранения
корректности данных.</li>
</ul></li>
</ul></li>
</ul>
<h1 id="спринт-7-1">Спринт 7</h1>
<h2 id="введение-в-искусственный-интеллект-ai-1">Введение в
искусственный интеллект (AI)</h2>
<ul>
<li>ключевая технология
<ul>
<li>Natural Language Processing - обработка естественного языка</li>
</ul></li>
</ul>
<h3 id="искусственный-интеллект-1">Искусственный интеллект</h3>
<ul>
<li>технология, реализованная в информационных системах и имитирующая
человеческий интеллект с помощью методов машинного обучения</li>
<li>методы машинного обучения
<ul>
<li>AI технологии</li>
<li>наука о данных data science DS - извлечение полезной информации из
данных</li>
</ul></li>
</ul>
<h3 id="nlp-1">NLP</h3>
<ul>
<li>обработка естественного языка - класс задач по распознаванию,
генерации, обработке голоса и письменной речи
<ul>
<li>Алиса, Siri, Alexa, Google Assistant</li>
</ul></li>
<li>основные аспекты
<ul>
<li>токенизация
<ul>
<li>декомпозиция текста на отдельные слова, фразы или предложения,
которые называются токенами
<ul>
<li>пример, Исходный: «Мне понравился этот телефон. Очень хорошее
качество звука!»
<ul>
<li>После токенизации: [“Мне”, “понравился”, “этот”, “телефон”, “.”,
“Очень”, “хорошее”, “качество”, “звука”, “!”]</li>
</ul></li>
</ul></li>
</ul></li>
<li>стоп-слова
<ul>
<li>часто встречающиеся знаки и слова, такие как “и”, “в”, “на”,
“этот”,</li>
<li>не несут полезной информации для анализа.</li>
<li>часто удаляются, чтобы сократить объем данных и сосредоточиться на
значимых словах
<ul>
<li>пример, Исходный: «Мне понравился этот телефон. Очень хорошее
качество звука!»
<ul>
<li>После удаления стоп-слов: [“понравился”, “телефон”, “.”, “хорошее”,
“качество”, “звука”, “!”]</li>
</ul></li>
</ul></li>
</ul></li>
<li>лемматизация и стемминг
<ul>
<li>методы нормализации</li>
<li>Леммитизация приводит слово к его базовой (лемматической) форме, то
есть преобразует слова в исходные формы</li>
<li>Стемминг находит основу слова, убирая приставки, окончания
<ul>
<li>пример, Исходный: «Мне понравился этот телефон. Очень хорошее
качество звука!»
<ul>
<li>Лемматизация: «понравился» -&gt; «нравиться», «звука» -&gt;
«звук».</li>
<li>Стемминг: «понравился» -&gt; «нрав», «звука» -&gt; «звук».</li>
<li>После лемматизации и стемминга: [“нравиться”, “нрав”, “телефон”,
“.”, “хороший”, “качество”, “звук”, “!”]</li>
</ul></li>
</ul></li>
</ul></li>
<li>мешок слов
<ul>
<li>bag of words - сложенный в массив набор всех токенов.</li>
<li>Каждый токен заноситься в общий словарь, и каждому присваивается
число, которое отражает, сколько как встречается
<ul>
<li>пример, Исходный: «Мне понравился этот телефон. Очень хорошее
качество звука!»
<ul>
<li>Мешок-слов: [“нравиться”: 1, “телефон”: 1, “качество”: 1, “звук”: 1,
“хороший”: 1]</li>
</ul></li>
</ul></li>
</ul></li>
<li>TF-IDF
<ul>
<li>term frequency-inverse document frequency - числовой показатель,
который оценивает важность слов во всем тексте</li>
<li>похож на мешок слов, но тут используется более сложный расчет,
показывающий “важность” слов в документе
<ul>
<li>пример,
<ul>
<li>Слово «телефон» может встречаться во многих отзывах, поэтому его IDF
будет низким, так как оно не уникально для конкретного отзыва.</li>
<li>Слово «звук» может встречаться реже, что делает его более важным для
текущего документа, если оно встречается в этом отзыве.</li>
</ul></li>
</ul></li>
</ul></li>
<li>распознавание намерений
<ul>
<li>метод определения цели или намерения пользования на основе текста с
использованием машинного обучения
<ul>
<li>пример
<ul>
<li>Исходный отзыв: «Мне понравился этот телефон. Очень хорошее качество
звука!»</li>
<li>Распознавание намерений: Определяет, что намерение пользователя
<ul>
<li>— «положительная оценка качества звука».</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="работа-с-данными-как-основа-машинного-обучения-ml-1">Работа с
данными как основа машинного обучения (ML)</h2>
<ul>
<li>обучение модели требует много ресурса</li>
</ul>
<figure>
<img src="images/img_191.png" alt="img_191.png" />
<figcaption aria-hidden="true">img_191.png</figcaption>
</figure>
<ul>
<li>Шаг 1. Формирование бизнес-требований и технологического стека
<ul>
<li>критерии успеха</li>
<li>функциональные требования</li>
<li>технологии</li>
<li>ограничения</li>
<li>основные функции</li>
</ul></li>
<li>Шаг 2. Сбор данных
<ul>
<li>хранение в БД, скорее всего неструктурированных (Mongo,
ElasticSearch)</li>
</ul></li>
<li>Шаг 3. Подготовка данных
<ul>
<li>автоматизация очистки, анализа и моделирования данных</li>
<li>результат набор дата сетов - для анализа и обучения моделей
машинного обучения</li>
<li>пример датасета</li>
</ul></li>
</ul>
<pre><code>
customer_id,product_id,purchase_date,units_sold,price_per_unit,season,previous_purchases,promotion_applied
22,147,2024-02-26,7,287,spring,3,0
47,125,2024-08-10,2,62,winter,10,0
30,106,2024-03-06,2,147,spring,10,0
4,139,2024-01-13,2,77,spring,10,0
36,132,2024-01-17,4,265,winter,9,0
6,129,2024-01-08,8,273,spring,10,1
50,110,2024-04-16,1,167,winter,3,0
35,127,2024-04-25,8,256,spring,1,0


</code></pre>
<ul>
<li>инструменты на этом этапе
<ul>
<li>Python и R — основные языки для обработки и подготовки данных.
<ul>
<li>библиотеки
<ul>
<li>R - Pandas и NumPy или Tidyvers - очистка и создание новых
признаков</li>
<li>Python - Scikit-learn
<ul>
<li>One-Hot Encoding, Label Encoding, StandardScaler (для стандартизации
данных) и SimpleImputer (для заполнения пропусков).</li>
</ul></li>
</ul></li>
<li>Apache Spark - если данные велики для обработки в памяти,
распределение по кластерам</li>
<li>Excel или Google Sheets - для небольших задачи очистки</li>
<li>Trifacta инструмент для очистки данных</li>
</ul></li>
</ul></li>
<li>Шаг 4. Анализ данных
<ul>
<li>с этого этапа процесс называется data mining</li>
<li>исследование анализа данных для выявления паттернов и трендов</li>
<li>Python библиотеки Pandas, NumPy и SciPy используются для выполнения
статистических расчётов,
<ul>
<li>а Matplotlib и Seaborn — для визуализации данных.</li>
</ul></li>
<li>Tableau и Power BI. Инструменты для визуализации данных</li>
<li>D3.js. Для более сложных и интерактивных визуализаций данных</li>
</ul></li>
<li>Шаг 5. Моделирование
<ul>
<li>на этом этапе создание, обучение, тестирование, выбор модели</li>
<li>формирование признаков модели на основе целевых признаков</li>
<li>Для оценки различные метрики, такие как точность (accuracy),
precision, recall, F1-score, RMSE</li>
<li>софт на этом этапе
<ul>
<li>Python с библиотеками Scikit-learn, TensorFlow, Keras и
PyTorch.</li>
<li>Hyperopt, Optuna — библиотеки для автоматической настройки
гиперпараметров моделей с использованием методов оптимизации, т</li>
</ul></li>
</ul></li>
<li>Шаг 6. Оценка модели и решения</li>
<li>Шаг 7. Принятие решений</li>
<li>Шаг 8. Мониторинг
<ul>
<li>софт на этом этапе
<ul>
<li>Prometheus и Grafana</li>
<li>Apache Airflow</li>
</ul></li>
</ul></li>
</ul>
<h3 id="crisp-dm-1">CRISP-DM</h3>
<ul>
<li>CRISP-DM - межотраслевой стандартный процесс исследования данных,
который особенно используется в моделях исследования данных, в частности
data mining.</li>
<li>определяется модель жизненного цикла исследования данных
<ul>
<li><figure>
<img src="images/img_192.png" alt="img_192.png" />
<figcaption aria-hidden="true">img_192.png</figcaption>
</figure></li>
</ul></li>
</ul>
<h2 id="ml-модели-и-их-виды-1">## ML-модели и их виды</h2>
</body>
</html>
